{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing, cleaning and analysing the data for Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>350625839</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>16750</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>24.07.18</td>\n",
       "      <td>24.08.18</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0378033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>354412280</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>35950</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>16.08.18</td>\n",
       "      <td>07.10.18</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.067925678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>349572992</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11950</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>16.07.18</td>\n",
       "      <td>05.09.18</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.081613797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>350266763</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1750</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>20.07.18</td>\n",
       "      <td>29.10.18</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014008621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>355688985</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>26500</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>28.08.18</td>\n",
       "      <td>08.09.18</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.040816327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78316</td>\n",
       "      <td>348704581</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>15740</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>12.07.18</td>\n",
       "      <td>19.10.18</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.033357505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78317</td>\n",
       "      <td>359231940</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2950</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>28.09.18</td>\n",
       "      <td>23.10.18</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01293617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78318</td>\n",
       "      <td>362425932</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>7850</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>04.11.18</td>\n",
       "      <td>21.11.18</td>\n",
       "      <td>448.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78319</td>\n",
       "      <td>357164227</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>13945</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>04.09.18</td>\n",
       "      <td>02.10.18</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.017934447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78320</td>\n",
       "      <td>353639932</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>38800</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>08.08.18</td>\n",
       "      <td>09.08.18</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78321 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id product_tier      make_name  price  first_zip_digit  \\\n",
       "0       350625839        Basic     Mitsubishi  16750                5   \n",
       "1       354412280        Basic  Mercedes-Benz  35950                4   \n",
       "2       349572992        Basic  Mercedes-Benz  11950                3   \n",
       "3       350266763        Basic           Ford   1750                6   \n",
       "4       355688985        Basic  Mercedes-Benz  26500                3   \n",
       "...           ...          ...            ...    ...              ...   \n",
       "78316   348704581        Basic          Lexus  15740                8   \n",
       "78317   359231940        Basic        Hyundai   2950                6   \n",
       "78318   362425932        Basic     Volkswagen   7850                8   \n",
       "78319   357164227        Basic         Toyota  13945                5   \n",
       "78320   353639932        Basic     Volkswagen  38800                7   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "0                         2013     24.07.18     24.08.18        3091.0   \n",
       "1                         2015     16.08.18     07.10.18        3283.0   \n",
       "2                         1998     16.07.18     05.09.18        3247.0   \n",
       "3                         2003     20.07.18     29.10.18        1856.0   \n",
       "4                         2014     28.08.18     08.09.18         490.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "78316                     2014     12.07.18     19.10.18        6895.0   \n",
       "78317                     2006     28.09.18     23.10.18        1175.0   \n",
       "78318                     2014     04.11.18     21.11.18         448.0   \n",
       "78319                     2011     04.09.18     02.10.18        1617.0   \n",
       "78320                     2018     08.08.18     09.08.18          55.0   \n",
       "\n",
       "       detail_views  stock_days          ctr  \n",
       "0             123.0          30    0.0378033  \n",
       "1             223.0          52  0.067925678  \n",
       "2             265.0          51  0.081613797  \n",
       "3              26.0         101  0.014008621  \n",
       "4              20.0          12  0.040816327  \n",
       "...             ...         ...          ...  \n",
       "78316         230.0          99  0.033357505  \n",
       "78317          16.0          25   0.01293617  \n",
       "78318          21.0          16     0.046875  \n",
       "78319          29.0          28  0.017934447  \n",
       "78320           2.0           1  0.034545455  \n",
       "\n",
       "[78321 rows x 12 columns]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('AS24_Case_Study_Data.csv', sep=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                  0\n",
       "product_tier                0\n",
       "make_name                   0\n",
       "price                       0\n",
       "first_zip_digit             0\n",
       "first_registration_year     0\n",
       "created_date                0\n",
       "deleted_date                0\n",
       "search_views               10\n",
       "detail_views               10\n",
       "stock_days                  0\n",
       "ctr                        24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of null values per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6738</td>\n",
       "      <td>355684985</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>5950</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>28.08.18</td>\n",
       "      <td>28.08.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10151</td>\n",
       "      <td>363161664</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Renault</td>\n",
       "      <td>4950</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>12.11.18</td>\n",
       "      <td>01.03.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19983</td>\n",
       "      <td>360460901</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>2004</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21423</td>\n",
       "      <td>358837372</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2999</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26122</td>\n",
       "      <td>360460897</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>22445</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27830</td>\n",
       "      <td>358837359</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2999</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28823</td>\n",
       "      <td>360460890</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>26445</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38923</td>\n",
       "      <td>360471136</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Audi</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43222</td>\n",
       "      <td>360493605</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>37500</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47870</td>\n",
       "      <td>358837344</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2999</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52291</td>\n",
       "      <td>360460896</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>1194</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57353</td>\n",
       "      <td>350278423</td>\n",
       "      <td>Basic</td>\n",
       "      <td>BMW</td>\n",
       "      <td>10950</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>20.07.18</td>\n",
       "      <td>20.07.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60758</td>\n",
       "      <td>350270138</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Ford</td>\n",
       "      <td>5450</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>20.07.18</td>\n",
       "      <td>26.07.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63577</td>\n",
       "      <td>358837366</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2999</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65127</td>\n",
       "      <td>358837392</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2999</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66498</td>\n",
       "      <td>349581063</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>16.07.18</td>\n",
       "      <td>11.09.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68584</td>\n",
       "      <td>360460887</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Opel</td>\n",
       "      <td>16445</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69176</td>\n",
       "      <td>360460879</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>30445</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70772</td>\n",
       "      <td>364670935</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>2150</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>28.11.18</td>\n",
       "      <td>29.11.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71083</td>\n",
       "      <td>363908548</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Renault</td>\n",
       "      <td>14500</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>20.11.18</td>\n",
       "      <td>20.11.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71854</td>\n",
       "      <td>363925615</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>3795</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>20.11.18</td>\n",
       "      <td>21.11.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72408</td>\n",
       "      <td>358837338</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2999</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>24.09.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72620</td>\n",
       "      <td>359233783</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Audi</td>\n",
       "      <td>1039</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>28.09.18</td>\n",
       "      <td>28.09.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78057</td>\n",
       "      <td>360460880</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>994</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id product_tier      make_name  price  first_zip_digit  \\\n",
       "6738    355684985        Basic          Volvo   5950                8   \n",
       "10151   363161664        Basic        Renault   4950                3   \n",
       "19983   360460901        Basic  Mercedes-Benz    105                7   \n",
       "21423   358837372        Basic     Volkswagen   2999                5   \n",
       "26122   360460897        Basic  Mercedes-Benz  22445                7   \n",
       "27830   358837359        Basic     Volkswagen   2999                5   \n",
       "28823   360460890        Basic  Mercedes-Benz  26445                7   \n",
       "38923   360471136        Basic           Audi   1500                2   \n",
       "43222   360493605        Basic  Mercedes-Benz  37500                3   \n",
       "47870   358837344        Basic     Volkswagen   2999                5   \n",
       "52291   360460896        Basic  Mercedes-Benz   1194                7   \n",
       "57353   350278423        Basic            BMW  10950                9   \n",
       "60758   350270138        Basic           Ford   5450                2   \n",
       "63577   358837366        Basic     Volkswagen   2999                5   \n",
       "65127   358837392        Basic     Volkswagen   2999                5   \n",
       "66498   349581063        Basic         Subaru      1                5   \n",
       "68584   360460887        Basic           Opel  16445                7   \n",
       "69176   360460879        Basic  Mercedes-Benz  30445                7   \n",
       "70772   364670935        Basic  Mercedes-Benz   2150                3   \n",
       "71083   363908548        Basic        Renault  14500                7   \n",
       "71854   363925615        Basic           Fiat   3795                5   \n",
       "72408   358837338        Basic     Volkswagen   2999                5   \n",
       "72620   359233783        Basic           Audi   1039                4   \n",
       "78057   360460880        Basic  Mercedes-Benz    994                7   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "6738                      2009     28.08.18     28.08.18           0.0   \n",
       "10151                     2011     12.11.18     01.03.19           NaN   \n",
       "19983                     2004     12.10.18     12.10.18           0.0   \n",
       "21423                     2003     24.09.18     24.09.18           NaN   \n",
       "26122                     2011     12.10.18     12.10.18           0.0   \n",
       "27830                     2003     24.09.18     24.09.18           NaN   \n",
       "28823                     2011     12.10.18     12.10.18           0.0   \n",
       "38923                     2012     12.10.18     12.10.18           0.0   \n",
       "43222                     2002     12.10.18     12.10.18           0.0   \n",
       "47870                     2003     24.09.18     24.09.18           NaN   \n",
       "52291                     2018     12.10.18     12.10.18           0.0   \n",
       "57353                     2006     20.07.18     20.07.18           NaN   \n",
       "60758                     2009     20.07.18     26.07.18           NaN   \n",
       "63577                     2003     24.09.18     24.09.18           NaN   \n",
       "65127                     2003     24.09.18     24.09.18           NaN   \n",
       "66498                     2006     16.07.18     11.09.18           NaN   \n",
       "68584                     2009     12.10.18     12.10.18           0.0   \n",
       "69176                     2014     12.10.18     12.10.18           0.0   \n",
       "70772                     2002     28.11.18     29.11.18           0.0   \n",
       "71083                     2015     20.11.18     20.11.18           0.0   \n",
       "71854                     2011     20.11.18     21.11.18           0.0   \n",
       "72408                     2003     24.09.18     24.09.18           NaN   \n",
       "72620                     2016     28.09.18     28.09.18           0.0   \n",
       "78057                     2014     12.10.18     12.10.18           0.0   \n",
       "\n",
       "       detail_views  stock_days  ctr  \n",
       "6738            0.0           0  NaN  \n",
       "10151           NaN         109  NaN  \n",
       "19983           0.0          -1  NaN  \n",
       "21423           NaN           0  NaN  \n",
       "26122           0.0           0  NaN  \n",
       "27830           NaN           0  NaN  \n",
       "28823           0.0           0  NaN  \n",
       "38923           0.0           0  NaN  \n",
       "43222           0.0           0  NaN  \n",
       "47870           NaN           0  NaN  \n",
       "52291           0.0           0  NaN  \n",
       "57353           NaN          -1  NaN  \n",
       "60758           NaN           7  NaN  \n",
       "63577           NaN           0  NaN  \n",
       "65127           NaN           0  NaN  \n",
       "66498           NaN          57  NaN  \n",
       "68584           0.0           0  NaN  \n",
       "69176           0.0           0  NaN  \n",
       "70772           0.0           1  NaN  \n",
       "71083           0.0           0  NaN  \n",
       "71854           0.0           2  NaN  \n",
       "72408           NaN           0  NaN  \n",
       "72620           0.0           0  NaN  \n",
       "78057           0.0           0  NaN  "
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying rows with null values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced null values ('NaN') with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                 0\n",
       "product_tier               0\n",
       "make_name                  0\n",
       "price                      0\n",
       "first_zip_digit            0\n",
       "first_registration_year    0\n",
       "created_date               0\n",
       "deleted_date               0\n",
       "search_views               0\n",
       "detail_views               0\n",
       "stock_days                 0\n",
       "ctr                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No more null values in any column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6738</td>\n",
       "      <td>355684985</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>5950</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>28.08.18</td>\n",
       "      <td>28.08.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id product_tier make_name  price  first_zip_digit  \\\n",
       "6738   355684985        Basic     Volvo   5950                8   \n",
       "\n",
       "      first_registration_year created_date deleted_date  search_views  \\\n",
       "6738                     2009     28.08.18     28.08.18           0.0   \n",
       "\n",
       "      detail_views  stock_days ctr  \n",
       "6738           0.0           0   0  "
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row which previously had NaN value\n",
    "df.iloc[[6738]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10151</td>\n",
       "      <td>363161664</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Renault</td>\n",
       "      <td>4950</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>12.11.18</td>\n",
       "      <td>01.03.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id product_tier make_name  price  first_zip_digit  \\\n",
       "10151   363161664        Basic   Renault   4950                3   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "10151                     2011     12.11.18     01.03.19           0.0   \n",
       "\n",
       "       detail_views  stock_days ctr  \n",
       "10151           0.0         109   0  "
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row which previously had NaN value\n",
    "df.iloc[[10151]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78321 entries, 0 to 78320\n",
      "Data columns (total 12 columns):\n",
      "article_id                 78321 non-null int64\n",
      "product_tier               78321 non-null object\n",
      "make_name                  78321 non-null object\n",
      "price                      78321 non-null int64\n",
      "first_zip_digit            78321 non-null int64\n",
      "first_registration_year    78321 non-null int64\n",
      "created_date               78321 non-null object\n",
      "deleted_date               78321 non-null object\n",
      "search_views               78321 non-null float64\n",
      "detail_views               78321 non-null float64\n",
      "stock_days                 78321 non-null int64\n",
      "ctr                        78321 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# This gives an overview of the datatype of each column and helps notice irregularities. \n",
    "# Some incorrect values I noticed while analysing later on.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>849</td>\n",
       "      <td>361161145</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>32450</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>20.10.18</td>\n",
       "      <td>08.11.18</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19</td>\n",
       "      <td>27.624.309.392.265.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1649</td>\n",
       "      <td>360100841</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Opel</td>\n",
       "      <td>4949</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "      <td>08.10.18</td>\n",
       "      <td>31.10.18</td>\n",
       "      <td>930.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4.086.021.505.376.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3885</td>\n",
       "      <td>353638718</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>3750</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>08.08.18</td>\n",
       "      <td>29.08.18</td>\n",
       "      <td>898.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20</td>\n",
       "      <td>30.066.815.144.766.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4169</td>\n",
       "      <td>357115804</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Citroen</td>\n",
       "      <td>8940</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>04.09.18</td>\n",
       "      <td>19.10.18</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>44</td>\n",
       "      <td>5.126.118.795.768.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>353090123</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>4250</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>04.08.18</td>\n",
       "      <td>10.08.18</td>\n",
       "      <td>404.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.485.148.514.851.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71858</td>\n",
       "      <td>360491257</td>\n",
       "      <td>Basic</td>\n",
       "      <td>BMW</td>\n",
       "      <td>6999</td>\n",
       "      <td>7</td>\n",
       "      <td>2005</td>\n",
       "      <td>12.10.18</td>\n",
       "      <td>31.12.18</td>\n",
       "      <td>3472.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>79</td>\n",
       "      <td>7.574.884.792.626.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73055</td>\n",
       "      <td>357159320</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>3750</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>04.09.18</td>\n",
       "      <td>05.01.19</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>123</td>\n",
       "      <td>23.525.280.898.876.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73402</td>\n",
       "      <td>364332664</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Kia</td>\n",
       "      <td>7850</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "      <td>24.11.18</td>\n",
       "      <td>16.01.19</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53</td>\n",
       "      <td>2.883.720.930.232.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74868</td>\n",
       "      <td>361183805</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>6950</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>20.10.18</td>\n",
       "      <td>01.12.18</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42</td>\n",
       "      <td>4.199.855.177.407.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76408</td>\n",
       "      <td>364317161</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>1900</td>\n",
       "      <td>4</td>\n",
       "      <td>1998</td>\n",
       "      <td>24.11.18</td>\n",
       "      <td>01.12.18</td>\n",
       "      <td>829.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7</td>\n",
       "      <td>34.981.905.910.735.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id product_tier   make_name  price  first_zip_digit  \\\n",
       "849     361161145        Basic  Volkswagen  32450                6   \n",
       "1649    360100841        Basic        Opel   4949                8   \n",
       "3885    353638718        Basic  Volkswagen   3750                2   \n",
       "4169    357115804        Basic     Citroen   8940                2   \n",
       "4410    353090123        Basic        Fiat   4250                5   \n",
       "...           ...          ...         ...    ...              ...   \n",
       "71858   360491257        Basic         BMW   6999                7   \n",
       "73055   357159320        Basic        Fiat   3750                2   \n",
       "73402   364332664        Basic         Kia   7850                8   \n",
       "74868   361183805        Basic      Nissan   6950                2   \n",
       "76408   364317161        Basic      Toyota   1900                4   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "849                       2018     20.10.18     08.11.18        2172.0   \n",
       "1649                      2011     08.10.18     31.10.18         930.0   \n",
       "3885                      2009     08.08.18     29.08.18         898.0   \n",
       "4169                      2012     04.09.18     19.10.18        1229.0   \n",
       "4410                      2010     04.08.18     10.08.18         404.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "71858                     2005     12.10.18     31.12.18        3472.0   \n",
       "73055                     2008     04.09.18     05.01.19        2848.0   \n",
       "73402                     2011     24.11.18     16.01.19        1075.0   \n",
       "74868                     2013     20.10.18     01.12.18        1381.0   \n",
       "76408                     1998     24.11.18     01.12.18         829.0   \n",
       "\n",
       "       detail_views  stock_days                     ctr  \n",
       "849            60.0          19  27.624.309.392.265.100  \n",
       "1649           40.0          23   4.086.021.505.376.340  \n",
       "3885           27.0          20  30.066.815.144.766.100  \n",
       "4169           63.0          44   5.126.118.795.768.910  \n",
       "4410            6.0           6   1.485.148.514.851.480  \n",
       "...             ...         ...                     ...  \n",
       "71858         263.0          79   7.574.884.792.626.720  \n",
       "73055          67.0         123  23.525.280.898.876.400  \n",
       "73402          31.0          53   2.883.720.930.232.550  \n",
       "74868          58.0          42   4.199.855.177.407.670  \n",
       "76408          29.0           7  34.981.905.910.735.800  \n",
       "\n",
       "[82 rows x 12 columns]"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I noticed that, column 'ctr' haS irregular values\n",
    "df[pd.to_numeric(df['ctr'], errors='coerce').isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I was removing the rows where ctr was incorrect but later I made the decision to replace them with the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing the rows where the 'ctr' column has irregular values\n",
    "# df = df[pd.to_numeric(df['ctr'], errors='coerce').notnull()]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>350625839</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>16750</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0378033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>354412280</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>35950</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.067925678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>349572992</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11950</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.081613797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>350266763</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1750</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>2018-10-29</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014008621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>355688985</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>26500</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.040816327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78316</td>\n",
       "      <td>348704581</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>15740</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.033357505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78317</td>\n",
       "      <td>359231940</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2950</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01293617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78318</td>\n",
       "      <td>362425932</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>7850</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>448.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78319</td>\n",
       "      <td>357164227</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>13945</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.017934447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78320</td>\n",
       "      <td>353639932</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>38800</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78321 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id product_tier      make_name  price  first_zip_digit  \\\n",
       "0       350625839        Basic     Mitsubishi  16750                5   \n",
       "1       354412280        Basic  Mercedes-Benz  35950                4   \n",
       "2       349572992        Basic  Mercedes-Benz  11950                3   \n",
       "3       350266763        Basic           Ford   1750                6   \n",
       "4       355688985        Basic  Mercedes-Benz  26500                3   \n",
       "...           ...          ...            ...    ...              ...   \n",
       "78316   348704581        Basic          Lexus  15740                8   \n",
       "78317   359231940        Basic        Hyundai   2950                6   \n",
       "78318   362425932        Basic     Volkswagen   7850                8   \n",
       "78319   357164227        Basic         Toyota  13945                5   \n",
       "78320   353639932        Basic     Volkswagen  38800                7   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "0                         2013   2018-07-24   2018-08-24        3091.0   \n",
       "1                         2015   2018-08-16   2018-10-07        3283.0   \n",
       "2                         1998   2018-07-16   2018-09-05        3247.0   \n",
       "3                         2003   2018-07-20   2018-10-29        1856.0   \n",
       "4                         2014   2018-08-28   2018-09-08         490.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "78316                     2014   2018-07-12   2018-10-19        6895.0   \n",
       "78317                     2006   2018-09-28   2018-10-23        1175.0   \n",
       "78318                     2014   2018-11-04   2018-11-21         448.0   \n",
       "78319                     2011   2018-09-04   2018-10-02        1617.0   \n",
       "78320                     2018   2018-08-08   2018-08-09          55.0   \n",
       "\n",
       "       detail_views  stock_days          ctr  \n",
       "0             123.0          30    0.0378033  \n",
       "1             223.0          52  0.067925678  \n",
       "2             265.0          51  0.081613797  \n",
       "3              26.0         101  0.014008621  \n",
       "4              20.0          12  0.040816327  \n",
       "...             ...         ...          ...  \n",
       "78316         230.0          99  0.033357505  \n",
       "78317          16.0          25   0.01293617  \n",
       "78318          21.0          16     0.046875  \n",
       "78319          29.0          28  0.017934447  \n",
       "78320           2.0           1  0.034545455  \n",
       "\n",
       "[78321 rows x 12 columns]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting date columns to datetime datatype\n",
    "# Since Pandas defaults to the US date format, and this data is in European date format, the format is date first\n",
    "df['created_date'] = pd.to_datetime(df['created_date'], dayfirst=True)\n",
    "df['deleted_date'] = pd.to_datetime(df['deleted_date'], dayfirst=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I noticed some incorrect and some negative values in stock_days, \n",
    "# Therefore, I made this calculation as 'Time in days between the creation of the listing and the deletion of the listing'\n",
    "df['calculated_stock_days'] = (df['deleted_date'] - df['created_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>350625839</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>16750</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0378033</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>355688985</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>26500</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.040816327</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>354745488</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Peugeot</td>\n",
       "      <td>12425</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>639.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92</td>\n",
       "      <td>0.008920188</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>355653285</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Opel</td>\n",
       "      <td>6450</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.131650135</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>361202401</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Ford</td>\n",
       "      <td>20400</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>534.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.007490637</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78297</td>\n",
       "      <td>353006120</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Opel</td>\n",
       "      <td>2399</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2018-08-04</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>27609.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.081132964</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78305</td>\n",
       "      <td>348757058</td>\n",
       "      <td>Basic</td>\n",
       "      <td>BMW</td>\n",
       "      <td>54750</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>935.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>110</td>\n",
       "      <td>0.074171123</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78312</td>\n",
       "      <td>353639867</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Daihatsu</td>\n",
       "      <td>2749</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>2018-08-14</td>\n",
       "      <td>388.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041237113</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78313</td>\n",
       "      <td>353637877</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Renault</td>\n",
       "      <td>6950</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>4316.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.065801668</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78318</td>\n",
       "      <td>362425932</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>7850</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>448.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11853 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id product_tier      make_name  price  first_zip_digit  \\\n",
       "0       350625839        Basic     Mitsubishi  16750                5   \n",
       "4       355688985        Basic  Mercedes-Benz  26500                3   \n",
       "10      354745488        Basic        Peugeot  12425                2   \n",
       "12      355653285        Basic           Opel   6450                4   \n",
       "15      361202401        Basic           Ford  20400                6   \n",
       "...           ...          ...            ...    ...              ...   \n",
       "78297   353006120        Basic           Opel   2399                3   \n",
       "78305   348757058        Basic            BMW  54750                3   \n",
       "78312   353639867        Basic       Daihatsu   2749                3   \n",
       "78313   353637877        Basic        Renault   6950                5   \n",
       "78318   362425932        Basic     Volkswagen   7850                8   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "0                         2013   2018-07-24   2018-08-24        3091.0   \n",
       "4                         2014   2018-08-28   2018-09-08         490.0   \n",
       "10                        2017   2018-08-20   2018-11-19         639.0   \n",
       "12                        2007   2018-08-28   2018-09-10        1109.0   \n",
       "15                        2018   2018-10-20   2018-11-22         534.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "78297                     2008   2018-08-04   2018-11-12       27609.0   \n",
       "78305                     2018   2018-07-12   2018-10-31         935.0   \n",
       "78312                     2008   2018-08-08   2018-08-14         388.0   \n",
       "78313                     2011   2018-08-08   2018-10-08        4316.0   \n",
       "78318                     2014   2018-11-04   2018-11-21         448.0   \n",
       "\n",
       "       detail_views  stock_days          ctr  calculated_stock_days  \n",
       "0             123.0          30    0.0378033                     31  \n",
       "4              20.0          12  0.040816327                     11  \n",
       "10              6.0          92  0.008920188                     91  \n",
       "12            146.0          12  0.131650135                     13  \n",
       "15              4.0          32  0.007490637                     33  \n",
       "...             ...         ...          ...                    ...  \n",
       "78297        2240.0          99  0.081132964                    100  \n",
       "78305          73.0         110  0.074171123                    111  \n",
       "78312          16.0           5  0.041237113                      6  \n",
       "78313         284.0          60  0.065801668                     61  \n",
       "78318          21.0          16     0.046875                     17  \n",
       "\n",
       "[11853 rows x 13 columns]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the rows & count where the original column had wrong values \n",
    "df.loc[~(df['calculated_stock_days'] == df['stock_days'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>359768765</td>\n",
       "      <td>Basic</td>\n",
       "      <td>MINI</td>\n",
       "      <td>19950</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>873</td>\n",
       "      <td>362809203</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>13495</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-11-08</td>\n",
       "      <td>2018-11-09</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1269</td>\n",
       "      <td>347248705</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>13925</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.172413793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5095</td>\n",
       "      <td>357831511</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bentley</td>\n",
       "      <td>69950</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5477</td>\n",
       "      <td>348703289</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>18900</td>\n",
       "      <td>7</td>\n",
       "      <td>1966</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76209</td>\n",
       "      <td>362810854</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Audi</td>\n",
       "      <td>4450</td>\n",
       "      <td>7</td>\n",
       "      <td>2005</td>\n",
       "      <td>2018-11-08</td>\n",
       "      <td>2018-11-08</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.108108108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77128</td>\n",
       "      <td>364284041</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2950</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>156.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.121794872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77676</td>\n",
       "      <td>358519572</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>34950</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77808</td>\n",
       "      <td>363557939</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>6485</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>137.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.055474453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77954</td>\n",
       "      <td>361480979</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>1950</td>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>184.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.070652174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id product_tier      make_name  price  first_zip_digit  \\\n",
       "161     359768765        Basic           MINI  19950                7   \n",
       "873     362809203        Basic         Toyota  13495                3   \n",
       "1269    347248705        Basic     Volkswagen  13925                7   \n",
       "5095    357831511        Basic        Bentley  69950                1   \n",
       "5477    348703289        Basic      Chevrolet  18900                7   \n",
       "...           ...          ...            ...    ...              ...   \n",
       "76209   362810854        Basic           Audi   4450                7   \n",
       "77128   364284041        Basic     Volkswagen   2950                1   \n",
       "77676   358519572        Basic  Mercedes-Benz  34950                7   \n",
       "77808   363557939        Basic         Nissan   6485                7   \n",
       "77954   361480979        Basic     Volkswagen   1950                7   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "161                       2011   2018-10-04   2018-10-04           4.0   \n",
       "873                       2014   2018-11-08   2018-11-09          85.0   \n",
       "1269                      2013   2018-07-04   2018-07-04          29.0   \n",
       "5095                      2007   2018-09-12   2018-09-12          47.0   \n",
       "5477                      1966   2018-07-12   2018-07-12         100.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "76209                     2005   2018-11-08   2018-11-08          74.0   \n",
       "77128                     2007   2018-11-24   2018-11-24         156.0   \n",
       "77676                     2017   2018-09-20   2018-09-20          16.0   \n",
       "77808                     2010   2018-11-16   2018-11-16         137.0   \n",
       "77954                     2003   2018-10-24   2018-10-24         184.0   \n",
       "\n",
       "       detail_views  stock_days          ctr  calculated_stock_days  \n",
       "161             1.0          -1         0.25                      0  \n",
       "873             0.0          -1            0                      1  \n",
       "1269            5.0          -1  0.172413793                      0  \n",
       "5095            0.0          -1            0                      0  \n",
       "5477           19.0          -1         0.19                      0  \n",
       "...             ...         ...          ...                    ...  \n",
       "76209           8.0          -1  0.108108108                      0  \n",
       "77128          19.0          -1  0.121794872                      0  \n",
       "77676           0.0          -1            0                      0  \n",
       "77808           8.0          -1  0.055474453                      0  \n",
       "77954          13.0          -1  0.070652174                      0  \n",
       "\n",
       "[93 rows x 13 columns]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying negative values in the stock_days column\n",
    "df[(df['stock_days'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                          int64\n",
       "product_tier                       object\n",
       "make_name                          object\n",
       "price                               int64\n",
       "first_zip_digit                     int64\n",
       "first_registration_year             int64\n",
       "created_date               datetime64[ns]\n",
       "deleted_date               datetime64[ns]\n",
       "search_views                      float64\n",
       "detail_views                      float64\n",
       "stock_days                          int64\n",
       "ctr                                object\n",
       "calculated_stock_days               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical columns to their required datatypes\n",
    "df['product_tier'] = df['product_tier'].astype('category')\n",
    "df['make_name'] = df['make_name'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                          int64\n",
       "product_tier                     category\n",
       "make_name                        category\n",
       "price                               int64\n",
       "first_zip_digit                     int64\n",
       "first_registration_year             int64\n",
       "created_date               datetime64[ns]\n",
       "deleted_date               datetime64[ns]\n",
       "search_views                      float64\n",
       "detail_views                      float64\n",
       "stock_days                          int64\n",
       "ctr                                object\n",
       "calculated_stock_days               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I noticed some ireegular values in the 'ctr' column, \n",
    "# Therefore, I made this calculation as 'Click through rate calculated as the quotient of detail_views over search_views'\n",
    "df['calculated_ctr'] = df.detail_views / df.search_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced null values ('NaN') with 0 as dividing by 0 gives NaN\n",
    "df['calculated_ctr'] = df['calculated_ctr'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This wouldn't work without removing the irregular values in column 'ctr'\n",
    "# df['ctr'] = df['ctr'].round(decimals=6)\n",
    "# df['calculated_ctr'] = df['calculated_ctr'].round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Displaying the rows & count where the original column had wrong values \n",
    "# # and cannot be converted to datatype 'float64'\n",
    "# df.loc[~(df['calculated_ctr'] == df['ctr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "      <th>calculated_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>350625839</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>16750</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0378033</td>\n",
       "      <td>31</td>\n",
       "      <td>0.039793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>354412280</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>35950</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.067925678</td>\n",
       "      <td>52</td>\n",
       "      <td>0.067926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>349572992</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11950</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.081613797</td>\n",
       "      <td>51</td>\n",
       "      <td>0.081614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>350266763</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1750</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>2018-10-29</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014008621</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>355688985</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>26500</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.040816327</td>\n",
       "      <td>11</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78316</td>\n",
       "      <td>348704581</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>15740</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.033357505</td>\n",
       "      <td>99</td>\n",
       "      <td>0.033358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78317</td>\n",
       "      <td>359231940</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2950</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01293617</td>\n",
       "      <td>25</td>\n",
       "      <td>0.013617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78318</td>\n",
       "      <td>362425932</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>7850</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>448.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>17</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78319</td>\n",
       "      <td>357164227</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>13945</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.017934447</td>\n",
       "      <td>28</td>\n",
       "      <td>0.017934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78320</td>\n",
       "      <td>353639932</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>38800</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034545455</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78321 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id product_tier      make_name  price  first_zip_digit  \\\n",
       "0       350625839        Basic     Mitsubishi  16750                5   \n",
       "1       354412280        Basic  Mercedes-Benz  35950                4   \n",
       "2       349572992        Basic  Mercedes-Benz  11950                3   \n",
       "3       350266763        Basic           Ford   1750                6   \n",
       "4       355688985        Basic  Mercedes-Benz  26500                3   \n",
       "...           ...          ...            ...    ...              ...   \n",
       "78316   348704581        Basic          Lexus  15740                8   \n",
       "78317   359231940        Basic        Hyundai   2950                6   \n",
       "78318   362425932        Basic     Volkswagen   7850                8   \n",
       "78319   357164227        Basic         Toyota  13945                5   \n",
       "78320   353639932        Basic     Volkswagen  38800                7   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "0                         2013   2018-07-24   2018-08-24        3091.0   \n",
       "1                         2015   2018-08-16   2018-10-07        3283.0   \n",
       "2                         1998   2018-07-16   2018-09-05        3247.0   \n",
       "3                         2003   2018-07-20   2018-10-29        1856.0   \n",
       "4                         2014   2018-08-28   2018-09-08         490.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "78316                     2014   2018-07-12   2018-10-19        6895.0   \n",
       "78317                     2006   2018-09-28   2018-10-23        1175.0   \n",
       "78318                     2014   2018-11-04   2018-11-21         448.0   \n",
       "78319                     2011   2018-09-04   2018-10-02        1617.0   \n",
       "78320                     2018   2018-08-08   2018-08-09          55.0   \n",
       "\n",
       "       detail_views  stock_days          ctr  calculated_stock_days  \\\n",
       "0             123.0          30    0.0378033                     31   \n",
       "1             223.0          52  0.067925678                     52   \n",
       "2             265.0          51  0.081613797                     51   \n",
       "3              26.0         101  0.014008621                    101   \n",
       "4              20.0          12  0.040816327                     11   \n",
       "...             ...         ...          ...                    ...   \n",
       "78316         230.0          99  0.033357505                     99   \n",
       "78317          16.0          25   0.01293617                     25   \n",
       "78318          21.0          16     0.046875                     17   \n",
       "78319          29.0          28  0.017934447                     28   \n",
       "78320           2.0           1  0.034545455                      1   \n",
       "\n",
       "       calculated_ctr  \n",
       "0            0.039793  \n",
       "1            0.067926  \n",
       "2            0.081614  \n",
       "3            0.014009  \n",
       "4            0.040816  \n",
       "...               ...  \n",
       "78316        0.033358  \n",
       "78317        0.013617  \n",
       "78318        0.046875  \n",
       "78319        0.017934  \n",
       "78320        0.036364  \n",
       "\n",
       "[78321 rows x 14 columns]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysing both the columns 'stock_days' & 'ctr', it is clear that there were a few incorrect values.\n",
    "Therefore, I made the decision to drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the original incorrect columns\n",
    "df = df.drop(['stock_days','ctr'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "      <th>calculated_ctr</th>\n",
       "      <th>product_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>350625839</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>16750</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.039793</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>354412280</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>35950</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.067926</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>349572992</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11950</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.081614</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>350266763</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1750</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>2018-10-29</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>355688985</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>26500</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78316</td>\n",
       "      <td>348704581</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>15740</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.033358</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78317</td>\n",
       "      <td>359231940</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2950</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78318</td>\n",
       "      <td>362425932</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>7850</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>448.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78319</td>\n",
       "      <td>357164227</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>13945</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78320</td>\n",
       "      <td>353639932</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>38800</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78321 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id      make_name  price  first_zip_digit  \\\n",
       "0       350625839     Mitsubishi  16750                5   \n",
       "1       354412280  Mercedes-Benz  35950                4   \n",
       "2       349572992  Mercedes-Benz  11950                3   \n",
       "3       350266763           Ford   1750                6   \n",
       "4       355688985  Mercedes-Benz  26500                3   \n",
       "...           ...            ...    ...              ...   \n",
       "78316   348704581          Lexus  15740                8   \n",
       "78317   359231940        Hyundai   2950                6   \n",
       "78318   362425932     Volkswagen   7850                8   \n",
       "78319   357164227         Toyota  13945                5   \n",
       "78320   353639932     Volkswagen  38800                7   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "0                         2013   2018-07-24   2018-08-24        3091.0   \n",
       "1                         2015   2018-08-16   2018-10-07        3283.0   \n",
       "2                         1998   2018-07-16   2018-09-05        3247.0   \n",
       "3                         2003   2018-07-20   2018-10-29        1856.0   \n",
       "4                         2014   2018-08-28   2018-09-08         490.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "78316                     2014   2018-07-12   2018-10-19        6895.0   \n",
       "78317                     2006   2018-09-28   2018-10-23        1175.0   \n",
       "78318                     2014   2018-11-04   2018-11-21         448.0   \n",
       "78319                     2011   2018-09-04   2018-10-02        1617.0   \n",
       "78320                     2018   2018-08-08   2018-08-09          55.0   \n",
       "\n",
       "       detail_views  calculated_stock_days  calculated_ctr product_tier  \n",
       "0             123.0                     31        0.039793        Basic  \n",
       "1             223.0                     52        0.067926        Basic  \n",
       "2             265.0                     51        0.081614        Basic  \n",
       "3              26.0                    101        0.014009        Basic  \n",
       "4              20.0                     11        0.040816        Basic  \n",
       "...             ...                    ...             ...          ...  \n",
       "78316         230.0                     99        0.033358        Basic  \n",
       "78317          16.0                     25        0.013617        Basic  \n",
       "78318          21.0                     17        0.046875        Basic  \n",
       "78319          29.0                     28        0.017934        Basic  \n",
       "78320           2.0                      1        0.036364        Basic  \n",
       "\n",
       "[78321 rows x 12 columns]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols = ['article_id', 'make_name', 'price', 'first_zip_digit', 'first_registration_year', 'created_date', 'deleted_date', 'search_views', 'detail_views', 'calculated_stock_days', 'calculated_ctr', 'product_tier']\n",
    "df = df[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('AS24_Case_Study_Data_Processed.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data is clean, now onto the Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "      <th>calculated_ctr</th>\n",
       "      <th>product_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>350625839</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>16750</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.039793</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>354412280</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>35950</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.067926</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>349572992</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11950</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>2018-07-16</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.081614</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>350266763</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1750</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>2018-10-29</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>355688985</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>26500</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78316</td>\n",
       "      <td>348704581</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>15740</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.033358</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78317</td>\n",
       "      <td>359231940</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2950</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78318</td>\n",
       "      <td>362425932</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>7850</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>448.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78319</td>\n",
       "      <td>357164227</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>13945</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78320</td>\n",
       "      <td>353639932</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>38800</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>Basic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78321 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id      make_name  price  first_zip_digit  \\\n",
       "0       350625839     Mitsubishi  16750                5   \n",
       "1       354412280  Mercedes-Benz  35950                4   \n",
       "2       349572992  Mercedes-Benz  11950                3   \n",
       "3       350266763           Ford   1750                6   \n",
       "4       355688985  Mercedes-Benz  26500                3   \n",
       "...           ...            ...    ...              ...   \n",
       "78316   348704581          Lexus  15740                8   \n",
       "78317   359231940        Hyundai   2950                6   \n",
       "78318   362425932     Volkswagen   7850                8   \n",
       "78319   357164227         Toyota  13945                5   \n",
       "78320   353639932     Volkswagen  38800                7   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "0                         2013   2018-07-24   2018-08-24        3091.0   \n",
       "1                         2015   2018-08-16   2018-10-07        3283.0   \n",
       "2                         1998   2018-07-16   2018-09-05        3247.0   \n",
       "3                         2003   2018-07-20   2018-10-29        1856.0   \n",
       "4                         2014   2018-08-28   2018-09-08         490.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "78316                     2014   2018-07-12   2018-10-19        6895.0   \n",
       "78317                     2006   2018-09-28   2018-10-23        1175.0   \n",
       "78318                     2014   2018-11-04   2018-11-21         448.0   \n",
       "78319                     2011   2018-09-04   2018-10-02        1617.0   \n",
       "78320                     2018   2018-08-08   2018-08-09          55.0   \n",
       "\n",
       "       detail_views  calculated_stock_days  calculated_ctr product_tier  \n",
       "0             123.0                     31        0.039793        Basic  \n",
       "1             223.0                     52        0.067926        Basic  \n",
       "2             265.0                     51        0.081614        Basic  \n",
       "3              26.0                    101        0.014009        Basic  \n",
       "4              20.0                     11        0.040816        Basic  \n",
       "...             ...                    ...             ...          ...  \n",
       "78316         230.0                     99        0.033358        Basic  \n",
       "78317          16.0                     25        0.013617        Basic  \n",
       "78318          21.0                     17        0.046875        Basic  \n",
       "78319          29.0                     28        0.017934        Basic  \n",
       "78320           2.0                      1        0.036364        Basic  \n",
       "\n",
       "[78321 rows x 12 columns]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                   int64\n",
       "make_name                   object\n",
       "price                        int64\n",
       "first_zip_digit              int64\n",
       "first_registration_year      int64\n",
       "created_date                object\n",
       "deleted_date                object\n",
       "search_views               float64\n",
       "detail_views               float64\n",
       "calculated_stock_days        int64\n",
       "calculated_ctr             float64\n",
       "product_tier                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_tier'] = df['product_tier'].astype('category')\n",
    "df['make_name'] = df['make_name'].astype('category')\n",
    "df['created_date'] = pd.to_datetime(df['created_date'], dayfirst=True)\n",
    "df['deleted_date'] = pd.to_datetime(df['deleted_date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                          int64\n",
       "make_name                        category\n",
       "price                               int64\n",
       "first_zip_digit                     int64\n",
       "first_registration_year             int64\n",
       "created_date               datetime64[ns]\n",
       "deleted_date               datetime64[ns]\n",
       "search_views                      float64\n",
       "detail_views                      float64\n",
       "calculated_stock_days               int64\n",
       "calculated_ctr                    float64\n",
       "product_tier                     category\n",
       "dtype: object"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will have to encode categorical values. \n",
    "i.e. represent the strings (categories in column 'product_tier' & 'make_name') as integers\n",
    "\n",
    "The scikit approach is optimal when you are trying to build a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# ord_enc = OrdinalEncoder()\n",
    "# df_encoded[\"make_name\"] = ord_enc.fit_transform(df_encoded[[\"make_name\"]])\n",
    "# df_encoded[\"product_tier\"] = ord_enc.fit_transform(df_encoded[[\"product_tier\"]])\n",
    "# df_encoded[\"created_date\"] = ord_enc.fit_transform(df_encoded[[\"created_date\"]])\n",
    "# df_encoded[\"deleted_date\"] = ord_enc.fit_transform(df_encoded[[\"deleted_date\"]])\n",
    "# df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.to_csv('AS24_Case_Study_Data_Encoded.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# ord_enc = OrdinalEncoder()\n",
    "# df_encoded[\"make_name\"] = ord_enc.fit_transform(df_encoded[[\"make_name\"]])\n",
    "# df_encoded[\"created_date\"] = ord_enc.fit_transform(df_encoded[[\"created_date\"]])\n",
    "# df_encoded[\"deleted_date\"] = ord_enc.fit_transform(df_encoded[[\"deleted_date\"]])\n",
    "# Mapping_Tier = {\"Basic\":0, \"Plus\":0.5, \"Premium\":1}\n",
    "# df_encoded[\"product_tier\"] = df_encoded[\"product_tier\"].replace(Mapping_Tier)\n",
    "# df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['product_tier']=df['product_tier'].astype('category').cat.codes\n",
    "# df['make_name']=df['make_name'].astype('category').cat.codes\n",
    "# df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1. Is it possible to predict the product tier from the information given in the other columns?\n",
    "\n",
    "# This is a Classification predictive modeling problem, particularly a Multi-Class Classification problem with 3 classes; Basic, Plus & Premium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular algorithms that can be used for multi-class classification include:\n",
    "\n",
    "k-Nearest Neighbors.\n",
    "Decision Trees.\n",
    "Naive Bayes.\n",
    "Random Forest.\n",
    "Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start with analysing whether there's a correlation between any variable. \n",
    "As in, if the prediction of 'product tier' is in any way dependent on any other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample figsize in inches\n",
    "fig, ax = plt.subplots(figsize=(20,15))         \n",
    "# Imbalanced DataFrame Correlation\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, cmap='YlGnBu', annot_kws={'size':30}, ax=ax)\n",
    "ax.set_title(\"Correlation Matrix\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am converting the columns as input and output for ML algorithms.\n",
    "X -> features to predict product_tier\n",
    "y -> predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (78321, 11)\n",
      "Output (78321,)\n"
     ]
    }
   ],
   "source": [
    "print('Input', X.shape)\n",
    "print('Output', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['350625839.0' '62.0' '16750.0' ... '123.0' '31.0'\n",
      "  '0.039792947266256866']\n",
      " ['354412280.0' '60.0' '35950.0' ... '223.0' '52.0' '0.06792567773378007']\n",
      " ['349572992.0' '60.0' '11950.0' ... '265.0' '51.0' '0.0816137973514013']\n",
      " ...\n",
      " ['362425932.0' '88.0' '7850.0' ... '21.0' '17.0' '0.046875']\n",
      " ['357164227.0' '85.0' '13945.0' ... '29.0' '28.0' '0.017934446505875078']\n",
      " ['353639932.0' '88.0' '38800.0' ... '2.0' '1.0' '0.03636363636363636']]\n",
      "['0.0' '0.0' '0.0' ... '0.0' '0.0' '0.0']\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal = OrdinalEncoder()\n",
    "# X = ordinal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Input', X.shape)\n",
    "# print(X[:5, :])\n",
    "# print('Output', y.shape)\n",
    "# print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "      <th>calculated_ctr</th>\n",
       "      <th>product_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>article_id</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.026242</td>\n",
       "      <td>0.988639</td>\n",
       "      <td>0.801259</td>\n",
       "      <td>0.026660</td>\n",
       "      <td>0.034606</td>\n",
       "      <td>-0.001896</td>\n",
       "      <td>-0.048348</td>\n",
       "      <td>0.023190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>make_name</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098114</td>\n",
       "      <td>0.025569</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>-0.011613</td>\n",
       "      <td>-0.050173</td>\n",
       "      <td>-0.065962</td>\n",
       "      <td>-0.027941</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.023868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>price</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>-0.098114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034330</td>\n",
       "      <td>0.311407</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.059369</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.085757</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>-0.007634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>first_zip_digit</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.025569</td>\n",
       "      <td>-0.034330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016744</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>-0.016309</td>\n",
       "      <td>-0.008914</td>\n",
       "      <td>-0.006135</td>\n",
       "      <td>-0.039331</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>-0.029988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>first_registration_year</td>\n",
       "      <td>0.026242</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>0.311407</td>\n",
       "      <td>-0.016744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027137</td>\n",
       "      <td>0.069870</td>\n",
       "      <td>-0.110159</td>\n",
       "      <td>-0.122525</td>\n",
       "      <td>0.081650</td>\n",
       "      <td>-0.052600</td>\n",
       "      <td>-0.023942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>created_date</td>\n",
       "      <td>0.988639</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>0.027137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810338</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.036147</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>-0.035349</td>\n",
       "      <td>0.021473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>deleted_date</td>\n",
       "      <td>0.801259</td>\n",
       "      <td>-0.011613</td>\n",
       "      <td>0.059369</td>\n",
       "      <td>-0.016309</td>\n",
       "      <td>0.069870</td>\n",
       "      <td>0.810338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181339</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>0.585120</td>\n",
       "      <td>-0.115374</td>\n",
       "      <td>0.010790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>search_views</td>\n",
       "      <td>0.026660</td>\n",
       "      <td>-0.050173</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>-0.008914</td>\n",
       "      <td>-0.110159</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.181339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>0.271771</td>\n",
       "      <td>-0.057832</td>\n",
       "      <td>0.315879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>detail_views</td>\n",
       "      <td>0.034606</td>\n",
       "      <td>-0.065962</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>-0.006135</td>\n",
       "      <td>-0.122525</td>\n",
       "      <td>0.036147</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>0.102354</td>\n",
       "      <td>0.244760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>calculated_stock_days</td>\n",
       "      <td>-0.001896</td>\n",
       "      <td>-0.027941</td>\n",
       "      <td>0.085757</td>\n",
       "      <td>-0.039331</td>\n",
       "      <td>0.081650</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>0.585120</td>\n",
       "      <td>0.271771</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.147377</td>\n",
       "      <td>-0.011427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>calculated_ctr</td>\n",
       "      <td>-0.048348</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>-0.052600</td>\n",
       "      <td>-0.035349</td>\n",
       "      <td>-0.115374</td>\n",
       "      <td>-0.057832</td>\n",
       "      <td>0.102354</td>\n",
       "      <td>-0.147377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>product_tier</td>\n",
       "      <td>0.023190</td>\n",
       "      <td>-0.023868</td>\n",
       "      <td>-0.007634</td>\n",
       "      <td>-0.029988</td>\n",
       "      <td>-0.023942</td>\n",
       "      <td>0.021473</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.315879</td>\n",
       "      <td>0.244760</td>\n",
       "      <td>-0.011427</td>\n",
       "      <td>-0.051897</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         article_id  make_name     price  first_zip_digit  \\\n",
       "article_id                 1.000000   0.006237  0.012259         0.007915   \n",
       "make_name                  0.006237   1.000000 -0.098114         0.025569   \n",
       "price                      0.012259  -0.098114  1.000000        -0.034330   \n",
       "first_zip_digit            0.007915   0.025569 -0.034330         1.000000   \n",
       "first_registration_year    0.026242   0.029837  0.311407        -0.016744   \n",
       "created_date               0.988639   0.005815  0.010852         0.008609   \n",
       "deleted_date               0.801259  -0.011613  0.059369        -0.016309   \n",
       "search_views               0.026660  -0.050173  0.003006        -0.008914   \n",
       "detail_views               0.034606  -0.065962  0.028902        -0.006135   \n",
       "calculated_stock_days     -0.001896  -0.027941  0.085757        -0.039331   \n",
       "calculated_ctr            -0.048348  -0.019120  0.003916         0.020698   \n",
       "product_tier               0.023190  -0.023868 -0.007634        -0.029988   \n",
       "\n",
       "                         first_registration_year  created_date  deleted_date  \\\n",
       "article_id                              0.026242      0.988639      0.801259   \n",
       "make_name                               0.029837      0.005815     -0.011613   \n",
       "price                                   0.311407      0.010852      0.059369   \n",
       "first_zip_digit                        -0.016744      0.008609     -0.016309   \n",
       "first_registration_year                 1.000000      0.027137      0.069870   \n",
       "created_date                            0.027137      1.000000      0.810338   \n",
       "deleted_date                            0.069870      0.810338      1.000000   \n",
       "search_views                           -0.110159      0.027253      0.181339   \n",
       "detail_views                           -0.122525      0.036147      0.194355   \n",
       "calculated_stock_days                   0.081650     -0.000829      0.585120   \n",
       "calculated_ctr                         -0.052600     -0.035349     -0.115374   \n",
       "product_tier                           -0.023942      0.021473      0.010790   \n",
       "\n",
       "                         search_views  detail_views  calculated_stock_days  \\\n",
       "article_id                   0.026660      0.034606              -0.001896   \n",
       "make_name                   -0.050173     -0.065962              -0.027941   \n",
       "price                        0.003006      0.028902               0.085757   \n",
       "first_zip_digit             -0.008914     -0.006135              -0.039331   \n",
       "first_registration_year     -0.110159     -0.122525               0.081650   \n",
       "created_date                 0.027253      0.036147              -0.000829   \n",
       "deleted_date                 0.181339      0.194355               0.585120   \n",
       "search_views                 1.000000      0.835640               0.271771   \n",
       "detail_views                 0.835640      1.000000               0.281700   \n",
       "calculated_stock_days        0.271771      0.281700               1.000000   \n",
       "calculated_ctr              -0.057832      0.102354              -0.147377   \n",
       "product_tier                 0.315879      0.244760              -0.011427   \n",
       "\n",
       "                         calculated_ctr  product_tier  \n",
       "article_id                    -0.048348      0.023190  \n",
       "make_name                     -0.019120     -0.023868  \n",
       "price                          0.003916     -0.007634  \n",
       "first_zip_digit                0.020698     -0.029988  \n",
       "first_registration_year       -0.052600     -0.023942  \n",
       "created_date                  -0.035349      0.021473  \n",
       "deleted_date                  -0.115374      0.010790  \n",
       "search_views                  -0.057832      0.315879  \n",
       "detail_views                   0.102354      0.244760  \n",
       "calculated_stock_days         -0.147377     -0.011427  \n",
       "calculated_ctr                 1.000000     -0.051897  \n",
       "product_tier                  -0.051897      1.000000  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Feature Selection helps identify whether a feature is important in order to predict the label.\n",
    "It can help improve accuracy by choosing only the best features and not letting other features affect the model.\n",
    "It helps avoid over-fitting and the complexity; i.e. helps to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: article_id, \n",
      "Feature 1: make_name, \n",
      "Feature 2: price, \n",
      "Feature 3: first_zip_digit, \n",
      "Feature 4: first_registration_year, \n",
      "Feature 5: created_date, \n",
      "Feature 6: deleted_date, \n",
      "Feature 7: search_views, \n",
      "Feature 8: detail_views, \n",
      "Feature 9: calculated_stock_days, \n",
      "Feature 10: calculated_ctr\n",
      "\n",
      "Feature: 0, Score: 0.06928\n",
      "Feature: 1, Score: 0.05468\n",
      "Feature: 2, Score: 0.11411\n",
      "Feature: 3, Score: 0.06421\n",
      "Feature: 4, Score: 0.06077\n",
      "Feature: 5, Score: 0.02443\n",
      "Feature: 6, Score: 0.05634\n",
      "Feature: 7, Score: 0.26096\n",
      "Feature: 8, Score: 0.05756\n",
      "Feature: 9, Score: 0.15896\n",
      "Feature: 10, Score: 0.07869\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decision tree for feature importance on a classification problem with 'product_tier' as the label (output)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "print(\"Feature 0: article_id, \\nFeature 1: make_name, \\nFeature 2: price, \\nFeature 3: first_zip_digit, \\nFeature 4: first_registration_year, \\nFeature 5: created_date, \\nFeature 6: deleted_date, \\nFeature 7: search_views, \\nFeature 8: detail_views, \\nFeature 9: calculated_stock_days, \\nFeature 10: calculated_ctr\\n\")\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.07401\n",
      "Feature: 1, Score: 0.04709\n",
      "Feature: 2, Score: 0.09129\n",
      "Feature: 3, Score: 0.04675\n",
      "Feature: 4, Score: 0.05766\n",
      "Feature: 5, Score: 0.04236\n",
      "Feature: 6, Score: 0.07718\n",
      "Feature: 7, Score: 0.22030\n",
      "Feature: 8, Score: 0.11069\n",
      "Feature: 9, Score: 0.13408\n",
      "Feature: 10, Score: 0.09858\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: article_id, \n",
      "Feature 1: make_name, \n",
      "Feature 2: price, \n",
      "Feature 3: first_zip_digit, \n",
      "Feature 4: first_registration_year, \n",
      "Feature 5: created_date, \n",
      "Feature 6: deleted_date, \n",
      "Feature 7: search_views, \n",
      "Feature 8: detail_views, \n",
      "Feature 9: calculated_stock_days, \n",
      "Feature 10: calculated_ctr\n",
      "\n",
      "Feature: 0, Score: 0.05510\n",
      "Feature: 1, Score: 0.05152\n",
      "Feature: 2, Score: 0.08253\n",
      "Feature: 3, Score: 0.09062\n",
      "Feature: 4, Score: 0.07642\n",
      "Feature: 5, Score: 0.00000\n",
      "Feature: 6, Score: 0.06368\n",
      "Feature: 7, Score: 0.25345\n",
      "Feature: 8, Score: 0.05605\n",
      "Feature: 9, Score: 0.19851\n",
      "Feature: 10, Score: 0.07213\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "print(\"Feature 0: article_id, \\nFeature 1: make_name, \\nFeature 2: price, \\nFeature 3: first_zip_digit, \\nFeature 4: first_registration_year, \\nFeature 5: created_date, \\nFeature 6: deleted_date, \\nFeature 7: search_views, \\nFeature 8: detail_views, \\nFeature 9: calculated_stock_days, \\nFeature 10: calculated_ctr\\n\")\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried three classifier algortihms (Decision Tree, Random Forest & XGBoost) to check for feature importance.\n",
    "\n",
    "But logically, I do not see any relation between 'search_views' and 'product_tier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran a Neural Network model with Keras with 'product_tier' as 'y' and all other columns as the input 'X'\n",
    "The Neural network architecture I used for the problem\n",
    "\"Hidden layer 1: 32 neurons, ReLU activation\n",
    "Hidden layer 2: 32 neurons, ReLU activation\n",
    "Output Layer: 1 neuron, Sigmoid activation\"\n",
    "\n",
    "The final epoch yielded a 96.28% accuracy on train dataset, 96.27% accuracy on validation dataset & 96.3% accuracy on test dataset\n",
    "\n",
    "While analysing the data previously, I noticed that most of the product tiers are 'Basic' and after training this model with yielded such a high accuracy, it proves that the dataset is an Imbalanced Dataset. \n",
    "Therefore, if 96% of the times the product tier is Basic, a model can always predict Basic and it will be accurate 96% of the times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "      <th>calculated_ctr</th>\n",
       "      <th>product_tier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_tier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Basic</td>\n",
       "      <td>75421</td>\n",
       "      <td>90</td>\n",
       "      <td>5741</td>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "      <td>35</td>\n",
       "      <td>273</td>\n",
       "      <td>9160</td>\n",
       "      <td>1251</td>\n",
       "      <td>127</td>\n",
       "      <td>41344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Plus</td>\n",
       "      <td>576</td>\n",
       "      <td>42</td>\n",
       "      <td>353</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>183</td>\n",
       "      <td>559</td>\n",
       "      <td>356</td>\n",
       "      <td>119</td>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Premium</td>\n",
       "      <td>2324</td>\n",
       "      <td>53</td>\n",
       "      <td>854</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>233</td>\n",
       "      <td>2224</td>\n",
       "      <td>893</td>\n",
       "      <td>125</td>\n",
       "      <td>2302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              article_id  make_name  price  first_zip_digit  \\\n",
       "product_tier                                                  \n",
       "Basic              75421         90   5741                9   \n",
       "Plus                 576         42    353                9   \n",
       "Premium             2324         53    854                9   \n",
       "\n",
       "              first_registration_year  created_date  deleted_date  \\\n",
       "product_tier                                                        \n",
       "Basic                              87            35           273   \n",
       "Plus                               28            35           183   \n",
       "Premium                            38            35           233   \n",
       "\n",
       "              search_views  detail_views  calculated_stock_days  \\\n",
       "product_tier                                                      \n",
       "Basic                 9160          1251                    127   \n",
       "Plus                   559           356                    119   \n",
       "Premium               2224           893                    125   \n",
       "\n",
       "              calculated_ctr  product_tier  \n",
       "product_tier                                \n",
       "Basic                  41344             1  \n",
       "Plus                     573             1  \n",
       "Premium                 2302             1  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying count of the classes\n",
    "df.groupby('product_tier').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basic      96.297289\n",
       "Premium     2.967276\n",
       "Plus        0.735435\n",
       "Name: product_tier, dtype: float64"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of the classes\n",
    "df['product_tier'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several strategies to tackle the problem of an Imbalanced Dataset.\n",
    "From my research and experience, I have come accross:\n",
    "1. Resampling\n",
    "2. Class penalty -\n",
    "   Cost-sensitive Logistic Regression.\n",
    "   Cost-sensitive Decision Trees.\n",
    "   Cost-sensitive Support Vector Machines.\n",
    "   \n",
    "This is an example of an Anomaly / Fraud Detection problems. \n",
    "In principle, minority classes can be considered outliars by unsupervised ml algrotihms. Anomaly / Fraud Detection problems    often have an Imbalanced Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.countplot('product_tier', data=df)\n",
    "plt.title('Imbalanced Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 11) (1000,)\n",
      "Counter({0: 941, 2: 45, 1: 14})\n",
      "[131.  27. 143.   4.  30.   5.  44. 415.  27.  47. 486.] 0\n",
      "[262.  26. 345.   3.  32.  10.  86. 447. 106.  70. 755.] 0\n",
      "[ 88.  26.  41.   2.  15.   3.  55. 441. 128.  69. 823.] 0\n",
      "[112.  13. 158.   5.  20.   4. 108. 225. 125.   4.  77.] 0\n",
      "[383.  26. 271.   2.  31.  13.  58. 582.  92.  13. 501.] 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9e5hUxZk//qlz5jTTPTjTAzPCMMMoossIchVvgd0ETSARRRRFiWazGw27j/tbMPn+MEPi4uCaMMJuYsyzu98Qs7v+NlkNojtRMUEjuSwmmmBGQKLEKApzAYeBGWB6Ln2p3x/dp+f06apz6tx6+sycz/P44FRXvfXWW3WqT9dbn/cllFIECBAgQAD/QRppBQIECBAggD0EG3iAAAEC+BTBBh4gQIAAPkWwgQcIECCATxFs4AECBAjgU5QUsrOqqip64YUXFrLLAAECBPA93njjjZOU0mp9eUE38AsvvBD79u0rZJcBAgQI4HsQQj5klQdHKAECBAjgUwQbeIAAAQL4FMEGHiBAgAA+RbCBBwgQIIBPEWzgAQIECOBTFPQWymhGS2s7tu0+jI6efkyJhrFh2QysnF870moFCBBgFCPYwF1AS2s7Nj57EP3xJACgvacfG589CADBJh4gQADPEByhuIBtuw9nN28V/fEktu0+PEIaBQgQYCwg2MBdQEdPv6XyAAECBHADwQbuAqZEw5bKAwQIEMANFP0Z+AMtB/Hk68eQpBQyIVhz1VQ8vHJ2Th0jB6L2s/OqDoBW/gRUPg0pWYlV076IB6/9XF6fapv2nn7IhCBJKWqjYSxpqMbP3+nKKVf/JQC0uY3CiowlDdWY+Q8/QSyeAgAQAnzsogn4Q+dZnI7F8/qNhhU0rZjFPTe36ihl1QeQLasIKyAEOB2L54xTX2+KZuxmNtZ+ZkVffV2WrWsZMkTn3q5jWStDtVdPLJ5nT56e2vWrwsp4Hp35Lq547ztA7zGAyABNAkQGpUmcQDW2DN2GfeWf4o7NaA2Y2daqfezOvQqtrbTPk0SAcSUSliZ/ha+EdmAyutGRmojHQ3dh3vK1zPmORhRQCvT0569tnr1Z86sdixV7FepSAylkSrWFCxdSK7FQHmg5iB+8djSv/K6r67ObuN6BCKQ3zy23pD9XPyspb0VpzbMg0vDGSVMKbrvgSzmbOEueKNRFp272//36UaQsmleRCLbdNjdvso3GyXtw9fUViQAEiCeNlVJkAlAgbqA8y8baz1ZdXotn3mgX0teKzbUyROferH8ezPQyslNYkbGgvgKvvnfK9nhWSHvxiPI4wmSI2z5GQ2iM34OX5Y/njc3qGnDDPlbnXgXvWVexQtqLZuVxRDS2iNEQNtG1WHzzvQDy55sFs/Wjr8sai9mYrD6rIiCEvEEpXZhXXswb+PSNL+a8uaiQCcF7W64HACxq3oN2xllzbeb4Qv2sbHozpFBPXj2SqMSBu3+V/ZsnTxS10TBebbzWkRxVhhZG49TXNarvJvQ21kJ9U2G1ER2bUb9GNjbSi2cvFgphQ4A/nr2hdaiTTpq2b0tVYfHQY3ljs6O/G/axMvcqeM+6Cp4t2lJVuD3yPQDs+WbByjPKG4telhZWn1UR8Dbwoj5C4RlOWy7qQCRK/uYNACn5tGE7q1DbO5HDamvVUVoIB6pRH7y5szI2s37tjN1KX4VyQvPGM4WYb97pet3M9nb0d8M+VuberI0Kni2mkG7X148Vvdx4Vp2gqDdwo2+/Cxt3AUifK4NRJRKS0Tc0/BOGxqMgjDfwSYkU1n11I55LLXZFZwrgkq/uYqkkDIkQtLS2A0ifVZ5I/RqR6btBlB7QeBSDXcuQODM/259qC2D4HH1KNOz52yOF+RsKq82FjbvyfAZWUKpImL7xRX57AvBUikYUAOmfuU3PHUJPf/pIrSwkg1Ka9VcUElWTD2Hpzm9jfEMnUpr57aBVqBPYxDvoRADDTnP1/NWufWdt+mn22dH6ZVpa27H5+UNZ/w3v2eOtiWhEwaLmPczzeDN00CrsHx/DtyujOF4iY3IiifWnezD3bMTyOCVC8LvnvotXS7diMj2JDlqFrYnVzD1AIjA8BqUA5m1+CU0rZmXHwquurj03UdRHKGbnYjzIEkFSZ3XWGXhpKoWmk6ew5FwCjfF7XNvE3YB6VknLfs88ux/ovCW7ibPa3n7lVO7ZnWnfAmfgIwUJgJMtVrXNj357zNPxSQSYXl2Gdz/qM6wXqdyP0ppnEaeD2TJ1fq8/15d37quHegb+Al2Mb66eB0DsLNgKsjb73TFT/wkALJo+Ab8/2pt79s5YU6I+GQC4suIpHJn8ewxIwxfnSlMpTDu+AL/tvcPSeHjn6U72AAmALBPDsUgAvnn7PFvn4LwjlKK+Rvjwytm46+p6yISY1pUJAUH6nCnFeDATZ+ZjoPMWnB9PgVCKmngCTSdPYXlfDBEyhPtLdngwAvuIpyjiSYpx1btzNm8AIFIc46p3G7b9+Ttd2HLLbCHbaVEbDWPbrXOx7ba52bPkYkFtNJz2FDtAPEXx5Ovebt5A+s0sNmT8VVMbDWPC1FdyNm9geH6fSy1GY/wetKWqkKJAgkqgmX9TNH3+q246FGnWL4tU5hRZmwlstADwQXc/ttwyG7XRcPaZLAuV5NlcXeMiOFT1Qc7mDQADkoRDVR8Itdfi/pIdeV+KTveAFMy/iFIQ+7VhBUV9hAKkN3H1xsm0Rv7RRIpSHGleDiD3SEGLxJn5eHlwGyTGJqCeIxYbeGf3vHIVHT39WDm/Fl/60ZvCfX2QsZ+KlfNrDW1eKBDAdG6twMqRj11QanzmSQC82ngt5jxxH/vzzPw+l1qM54bM3wrVIXl1bm/FZura075pTnM4b3afAxaMztO9htvzU9Rv4HoYEWO0nxm9dXbQKk75RPuKeQgaj1oqV6HaQ5RMxLNZMZCRROdWFG7IEOlDZL1OLpvM/Nxsfln9aeW6DSs2Y+lgRS9WX3afAxZGcg9we36EN3BCiEwIaSWEvJD5exoh5HVCyLuEkB8RQkKuasbAhmUz0mdpOigSyTpEAGDNVVOZ7RdNn4B/Tt2OGM1VNUZD2JpY7a6yDqFIBIpMMNi1DDSV6/ygKQVDXcsM26r22LBsBsKKbNpfklIsat6TdZ6q4Nm8UJAlgkhIwoWNu7DuqxvxS+Xv8f64z2JvaB1WSHstyyMozBv4mqumYklDXg7aLHpiQ5i3+SUc+eNfQE7lzk9JiuArp09YGqe65pc0VDs9ZWJC1GaKTNA3mMCFjbswfeOLuLBxF+Ztfgk9sfSRRUl5K8qmN2N8QyPKpjdjXLRVqC/eczBo8BzwsDWxWngPUGSSPqt3ARKQs0+5JVMU6wG8rfn7EQDfopReAuA0gLvdVIyFlfNrse3WuajUeHOjYSWP+KI/O5cJwV1X1+OHX7wGH1/1d/hH8reZc0WSc45YaIQVCWWh4YdXXSa10TC23TYX226di/MSV2Kg8xakhqKgFEgNRRE/cQtun3kTouF8r7beHivn1+adR15yfhlTHzWKonYTXzm/Frdfwf5CVHW96+r6HF0iigRFs7Ikkv7y1M6byCNRFpJxUVUE737Ul3U81UknIRGgTjqJZuVxrJRfxSXnlwnJc3LzhSULSI9/0fQJeWtt4QUT8Mwb7dz2fUNJ9PTH8ZlzfdjU1Y2aeCLrm/nHri78ZexEdpyPKI9jTelr2flj9ffwytloaW3HM2+0M8dIkJ4DdR1o152bSKZo9maPuhH39MfRNzRMppNCPSAEkEI9CNf8DyKV5sd8qg+LxoefA5YjXztOHp5LLcbXkl/EaWUSUhjeA341bgnuuro+51nR+oMI0s9XROFvm0brkLj0RZAjU+QWCiGkDsATAL4O4MsAbgTQBWAypTRBCLkGQBOl1PDr0OotlELDCvHBLoHG6mV+L0gBVnX0QgdRueqZN5fUUjEViwYfs03IMCL9GMFs7KJrSZSsg4qpwJfeMqxiZV6dEs0A6zbjkelS8Sj6/tQoJEPk2qooUcer9Wuko90+nRJ5HgVwP4DzMn9PBNBDKU1k/m4DwLwbQwhZC2AtANTX11vRueBwg8RgJsMu6cCpHCttRQkhbpGeRMq5pJbeNnQM2Cdk2B2DW/MsStZBb5tpFSs6ebl+eOA6IkvEHZEiRzmiRB2v1q+RjgV3YhJCbgDwEaX0DW0xoypTa0rpdkrpQkrpwupq/plgMcCKg8FuBEKrTgwvIh1a1dGraItW5PIcT6ioE9LDyElrZxxuzTN3XHpU1JlWsaKT0/Vjpz3XEZkQd0SKOFNFHfherV8jHUfCibkIwApCyAcAngJwLdJv5FFCiPoGXwegw1XNHKCltR2LmvdgWuMupmOOB1GHX1iRuc4II6efIpO8dma6spxSRv2LwGicLNms+k51EJW7aPoEAGzHE5QwcN2mtM0NzhcVKR3FkteX6Lxr5S1pqDacN1GZrHHpX+AScilw3SZm+13v78LSnUsx54k5IPVfR6RyP7Oe3q4bls1gXqfVQ1/HyGaq450HliNSIeOwsPyz5opk+mbNI0s/wPo6V59FrQPWaP/grd+rL6pk1mc9/05heoRCKd0IYCMAEEI+AeD/pZTeSQh5GsCtSG/qnwfwY1c1swkn6c3Uz9XQkURDydZGGjQKDamWaynHAFAZUfDgjbMMo8XpdWU5pQiAVZfXOgpNqR+nWYhMbX03w2OKyP3hF6/Bnd/7DZ57bzEQT5MwpkjdkCrq0pvanNVAazvXe6Slgi+8YIJhX7xwtlo6dTSs4Ia5NTksV9YaY41NG5JXDXf6fP9iTFBCuF/5EcL9x9GJiXg5OQ/XSW9iitSNgfBkRD7zUHqcOux6fxeaft2EgeQAAKA3/hFKa55F2bgSdB2fZTiv6v9/9dkDzPABauhmKzbjhaqNqmGLz8zHEAClejckpQcVofOx8eovY/lFy/FAKD/sbpQT3lWrk2rH3v54nn5W1rn+WVT1MNo/eHPMcl6XhWR8/Wb70Qh5sESl12zgNxBCLkJ6854AoBXAXZTqKGU6FMKJ6ZXDzQuY6eqnsYwkCm2nYpmXpTuXorOvM6+8pqwGL936UsH0GA1wy+Hp1dpwJRohpfQXAH6R+f/3AVxpWyOP4Kf0Zma6+mksI4lC26lY5uV433FL5QH4cMvhWei14Ssmpgj8lN7MTFc/jWUk4ZWdeP6JYpkXHouTVx6AD7ccnoVeG6NuA/fK4eYFzHT101hGEl7YST0Tbe/pB0UuyalY5mX9gvUolUtzykrlUqxfsL6geowGWHV4WpHj5doo+mBWVuGVw80LmOnqp7GMJLywEyuqX388iW27D2fPMkd6XpZflA7w9e3ffxvH+45jctlkrF+wPlseQBxWHfsicgqxNoo6HniAACMFXhRGbWTEAAEKBV/GAw8QYKRQLOfcAQIYwXdHKGq6KKs/T/zSzqkMfdor7T1op9Drs6ShGi/s78wGL9LfdXfDBm7oaaffDctmMDOLOz1Xd8seorJGag4KDSfjNHpmit1+vjpC0V+2B9IP1ZZbjC/I+6WdUxktre3YsHN/XmYQRSJ5ERutgqUPC4pMsO3WuQDyU3tZtYFbetrt1+0N1029RGS52Wcxw8k4jZ4ZVlrCkbLfqDhCMXIsjYZ2TmVs232YmdYpnqKOUzmJpuqKJ9N9uWEDO3Cz35Xza/Fq47U40rwcrzZe65lT1CtZIzUHhYaTcRo9M0++fqzo7eerIxS3IwAWWzunMux+5kSfQutht++RJj+5qZeorGK1hdtwMk6jOm5HsPQCvtrAp0TDTJqqyCX8YmhHkabaamNG8H6e82RUhBUsat7DbMdrI6KzGYxk8/oStZ2bRxV258xruKmXqKxitYXbcDJOo3XNi+utlzuS5+S+OkKxe0m+GNqpaO/px4ad+7Hh6f1MkoiRDEUi6BtKcNuJppyzA9HoemrENVHbGRFm3NKzGMhPbuolKqtYbeE2nIzT6JkximCpwu31axVyU1NTQToCgO3btzetXbvWdvuGmnLUVYZxsL0X5wYSqI2GsenGmabfdiPZ7uxAIu/zFB2ObqcikaI42N6LuxdP4/ZNSDoVF69dQ0056idE8PqRbgxkIsxFwwq+4YLThaXPTfOm4Gh3DAOJdF+VESUbcU3Udnc/sQ+nMvkSebZwqqfInHkNN/USlVWstnAbTsZp9Mzcu+RiU7lur18eNm/e3NnU1LRdX+6rWyh+BI8QwoIZSWQ0kktG45gCjB0Uav2OilsofoQbWX7MPvfzmeZoHFOAsYORXr++cmKOJOw6KliEEEUmAE1fVVJBkD4/m77xRWYMhpbWdsSG8o9jWGdyxUw8YJGB9HdtASA2lEBLa7swaarpuUN5hCLAvZgULL31yRlYSQWsytInRvBqHr0ivoj0wxtbsa9dFrwgfFlBcIQiAKeECKNF3N7Tn832o4faB5BPigHyH5xiJ27w9Ft1eW0Oo1P7mQhpasPT+3O+DAFAlggk5H5JukmcMYJRPyKyWF/wbs6jV8QXPVmM1Y8iEYAgp726BoqFNGMVhfji4R2hBBu4ALzMwCKSCQRgX8nT918smWJ4MNIPEBujqEwe7NjCah9G/diRZSbTKpysEyP9RdcjC7wre8WydkcarmTkGavwkhDhJBOI34gbbpOTRD53Wt/tNk7mwq159Ir4IroeWfADaaYYETgxBeClo0LEcSna/0g7VMxgpJ9d3a2OzS5xxq02TubCrXl0optRHdH1yIJM2Fmpi2XtFit88Qaud5powTo/1jux9D/jIoqEb9wyJ/s59+zqwA7glYewd6ANHeMm4pH4ajyXWpz9eElDtaMxmZ2Bq6QYIP8MXHV6qszOlfNrLTlUeI40J8HsjeRfODGc9zZVUt6K0vN344zSiwqlGhFyHWKn5+bovqShOvtTXNWLEEB9YYsoUk7WeC0kAPp865efeRltm75omvFdOwarRx5avfV+j77BfEe0Hrwz8A3LZlieN7X+R6lfIzzpJdCSHlTUs23Nkq+V87X/OZjHQ8jqzCCLsdYjD6w3cEUiiA0lcGHjrryxAchxXKtrwmjNPtByED947Siz/4gioT+RAqXpL5M1V03FwgsmGO4Peud5RJFACMnayM1IoDwU/Rk4z2liBpYTSwsCoEQifEfRgR3A8+uA+PDDG6MhNMbvyW7iauQ9r5xiEoBv3j4v50FkbfhavUUcKlaccnYcSSLyS8pbUVrzLIg0/KWskHGQT63GyeOzDG+o6CERQCZAXLdbyxJBUjO/K6S9aFYeR4QMEy8ScilKbvpO3iZu1XGpggD42PQJ+P3RXlPnHa/9nVfXMzcPgO3MZkHrGIyH95namidflfPkb4/l2FKPu66ux8MrZ+eVG718GUGRABDCtJcipTdznjqsNWu0efOgfzHQP2cs5zlLV6eRQAEfOzGdOH3sIOs0+dZlQO+xvM/bUlVYPPRYfn0LsDImLxyVXjv+ROSXTW+GFOrJK68pq8FLt75kWU+eE0yLvaF1qJNO5n9QMRX40ls5RU7WnYguRnDLAarqIWJrI/ki4zFaI4V+hln6qNdz3ZLr5Bm2A98SeQrtxMj219vG/HwK6WbXt9OHjbpeRjosZH2i5G8oAHC877itfkUezimEsXkDzLl2su6cbhRuOUBVPURsbSRfZDwjGYFSpE83Nm+tXC+fNyso+g280E6MbH8VdczPO+hEAOmf43tD6/Be6Z3pt/UDO6z3IYCKsJL9/5bWdkguOHucOP5aWtuxqHkPpjXuwqLmPcygPSLyaTzKLJ9cNtmWnjwnmBYdtIr9AWOunaw7EV2M4JYDVNVDxNZG8kXGY8W5WQjo+3Q6J3q5Xj5vVlD0GzgvWpgZZImkzx05IEDe5zkOv+s2AUqu4WM0hK2J1dmz1DrpJCTQ9FHL8+uEN3HRyH4A0JdhJKpnsqw3CavMLyv9a2WLRl4TkT/YtQw0peSUlcqlWL9gvWU9FZkdOU6Rc9fA1sRqxGgop05CLk3PtQ4ifSsSyVubYUVm68Koy2vPm0ur86bqIWJrnnxVjmzwLJmtPyt6q1g0fQK3jSIRGKjD1GfNVVMt9Q8grw+t3A3LZhjuL1pdvWRlFn00Qla0MC1YJqyMKPjGzbOxdNZkZkTAiCJh221zs58zI41NmgVE64GON4HBs4iFa/CPic/jmfjH8H3lnzBROpvbaSqRrnvNvUJjYkX2e6u9N+82SooCB9t78ev3uvOingHpN4utt86x5CTh9d99bghnBxKQCQEF8mwiGnmNJX9ObXl24weAcala3D5vLk4n30dfvA81ZTVovLIRyy9azpSj1Uv7MqVGQGRFjmtaMStnDfyR1uMYrcJscgTjST/6wzUYd8M25i0UXt9a2zStmIWlM/PXEFcXXV1ee95cWp03VY/970dw5ux4KJEOQBpk2ponX5VzwYQI/vfdrjynokjkP54tVf3fPXEWiYwzUCJpJ+6/3Hk5t03TillYNmsyXnu/OxsJU10TPH2ubZiEk+cGcaCtl6ljRJGQyLwcyYTgzqvr8deLpnHnRt2XtDpEFAmhEilrI7cigQJBNEJ30RQF++IfAZrY540iMIpsBn6PBYvaF0QODBBgZOBbJ2ZRgnM+zi0XhBdEFzdRDDoECBBgGL4g8rgBswhwrIhwvGBEb/atwv30X/PuE/9D7814snFXtiysSChVZJyOxXPulKoX/Pd9eApPvn4MSUohE4KrL6rEqb4hJhHn6X1H864tqYSR+Q+9lL1nq94R194VN7tbrL2nG1HS3+kxzXGVqntlRMm7G6slG9mxuz46nRrZr6c/bplQ9EDLwTx7th7tyY6FEOBjF03AB939ucQg5P+6Ee2TNb5dBzrx5wM/x/0lOzCFdKMTuSSwyoiC5XNqsOtAp+WIfqzIh6r9rJKwRDkDvDpabgLLlhFFwrjM+tfqtaShOid4mbqmaqPihDJW30b1jCIflioSBhMppHQkHi1JBxAjCwHIEgBpbxtOoApbhm7DvvJPeRPkaiwcodghZbDIAFo5K6S92Qe0N3Q+Huq/Ff+TWORY10XT0xuMdsHt+/AUk4Rwyfll+KA7Jkxy0hNbFDn9twkXwRBGRAW7kfdYMCMU2SFqmMGsT974WIQhPQmMBdGIfvo2PIKQ1aiI+vpGdQBxUpEb0JNoeH2b1eNFPnSiTw4MCIAvyx+3HV3Rt0QeN2CXSCBKonFK3NDLem/L9TllbpEQvIIXkfes9AN4ZyM7BBUeYUhPAhPpz6kNrc6Ntr6d6JFeQpREY1bPreeVaVsTAqBdUs+YjkZo9yK9KInGzY2DJauYN2+gcFEQjeR5ZSM7BBUeYUhPAhOR6dSGVudGW15s0S1FSTRm9dwm9eTAhADotu3GhBPTrpNNNLqaWyQBniw35XuBQjk3jeR5ZSM7BBUeYUglgVnpz6kNrc6NtlxLItPXGUlyjmiESq+fV6Z8EwKg23YbExu4HSIBiwxgRHSwQzZigUU44JEQFk2fYEiw0ENfV5GNCREicEo80ZNt7PQD2CNqOO2TNz4WYUglgRmBF9HPyIYsMpAKq3OjJ231MVL4qTraeaacQE+i4fVtVo9HtHKiTw4MCIBepForeiKPGzAiQPD+ZpEBjIgOLLJRWJFwXmkJBuIpSGTYOx8NK2heNQdV54VwqP1MliByJyeim0pC0Nf9lzsvx3/sPZIlEvBAkI4W99cfm5ZHJFk2a3KO3hFFgiLnRmlUdRe1kxW7a8k25wYSqIwoKC2RMZBIcQlFLLBs9LHpE9B9bjA7FkLSX3opilxiEEOeVYKKdnw/667Cu0MT0oQh9KMDVdgc/1zOLZRbL6/DsVOxrN15pA99H6p9BhOpPDKQEQlLRHc9aUuf4g5Iv5U/esd8PslKUzeiSBifWf968s7R7lh23bLWl9FYjIhBvHpGRKuwIiFFac6z9YVF03JIOur6MV0bGgIgHTyLE6hGU/xzeKP8U6bryQgBkWeUIiDXBPACwboqLgREnlGKgFwTwAsE68ofML2FQggpBfArAOMy9XdSSh8khEwD8BSACQB+D+BzlNL8YB0uQE/Q0GbL0Cc4KAvJUGQpS3R4dOa7mPX2t1DafxwdqYl4PHQX5i1f65jgoK9XEVZACNATixu2MQOPoMAjGrGynqiZTKY17hLWn5fdJaoZVzSiYCCeRH/mZ79KSNGSMtQyVY52biQCfPaq9DGRPtC/o+wlGeIEetvSTqTrNhlm2TFKMKBmc7JCaOF+Lr+a1SsWnoyt8dvxxLkruSQqFeoa1x6nOcl8zhqzdl60c6au5Xgy/1hOf0au6lM1+RDIhJ+gP3USqXgUg13LkDgzP6cfdQ2LkJe0z7s+WQdvfkRswCKxiWQ30j97j858F1e89x2h9eY1TI9QCCEEQBml9BwhRAGwF8B6AF8G8Cyl9ClCyP8FsJ9S+m9GsuwcofAIGrw0WlrwCBWb6Fosvvle2wQHXj0tvMpkw5Kv/yLpG0rkEDvs6O8lFk2fgN9+cDqPfGIrewmDOAElDNz4GDPLjkh2J32mJbM1wfr81tCv0aw8jpLkQLZMS+ZRJIIUIJTlRnRNsmA3o5Ue2s1Wqw8rsxJNKRjovCW7iRtBP+cihCyrmbBY9hMlkOmxQtqLR5THEdbsKbz15iZsH6HQNM5l/lQy/1EA1wLYmSl/AsBKl3TNwZOv51+KB8w3bwC4v2RHzuYNABEyhPvwFLbtPsxss2334bxNrT+ezKvPqmfWxgxmMnnyV86vxauN1+JI83KUjSvJe1jt6O8lXn3vFHNDiaeoZZvhlYdyN28g/fcrD+VV3bb7sNBGFk/m6mG2Jlif34encjZvIL327i9JhxyOp6jh5g0Mr33RNcmC6JjNUDauJLthavUZV707Z/MGACLFMa56t5Bc/ZzznvecNklr64Rlv3iSWt68gfSeEtbtKbz1VggInYETQmRCyJsAPgLwMoD3APRQStV7Rm0AmF+HhJC1hJB9hJB9XV1dlhV0cuneiFDhhOBgVM9qHbfru6n/SMCyXhzihNMsO1YILazPnZB5VKhr3wmhxq155tmDl+2HV24mW/R5H6mMOFayOhUCQhs4pTRJKZ0HoA7AlQAuZVXjtH9p+VYAACAASURBVN1OKV1IKV1YXW09i7uTS/dGhAonBAejelbruF3fTf1HApb1shAZ0m4WFTObsj53QuZRoa59Jw5Ft+aZZw9eth9euZls0ed9pDLiWMnqVAhYuoVCKe0B8AsAVwOIEkJUJ2gdgA53VUuDR9AQIaDwCBWP4g7bBAejemZtzGA3U46ZDDv6e4lF0ycwySe2spcwiBP9GIf1XTfmpXwTze6kj7BoZlPW54/ijnS2Hw20ZB5FIqYkLHXti84pC3YzWhn1pdWHle2HphQMdi0Tkq2fcxFCllkETD1Y9hMlkOmxNbEa/bo9BUqYmdWpEDDdwAkh1YSQaOb/wwA+CeBtAD8HcGum2ucB/NgLBR9eORt3XV2f/WaWCcFdV9fjm6vnZYPqaKehLCSnb04AeKP8Uzh0+cOIhWuQAkFbqgpblXu5DkwgfZ685ZbZqI2GQZD2nrOcRfp60bCCyohi2MYMWpnqWJGRd9fV9aY6OdFf24e2b+24KiMKwsrwkqmMKLjr6npENZRrtYw1NxJJO+Z++MVrsO3WuaiMDLeLhhXrDkwg7Ti68TGgYiooCNppFb4ydDd+nFqcl/Jt5fzavH71qIwoeQ4yM5uyPl98870ouek76Yz3IIiFa7BVuRfPpxajNhrGttvm4p9vY+uirnH1ForonLLAG7N2XrRzJrKWtfokz8xHuPcOhEkVQIHUUDTHgan2o64vsznXP+8SATRLjjk/IjbQ22/brXOx7ba5putf/+y9Uf4pvHX5w9l5RcVUzx2YRhC5hTIHaSeljPSGv4NS+hAh5CIMXyNsBXAXpXTQSFZA5AngJUQi7AUI4EfYjkZIKT0AIO8+EKX0faTPwwMEKAoUW/S8AAG8xqgJJ+uE6OA3HUZbP3lgEHNakotMdZkSDTPfwO04sUTGvnnPf+GZI99DSj4Nmohi8KNlmCR9zDGJy4hs4vYcFMNzM1JgjV2fJUtPqCo2jIpYKE6IDn7TYbT1kwcGMSchl6Ixfg92Dn3MUBe3dBaRs3nPf+HpD7/FJLAo/Qtd6ZNFNnFzDorhuRkpsMbOIwfexQkyV0iM6lgoTogOftNhtPWTBwYxpyQ5gPvwlKkuTpx9WoiM/Zkj3+MSWNwicbHIJm7OQTE8NyMF1th5vB4RctFIYVQcoRTD2edIZ6Xxaz95MMloYqbLyvm1jt8eRcaekk8zw9CqBBYvSVxekHO8kF/MsDLGYs6INSrewIshctpIZ6Xxaz95MMloUghdRMYuJSuZdVQCi5ckLi/IOV7IL2ZYGWMxZ8QaFRu4E6KDU7S0tmevr+mn2Qsd3BirqvO0xl15ZBdtP3oCiFUCBau/+Q+9hHmbX+L3zSDmJORSPIo78uTGhhJM3Z1CxMarpn2RS2CxS+JyIzOR1T714yRIJyvmrYvRAtbYeebXkotEnp1CYlQcoWiD7BTSm653hKgZSdTwmV7o4HSsep1VsotWdhb6X442fknq+9OGNGX2rRIiNLdQSq7bhMXJRfjZc4dyssScjsX5ujuAiI0fvPZzwB6wb6HcYnPeTfZvRyF3GdCOUx/613BdjALw5tjoFoqlZ6dAGBW3UEYKfiSOiOrs1th4cuzI9KO9ReGmndzsfzTY1i2MpI1G9S2UkYIfnUBOoxV64ZwTlelHe4uikJEFrcgeDbZ1C8VoI18eofDIB1ZJCS2t7fjqswcQy6T7IABKpOHsHxIBbiB78dXQ05iEkyC67Bs84khFWMGi5j0FIWSYkT+iEQWUAr398WzWINaPLq1Tx+hcT+/80fevz1by+fGr8J/njAm7FMCd3/sNPujuz9NZOybeb0UK4MLGXXlJB1jZVqzanyXHKKsML6OSfo3qP68IK8wkwka2N9JTfxyggne0Z9T/pf/wk5wsTPqMOLayFRk8ryLPsdU+v7L0YsyuTGJgIDdGe2wogTP9CSRTFLJEUB4uQSTE3hb/feUUJBh3DUskgrfffpvZxipKS0tRV1cHReHH69HCd0coPPLBqstr8cwb7cKkhJbWdnx5x5uGiSFYGX202TeY5AuJAAQ5QfRZZW4QJkT7N4M+u8yGp/czg93rs6fo+2dlK2GRcKxCkYnweBSJ4PYrp+atBT1E7C+atUi1CwBufd4azcqQCZIpyl2PRtmKrJBSVF20Y7eatUebEcdOtiKj51XkObbT56ZPVOHa2RfggimTQDK3Sk7HhtB+uh8pzR4oEYLayjAqI7qIgzbqWwWlFN3d3Th79iymTZuW89moOULhkQ+efP2YJVLCtt2HTbP6sDL6aLNvsIgj40vzM+LEU1QoS45VMMkfjL6MIBOS83Bs232Ym6lkfGlJzgai75+VraQkOYCHyp7J2sjOjSwr44mnKHMt6CFif9GsRWpWGaP6vDWalZGkhj5ive3N9DRa2/qxW83ao82IYydbkdHzKvIc2+mzrrwE/SSc3bwB4ETvQM5mDAApSnGiN/ctXUVlJITayjBCcnrbDMmSa5s3ABBCMHHixLxfCUbw3REK77yJd9neybmVSPYNPXFkWuMuU7lWdPCyPZBesFr9jWT26JLv6uvy7BXpP45Xm9JOHiv2sQu3srq4Ta4x08voY73trfZt1MZJezvZigC+LUSeYzt9EpC8F5MhRuJmo3IgvYm7tWGzQCy+4fjuDZx3Dsi7bO+ErGAn+0YhCRluEC6sZOoxqytir0KQRNzK6mJ1Ls3qm+ll9LmVeRGBSMYhkfZ2shUB/LGKPMd2+1TfnHl/m5UXI3yjqRlhZs1VUy0RXDYsm8G8uF9S3oqy6c0Y39CIlfUT8WykPLeCSfYNZvYPieSRYtwgZDjNqqPXoaW1HX2DCWZdLYnngZaDmL7xxTwH7tbEagzRXH2GION30/8+R2eri85KRhlFIsy1oIdKWDEiFonaV80qY1Sft0a1CJUQ5pqUJYK+wQSXPGJ1HRAASxqG0xtaba+uBd56MctWZPS8ijzHVjMkrZD2YjI5hRn0PcQ7DuJoWxve6TyD80pLIOm+MCRCMKkiN5MSC6djQ3in8wwOtPXgnc4zOB0bMixX8dOf/hQzZszAxRdfjObmZtN+zCA3NTU5FiKK7du3N61du9ZyO9UpcUpjDG2mj003zsS9Sy5GXWUYB9t7cW4gkS3nnRs21JTjgoll+NUfP8r+tFLKW1Fa8yykkhgIAZJyAr+KlKE8UYrZ8T6QiqnAp5sNs2801JTn6dG0YhaWzpwsrJso1L5ee78bA4ncn32qfSojCkpLZAwmUoiGFYRDMgbjqTwdVBufYzyQlREFX785fU7+QMtB/OC1o8zz2mvKjuPj2AcJw7okqYzHOi5BLNqAhpryrN1/+cePsh59iQAfmz4BKQqcG0jk6Kza79OXTc5pw0JEkfDIrXOZa+GmeVPQfW4IZwcSOYSVgXgqa7uzAwn88o9dqKsMZ3VlyTl2KoaBzK2MaFjBNzI+BG39swMJyIRkSV36NXp2IAGJ5N6sSaQoSiSC0hIpuybLQjJSKYpY5kxXr6N2HahyRfDuiXPMcZ4dSOT4KcpCMkokkrW7uhYAMNdLZUTBP668LLuuWDY0el5FnmOeTFaf1w79Ao+Evo8zF69EdbQMMlIYj34MpGT0JkpQGVGQTFEkKUVIllATTZ9pt7S24+4n9uHhF/6Ap/e1YWJZKGtv1Zmp2iRJKc4NJBBPpvDR2cG8cqVEQliRkUwm8ZnPfAa7d+/Gxo0bsW7dOnz84x+HPlfwyZMn88o2b97c2dTUtF0/j764hVKoC/RLdy5FZ19nXnlNWQ1euvUl1/pxG27YR1TG9I0vMs8pZULw3vn3A735kdvaUlW4PfI91+bKyXhHmjAjoou2f6tjFRmfmQwR+Ib4863LgN5jeHvZDlx6wfnZ4iFagnfoVIRkKbsxqzC75fJO5xnmOTkBAcsVrfbxm9/8Bk1NTdi9ezcAYMuWLQCAjRs35tR/++23cemluXnjfX0LpVAX6I/3HbdUXixwwz6iMgydTwaRBN2cKyfjHWnCjEg/Vhx2ouVO63rRf0HAWZMK0r8cWBux2S0XnpOTd49Ird/e3o6pU4fjqtTV1aG93VksFV9s4IWKmja5bLKl8mKBG/YRlWHofDKIJOjmXDkZr1t13IDIOKyOtVBOdN9EMuSsyXjmAh7LYWn25cRzchJOMBu1Puu0w+qtEz18sYEXKtrg+gXrUSrnOjBK5VKsX7De1X7chhv2EZWhjcyWV37dJiR09ovREB7FHY6jGGqdd07Ga+awK1QUS54uVh12LJmFiGo4khFALYER3TJJCY7TSq7D0uzLaVJFKdP5OaFMMXSK1tXV4dix4SPGtrY2TJkyxfqYNPDFPfBCRRtcftFyAMC3f/9tHO87jsllk7F+wfpsebHCDfuIylAjs7Ejts1GCYDYTzahtP84OlIT8XjoLixevtbyXIlEfrMzXn1bFm2/UJHlRMZhdaxqeZMmcmNlRMHyOTW2Qgk40b0ooF446C8BBZBACTppJWJyOWorSpl3ujcsm8E8A1e/nNQ2J3oHMJRMISRLmJSRFRk3xCwHgCuuuALvvvsujhw5gtraWjz11FP47//+b0fD84UTM8DYg2+cZAF8AZZj0AheJXt+8cUXcd999yGZTOILX/gCvva1rwnpynNi+uINPMDYg2+cZAFGJdxIzcfC9ddfj+uvv941ecEG7hBefVO7CdHobvqf3fqoc3bk2gUv0qN6Dll0dj+wIycJhTZqpV1drbSzM39ewq1okFb78XodnI4NH5FUSX2YRE5DpnFADgHn1QCRCZ71zUKwgTtAMWbo0ENER1YEwtOxODbs3J9Tz6pcJzA6hyw6ux/YATy/Lh3oDEjfhX9+HQCgJbnIlq5Wxmhn/rwES/cfvHY0+7lb81XodaCNRhjFOUyiJyGrVweTQ8MciAJu4r64hVKsMLsvWgwQ0ZEXgVAbdc6OXCdgRXpUiRRFZ/dXHhrevFVkolba1dVKOzvz5yVEojh6FY3Ty3WgjV44mZyGTHQ2pyngbD4R0EsEb+AO4IdzWidkEdH2IuV2wDuHLDq7c8gi6G1Dx4A9Xa2M0c78eQmnGZac9uPVmLUEHpUIlIfkELvcIwRv4A7gBzKDE7KIaHuRcjdRdHbnRaesqLOtq5V2bkcqdArRPr2KxunVmLUEnjjv3Vf2LtQsC8EG7gB+IDOIkkVY5A9ZIoaEkZEae9HZnUEWUaNW2tXVSjve/GkjSBYSItENvYrG6eU60BJ4jtNKJKnO5kRKOzILiOAIxQH8QGYQJYvs+/BUjqMJMP52H8mxF53dVbII4xbKykwVq7paGSOPvDNSt1BYuntxC6XQ60BL4OlJjkcJIZZuoRw7dgx/+Zd/iePHj0OSJKxduxbr1ztjeQdEngAAAuJMgNENq0Qeo2uhdtHZ2YnOzk4sWLAAZ8+exeWXX46WlhbMnDnTVFdfRyMM4D2KzjEYIMBIQb0W2nsMAB2+FnpghyOxNTU1WLBgAQDgvPPOw6WXXuo4GmFwhCKIoiOOuAwz4kyh4Qd7+0HHADZgcC3U6Vu4ig8++ACtra246qqrHMkJ3sAFoBIG2nv6QTFMGNCntvIziskx6Ad7+0HHADZhcC3UDZw7dw6rVq3Co48+ivLycvMGBgg2cAEUHXHEAxgRZwoNP9jbDzoGsAmDa6FOEY/HsWrVKtx555245ZZbHMsLjlAEMFbOh70K4GMVfrC3H3QMYBPXbcoNjQCYJjMXAaUUd999Ny699FJ8+ctfdqhkGsEbuACKjjgyyuEHe/tBxwA2MWc1cONjQMVUACT9742POT7/fvXVV/Ff//Vf2LNnD+bNm4d58+bhxRdfdCTT9A2cEDIVwP8HYDKAFIDtlNJvE0ImAPgRgAsBfABgNaX0tCNtLMINJ5KIDLMA727CK8dYsTrcWHoV0t5Woerb3tOfk90eKB4d7aAQERPdbOs55qzO27C1kQj1yRpEsHjxYmZaNScQeQNPAPg/lNJLAVwN4O8IITMBNAJ4hVJ6CYBXMn8XDG44kURlFOp82CvHWLE63Hh6ASia83ievkB681a5eMWiox3YXR9O1lWxrkke1EiEajyUoWQK7af7cTpW2Ngnepi+gVNKOwF0Zv7/LCHkbQC1AG4C8IlMtScA/ALAVzzRkgEjJ5LoQ2RFRiHOh90YUyHlOoWRXq82Xlt0myFLXwr/k53srg8n66pY1yQP2kiEKlKU4kTvgKW3cLdh6QycEHIhgPkAXgcwKbO5q5v8+Zw2awkh+wgh+7q6upxpq4EbTqRic0R5pU+xjdOs/5HWiwe/6SsKu+NyYg+/2VIbiVCkvFAQ3sAJIeMBPAPgPkrpGdF2lNLtlNKFlNKF1dXVdnRkwg0nUrE5orzSp9jGadb/SOvFg9/0FUUhIia62XYkoI1EKFJeKAj1TghRkN68f0gpfTZTfIIQUpP5vAbAR96oyIYbxJNiIq94qY8VuS2t7VjUvAfTGndhUfMeT88ki83+ZvCbvqIoRMREN9uOBLSRCFVIhGBSRekIaZSGyC0UAuD7AN6mlH5T89FzAD4PoDnz74890ZADNyKRFVtUO6/0EZVb6BRVxWZ/M/hNX1HYHZcTe/jNltpIhHZvoXgB02iEhJDFAP4XwEGkrxECwFeRPgffAaAewFEAt1FKTxnJCqIRFjeCiIQBRissRyP0AF/4whfwwgsv4Pzzz8dbb73FredqNEJK6V5KKaGUzqGUzsv89yKltJtSeh2l9JLMv4abd4Dih98cSwECeIVd7+/C0p1LMeeJOVi6cyl2vb/Lscy/+qu/wk9/+lMXtBvGqKTS/+6572Lq77fhfNqFj0g1ji3YgCtW/I0hccBNUoGZLLcISPoA/svn1KDkrZ24Z+gHmCJ1o1c5H9+ma/DEuSsRjSigFOjtj3P75EUkrAgrWNS8x7Ofuix7AP75ee0VvCC6iMrU1/MiIcNIjs8Iu97fhQd/3YTB5AAAoLOvEw/+ugkdp/tx1aRP5hyfWCH3/MVf/AU++OADR+PTY9QldPjdc9/FZW88gDAZvmDfT0N4/oJGPHhkVh67b8stswGAyfyzQ8zQnyPrZZl9LtrHhqf352UiXyHtRbPyOCKascdoCI3xe/BcanFOXVafLN0UiQAkneHcrr5mYyl0n36AG+vErkxWPT0KpYtbMmeUnhE+Qvnk05/CidjxvPKq0kn49qKdANIOzMqIgtOxeM79cIkQ1FaGuZv4Bx98gBtuuKFwRyh+w9Tfb8vZvAEgTIaw6MN/5RIH3IwsZybLjb627T6ct3kDwP0lO3I2bwCIkCHcX5IfiJ7VJ4txOr60JGcjtaOvEVj2iKeop336AV5EOxSVyaqnR6F0GQmZH8VOMMtPDgxftEtRilN9cS65p1AYdUco59OuYX6zBjXoZtY3Ot+1c/Zrdo7sJQFpCjnJKRcfu55xOq2Rffbn1rm4G+MejfDCHyEqU7SPQugyEjInlp6PkwP5m3hVaS5XkYJ9elFIcs+oewP/iLDJQp2YyCyfEg27Siowk+UlAamDVnHK+WO325dbhAs3xj0a4YXdRWWK9lEIXUZC5mcv/luEpHE5ZSFpHFZftDanjLDeFFFYcs+o28CPLdiAfpp7/tRPQ3j1gnu5xAE3SQVmstwiIClS/uLZmliNmG7sMRrC1kR+GMxiIVyw5CsSgSLnjq+YSR5ewIndeWQsUZmseno4nQ8v1pVbMm+9dAW+eOlXUFU6CQBBVekk3NNwPxbVLM3WkQjBhDLFErlnzZo1uOaaa3D48GHU1dXh+9//viW9WBh1RyhXrPgb/A7I3EI5iY9IFY5dvgGrV/wNQiYeajc84mYEBTcJSPpbKOVzPoutb4XybqE8P3glKgVuodgZj1Pw5HvZpx9g1+4iZCwzmax6bt9C8WJdGcl8+23h6B+ojIRw+8yb8InaZdnbJeeVluDsQCLvtklknPgtlCeffNL22HgYdbdQAgQYywjIWGwUA5FHFGP6FkqAAGMZARlrbGHUHaEEyEdRZz4J4Cp4ZCzVkVesa6EQelFKQTJn1k6z63gFqyciwRv4KIffMp8EcAYjR16xroVC6FVaWoru7m5QSos2uw6lFN3d3SgtFY9wGLyBj3L4LfNJAGcwcuQtat5TlGuhEGu0rq4ObW1t6OrqwvHeASQYRLiuYwSTRzg8bGlpKerq6oTrBxv4KEdwJjr2wEv/V6xroRB6KYqCadOmAQCub9zFpOAQAEeal7vWZyEQHKGMcvgt80kA71Csa6HQehWrHexg1L2BF8IZ4nYfbkRJfKDlIJ58/RiSlEImBGuumoqHV87GhmUz8gL8EABLGsTS27kVOVFkfBVhBYQAPTFrd9Xt6qKP0KjedW7v6YdMCJKUotYg+QVrTCL28nKNGslmrQWjzEybnz+E07E0zyAaVtC0YhYAscQgVsbH0gsA+gYTaGltt2+bAzuAVx4CetuAijrguk3AnNWW7FDskJuamgrW2fbt25vWrl1rXtEmVGfIqYwz4uxAAr/8YxfqKsNoqCkvyj6M5L1z/KxQXw+0HMQPXjua/VlIARxo68XJc4O4d8nFOH6mHwfbenP6fffEOVOd3RirlfENJFIYiKds92VVl4F4CgOJ4f4OtPXi7EACALK2ZOnBG9PxM/34zp4/GdrLyzVqJruhphx1lWEcbO/FuYEEaqNhbLpxJnMD3rBzP/qGhje4gUQKLx06jp+9cyJLHnNrfKperx/pzs6/2qdt2xzYATy/Dohl4gANngH+9DMgWo+GedcI2aGYsHnz5s6mpqbt+vJRReQpBInB7T6M5AEQ6mv6xheRZMyjTAje23K9bZ3dGKud8dnty64uItDqwZOjvrXbaevGON2SbdVObo3PVdt86zKg91h+ecVU4Ev8UK7FCh6RZ1QdoRTCGeJ2H3bk6T9jbRracrs6exk5sRAR79yUpW3Lk8ObB5G2bozTLdlO6jvRwVXb9LZZK/cpRpUTsxDOCbf7MJIn2pdM2FHR1HK7OnsZOdFofHb78lKWti1PDm8eRNq6MU63ZDup70QHV21TwbmKxyv3KXy1gfOirKnwOnKeF30YyRPta81VU5my1XK7Oou2M5oXq+OzqqMViETZE9GDN6Y1V001tZeXa9Qt2RuWzciLBgmkNwu1vKS8FWXTmzG+oRGk/uvZnJFOdHCqv3YdNvWtQkLW3elWwmlH5iiCb5yYIs4RUSeNE7jdh5E80b6ubZiEk+cGcaj9DCjSb4J3Xl2Ph1fOdqSzSDsnjjOe8wpI35S5/cqpuHfJxbbsKjKeyoiC0hIZg4kUaqNh3DRvCrrPDeHsQAIyIaAAc8y8Md275GJTe3m5Rt2S3VBTjvoJkZx5iYYVbFk1B0tnTsYb3a8AVU9DKomBEGAw1Ye97XtRO74WK2ZeblsHJ/rr1+GbQ7XoINVYHDkGJdGXPvv+dDMwJz+0sh/geydmEGWtOOG1ozOY2+LD0p1L0dnXmVdeU1aDl259aQQ0Gv1ryPfRCIuVRTbWUQyOzgCFxfG+/IS/RuWFwFhdQ765hcKLskYxfI0uqiOCXDgxjF+/dyp7p7csJOPmBbXYdaAzh6Bww9yavGD1gHFAe+3fKiGkpz9uSgBRYUQoUds90HIQP3z9KNQfSRFFwjdumWOJ5KOvw9Kbl+RBhIDD+/1m5HjSy60IK9m7xaIyjPRjjfmF/Z05fajEFNb8jETEPi0RK1TeivFTXkYcp5CKRxHvWoahM/Oza2rfh6dySFsXVUfwflcMSUpBCBAukdAfT5muiYVnXsbG0NOYhJPooBPxSHw1dtE/x5qrpmLhBRNyiDwEyB4plddXozf+Uf4gElFMa9yVs6605CxeuZVkFdt2H84hWqnPPG8dUqTzupolpdA/j+cG4tCe6oUVCVsyz56+bt9gAkNJ9vVRr9eOb45Q9JlGvIQip1cEK/O7FYQVGVtumc18gIzGElZkLKivwKvvncr7TCLAN1fPAwAmm0zbn1Wbaduz2qqfs/oWGTdPJ5a9jWTw5IQVGasur8Uzb7QLjVmRCLbdNpd5pm9kV7ehErGAtHOwtOZZEGn4y4amFAx03oLEmfmQJYKkhXXJWxOfSv4SzcrjiJDhCHwxGkJj/B48l1oMiQC8biKV+1Fa8yzidJCpox3YmW+nEF3PKiQAn726Xnh9aftwunZ4Ryi+2cCB3G9gv4B1BueEUKLKBMxJPnb6UdvbJeCYvXXw5FZGFERCJcJvvVbJNDzo52ckzlK1RKyy6c2QQj15dVJDUfS912hLPmtN7A2tQ510Mq9uW6oKi4ceM5VZPfkQKut+lj42SUQRO7HU9ubN0lMPp8+MUZ+AOaFMhdX1pfbhdO2MCiKPGmVtGieaWDGCdQbn9FxOlORjpx+1jZ0zRQKYLlRe+55YHK2bljI/syLH6sOllzMSZ6lanYmSv3kblYuAtSamkPzNO13eLSTz5PFZ+N199wOAa8+jFfKaW7Aq1+r6stOHFfjGiamFn6KGsXR1qr8oycdOP2obNwhGVuq4RTbhkWlE5YxEpDqtzjQeZdbhlYuAtSY6aBWzbgedaFumUxjJ8TIyoRXZVteX2odX8OUGziNkrJD2Ym9oHd4f91nsDa3DCmmvLfmKTKBI1idKj7AiY0lDdQ7J5YGWg4gNJRzJbe/pR2wowdRRjeAGpCMOWhmFljTBs3F7Tz9OnhvMK/eCrMEiCKll7T39eWPjkWl4UCSS16+Ifrve34WlO5dizhNzsHTn0iyJxUhvo3ItEWuwaxloSsmRR1MKBruWAQBki+tSq3tLa3t27W1NrEaM5qYQi9EQtibS96SNehEhJ1mF2fpxow9en1ZkjyuxZn+JALGhBJd86BS+IfJoob3wr5IubpT24pHQ45hIzoIQoJzEcG3JARxLVeEwrQeQvoVy+xVTcexULIegcOvCOnSfG8qSB5pWzMLSWZNzCAU3zZuCo92xbPQ6LcpCie5WRgAAGkNJREFUMspCJRhIpHIIINfPmYxn3mjPIbkcaOvNI61EFAmKTCw5TQfiKcgSQWmJlNNOjeB2/Ew/nnmjPeczAmDR9AlIUTCJLFrShGrj197vzhuz3olmhXRjJSKeniD0yjsn8PKhEzm3SdTHyYhMw5q7aFjBNxjOJTP9dr2/C02/bkLPYPpI41z8XJbE8meVf2YrUuG9Sy7OErGSg5OBeCXC53Uihf70LZQTNyKeuYWyecUsVJ0XyosuyYJ2XlS9zg6mN/DDtB7HaBXmykdQhn60p6qwOfE5PJdaDCD95RZWZMQztyv0djYiJ1VGFEgwvgQQDSsIh2QMxvPXHgtG61EU2rVvRJirjChIJlM5TlxFSn95DiZyx1QWkkEAMC6hAEjfgnEjwqbviTymKED0MasOLlHHi1VHihY8p4pIZDwRWBmDm04+K06rQpI1zEgsTiIVWoHVeXEj6qVb+nkl1wxe9Gvn0oAdPUaFE9MQBYg+ZtXBVYiIe2aRCJ32NRJRA63KKyRZw4zE4iRSoRVYnRc3ol5awUjIHYm2di4NuLlefXkGzkQBoo9ZdXCJOi+sOlK0MItEaFcnq/V59cwCkDnt12pdp5hcNtmw3EmkQiuwOi9eOaXN+i2k3JFoa8eZ6+Z6HT0b+HWb0tHGtHA5+pjVaGkizhErjhR9hDijCHgikfFEsGHZDFOHrpETcuOzB9He0w+K9M/0jc8eFNrEWfZgOZcLnQpr/YL1KNVFuSuVS7F+wXoAziIVWoGVtWWkl5Wol1b1Y60bRc53HFuVa8eZ6UW/dpy5bq9XXzoxmZg0C4jWAx1vAoNnPYk+ZjVaGqu+GvHOyJGipvVSEVEkbLttLpbOnCwcAU8kMp7omOsnRHKcR6rTluX81OLuJ/ZlnXYqEimKg+29uHvxNNN+9fqznMuFToX1Z5V/htrxtTjUfQh98T7UlNWg8cpGLL9oOVdvN+dDhZW1ZaSXlaiXVvXTr5vKiIKv3+yMlci6wECRvu2hHlKFFQkhzaUAt/u1EmnSaE6sYPQ7MQMUHXgEDwLgSPPyQqsTIIBv4ftohAH8h5EgxQQIMJZguoETQv6dEPIRIeQtTdkEQsjLhJB3M/9WeqtmgGJEMWRIChBgLEPkDfw/AXxaV9YI4BVK6SUAXsn8HWAMQcRBuXJ+LbbcMhu10TAI0vdfvYzqFyDAWIPQGTgh5EIAL1BKL8v8fRjAJyilnYSQGgC/oJSavlYFZ+CjB6M9A0qAAMUEt8/AJ1FKOwEg8+/5Bh2vJYTsI4Ts6+rqstldgGLDWM2AEiBAMcFzJyaldDuldCGldGF1dbXX3QUoEAIHZYAAIw+7VPoThJAazREKI7/SyEI03ZbbKY9GIh2XE9jVd8OyGczMNW46KP1mywDeIVgLbNjdwJ8D8HkAzZl/f+yaRi5An35JdbDt+/BUTjoktRyAK4uB169b8t2GE33Vz716qPxmywDeIVgLfJg6MQkhTwL4BIAqACcAPAigBcAOAPUAjgK4jVKan8BRh0I5MQsVEU6032J17BWzvsWsW4DCIlgLDqIRUkrXcD66zrFWHqFQEeFE5RSrY6+Y9S1m3QIUFsFa4MM34WT1Z2BLGqrxwv7ObHD/yoiCB2+chZXzazElGrYUM1giBNMad2WPAQBrRwOqbrzfMlrHXsHP8g7sAF55KB1Wt6IOuGQp8O5LQG8bXi2diOah1dkg/iqiEYWpJ8C3S0trO5qeO5STbCEaVtC0Yha3jnbOtPZ5c9d2/G/oB5hCTqKDVmFrYlhHUVtqP4tGFFAK9PbHDW3u1G/iZb1oRMFAPIn++HBcEb3t7PQhClFbW3leRMa/+flD3OeKArj0H36CLbfMAYBswnP1l7ZZgm2n4/ayrSh8EQtFfwbGgyITbLt1LgAI1WfKkAhAkM1EAqSdczwCiplu2rasukayHePADuD5dUCc/2UWoyE0xu/J2cQlkj5u0mZUUeR0tCBtmao7AGx4ej8zA4siEWy7bS63jjpnqn32/s+/4iGyHREyHARL1fFl+eNCtgSM559lc568VZfX5vhNrLZ3s54eWttp4fY6s2prq88Lb/wbdu7PeQ6NoMiEWdercZvJc3sOfB0LZdvuw0KbcTxJsW334SwD0E4C0niK5i2E/ngS23YftqybnnnIqmsk2zFeechw8waACBnC/SU7cspSND8dVjxJ88pU3bftPsxNnxVPUcM66pwBafvch6dyNm9Vx6+Gnha2pdl6YdmcJ+/J148JzZno3Dqpp4fWdnb6EIVVW1t9XnjjF928AXDrejVuL9tagS+OUOxkZ1k5vxZf+tGbnuvAKydAnoOl4Gd5gtmIppBu212I6G5WR5s1Zsq4k8w6k3Ey583F7SxITv0movo4rWfWzkofonAzm4/b4xdBIcftRlsr8MUbuN3sLG6SStzIxlNw8otgNqIOOtF2FyLZhMzqaLPGdNAqdiXdWOxkmDFq7zSTjujcOq1n1s5KH6JwM5uP2+MXgRfj9rKtFfhiAxfNwqHPumEne4ciEWbmGz1BRY3E197TD/0jziO0FDw6HytLkQ4xGsLWRG7SC1bmG6NsOEZZexSJGNbRztmGZTPwKO5AjIZy6iTk0rzMSixbEgBLGqpN551lc6eZdETn1kk9PXhZZtxeZ25m87Eyfv1zaAReXa/G7WVbK/BFRh5epouj3THDbB8iGTL0fzetmMXMfMNyMGmzzajLxyjrhheZTwzBylI0+zag7yQweBaxcA224q/xo8FrsplNeJlvjLLhsLKvAOlbKN/InFuLZGhpqClHLNqAZ96TcHHiTxhP+tEfrsG4G7blZVZqqCnH8TP9ONjWm1P+7olz+OSlk/DJSydlda2MKCgtkQ0zCDnNpCM6t3brVUYUEKQzGrFsZ6cPUbiZzcfK+OsnRPD6kW4MZG7esLbosCLhnzTZqrRZerwct5dtWQgy8riIgFhQHAjmIcBYga9voRQbAmJBcSCYhwBjHb64hVIIWLl0zyMKueWgsEsAKCRJiEWs+vk7XQUNEub1PBQbCkoC0xPArttkmCB8rAWbEiGlFQLBGzjEssto4aWDwqouTtu5peMPXjvqWd+8sS1pqB4zKdsKOb9ZAljvMQA0/e/z69LlI61bEaCltR0bnt6fwzo+HYtjw879BR9zsIHD+qV7L1OF2SUAFJIkJEIycbNv3th+/k7XmEnZVlASGIsAFu9Pl4+0bkUAEVJaoRAcocDeWerK+bWebBR2z3ULeR7shGTiZn8dPf2ezUOxoaDn/TwCGKd8rPki7BCYvELwBo7iyi5jV5dCjsEJycTN/kbrWTcLBbUBjwDGKR9r8yNCSisUgg0cI0Cw8UAX0XYqAWla4y4sat5j68xOhGTipv2KaX5GCgW1AYsApoTzyFQjolsRQISUVigERyjwPrtMIXQRaedWZhNWX17eQimm+RkpFNQG6m0TwVsoY21+1HEVwy2UgMgzhhAQXwIE8CcCIk+AMedsChBgtCM4QhlDGC3El7FGGhkLCObUHoI38DGE0eBsGmukkbGAYE7tI9jAxxC8JCAVCmONNDIWEMypfQRHKGMMfie+BOf4ow/BnNpH8AYewFcYa6SRsYBgTu3DN2/gLa3t2Pz8IZyOpe9dhhUJpYqMnljcW6fHgR04/fwDqBg6gQ5ahX9K3o7xV6zBwytnWxb1QMtBPPn6MSQphUwI1lw1lSuH59R5oOUgfvjaUWgvf0bDCppWzMq7823FKeRGfSD9c7i9px8yIUhSilqX52bDshnMbN8swhJvPHZ0V9u09/SDEEC9fau9/6tfo0D+3Gj7joRkxIaSoIDQetDfO55Zcx5+/d4p07WQxYEdiP1kE0r7j6MjNRGPh+7CvOVrhTKsi9z5t2pz9TOhObUQHVHta+GZl7Ex9DQmoQuEyABNppOamERWtAWOflaeeTvwxT3wltZ2bNi53zBLdViR3T/PPbADQ//z/yBEB7NFMRpCY/welF/5WUsT8UDLQfzgtaN55XddXZ8nR0+4AdLjW1BfgVffO8WUr0gE226bm32QWO159nGjviITgJHN3kyWHZh92RiNB0C+7hIBCDuzeViRseryWjzzRjs3gJciE9x+xVT86HfHmDLUuWH1rQdvPWx4ej/Ttkx9NGshiwM7kPjx36MkOZAtitEQNtG1WHzzvdy5YdlSD56NjGyuXxOGc6pGR9QG2FLCwI2P5W3Eqr6fSv4SzcrjiJAh5IHT1jY4+u2o2YD7/9iQV501x2bg3QP3xQbOI6Do4Toh5VuXZUJq5qItVYWPx7+D97ZcLyxq+sYXmRnOZULy5IiOVw91/FYJO27VF9GtEDAaDwDLuqtv5E7qiPbt1nrIs7fBWr498j3u3Ij2zRu/0biF1wRHd1RMBb70FlPfvaF1qJNO8mUy2toGR792WoVFg4/llbPm2Ay8DdwXRyiFjn6XBSf62hTSbfpA68Grzyq3Ow61nVWnkFvlIroVAm47xUTm2qyOaN9urYe8NgZr2Y3oerzxuxK5z0J0RFXmFGKweRvJtAOOrBp0M8ut7h1G8IUTs9DR77LgRF/roBMhE/GM2QC49VnldsehtrPqFHKrXES3QsBIbzt6iMy1WR3Rvt1aD3ltDNayG9H1eOM3GrfwuCxER1RldtAqezLtgCOrExOZ5Vb3DiP44g18w7IZpmfgQPpn2oWNu1AWkqHIEnr7+Q5O1pnbvg9P5Tgctlzy11h55pG8M/CtidVIUopFzXuEHXRrrprKPAMPlZAsYUHvANPC7AxcArJOH5ZTCABiQwm0tLbnOZwqwgoUmeTY14jgw5JvdAauyAR9gwlMa9xl2eEs4lzVjyWeTOXJ0Y6HZRtZIkhydL/9iqlCZ+BP/vYYW4ZEDPvWYs1VU/PKNiybYekMHEg/C4ua92BJQzVe2N+Jvxi8Me9MOEZDeBR3GBK59M/eCmkv7i/ZgSnkJDpoFbYmVuMn5M/TPoDfHsvRUZEIljRUY9eBzjy5ikQQG0qvic+P/y3uV36ESP/xPAdlS2s73uxbhfvpv+aeZ3OiI6prc2tiNfcMPEkU/GPfKjxhYT3q1xghyF6geHTm3+OKgw/mnIH3YxxaKr8AHM+XxZpju5CbmppcE2aG7du3N61du9Zyu4aactRPiOD1I90YiKcfzrAi4bzSkuzfWsSTFAOJdPnZgQR++ccu1FWG0VBTDmDY0XEqNpSt8/LbJ7D/WG/Wo08BvNxdhakXNWBK7B2MS8bQTquwOfE5PJdazJXNw7UNk3Dy3CDeau/NuTWQSFG88vYJ7P7DCcSG2A92bTSMTTfOxNeWz8TJc4M40NabV6dEJlg6czIaasrRUFOOusowXnu/O2sHABiIp/DLP3bh+Jl+fGfPn7LjH0ikIBOCirCCwXgq2x9vUavyD7b34txAArXRMJpWzMLSWZNxsL0XZwcSkAkBRfq2xFAihVhm07JiM9Y8mc3lQCKV90UfDSt4eOVlWDm/Fg015Th+ph8HdTYsIQRhRc5rKxOCv/rYNHzy0knZsWlfoCojCr5+82xMiYbxsz+cgH6PDSsSHrl1brZvrd3KQjISmf5kQnAnx7mlrn/9fJrh7EACB9p6MZBI4TCtxzFahdnkCMajH+20Ct8J3Y0rV/yt4eb1zvGzePlQelwrpL1oVh7HROksCAHKSQwfl/ajjVYjNGU2DnWcyRk/IQR/aD+DPt26DisSUgD6hpJYIe3Fg/guIonMfAyeAf70MyBaj5aOKDY+exD7Bqbk6N4fqYGyfCvTCanaeGdbBd7uj+Ia+R2MwxC077wJSvDjwfk4TOuF1iNrjan7ztmBBF44Xonzp16CaM+hrG03xz+HpwauwVXTKtHRM5C9acSbYzNs3ry5s6mpabu+3BdOTCPYcXBacQppHQ5uRPOz6pBiyRbVg1fPyOHktqPRic1E2orYsxB2KWSkR6v6syCql7YvnmNQdeqL9q3Vk+tsrJiKRYOPObepgfN28dCwg9FIpsga8/qZ8rUT0wh2HJxWnELaSXHDOWbVIcWqL6oHr54dh5NdOLGZSFs7crywSzGktLPiHLPz3PAcg1ad+tq6XGdjbxs6BlywqYHzVlSmSH+FfKa08IUT0wh2HJxWnEJah4MbTj2rDilWfVE93OjLCljZfpzYzLDtgR3Aty7De6V3Ym9oHVZIe4Xl8OQaOeLs6LpC2ovflK4HmqLpN0FOVnersKq/FRlG9XiOQatOfW1drrOxos4dJ7qB81ZUZjSimHbjZO04ge83cF56Iy30qY5YUflkjgytw8GNaH4sGYpEmP1rnV9mMlh6iKQ+M2pvBbyIcksaqm3bjDfOR2e+myZO9B6DBIo66SSalceZm7ioXcKKjDVXTXVN1xXSXjyiPI7J6AJA0z/jn1/nyiZuRX8WrKT+0va1NbEaMRrK+Vx1hLL6VmSS92zq9WTJVB2UrkTPZKSH689cRBCR2dLajnMDCcMunK4dJ/CFE9MIIg6e8lIFj94xP6eN3gm3ecUsVJ0XwqH2M1yHA6udkbOPpy/LAbhs1uQcJ200rOAbHPaiqB7aemcNFqGdcehx9xP7sk4eFYkURfe5IWy6caYtm/HGeV3r3wOx3J/ACkliNjmCZ0MrEA7Jhs5Yntx7l1xse371Mp8Y98+oJGdzK6USQMebwDX3msqzYxeW/jfNm4Kj3bHss6E6XUXnWtvXG/1T0BeegrnyEYxLxdCeGnaEsvrWOrZ5eqoyrxz3IZREX5pg8+lmYM5qV543TJoFROvTdh88C1RMxZuzNuI/zlwhJPPuJ/ZlwxdoQdLkXVfWjghGrRNTi2mNu8AaDQFwpHm5Z/36AV7bpqC2b4oCvN6aetztyy78oGMAUxTLnjImUqoFUc348No2BbW9BWLHiMEPOgYwRbHvKY42cELIpwkhhwkhfyKENLqllF2MhowzXsFr2xTU9oxzTR6xA2A7Vz2HRR3HIkZkXiyi2PcU29cICSEygH8B8CkAbQB+Rwh5jlL6B7eUswr1vCnIrZcPr21TUNurBA6B8KL6aHqqc1WrsyewoONYxIjNi0UU+55i+wycEHINgCZK6bLM3xsBgFK6hdfG6zPwAAH0KCTBJoA4gnmxBi/OwGsBaClObZkyfcdrCSH7CCH7urq6HHQXIIB1BOm6ihPBvLgDJxs46+J03us8pXQ7pXQhpXRhdXW1g+4CBLCOYndCjVUE8+IOnGzgbQC0YbXqAHQ4UydAAHdR7E6osYpgXtyBk1govwNwCSFkGoB2AHcA+KwrWgUI4BKK3Qk1VhHMiztwROQhhFwP4FEAMoB/p5R+3ah+4MQMECBAAOvwJBohpfRFAC86kREgQIAAAexhVDExAwQIEGAsIdjAAwQIEMCnCDbwAAECBPApgg08QIAAAXyKgoaTJYR0AfjQZvMqAJz8S6MWwZjHBoIxjw04GfMFlNI8JmRBN3AnIITsY12jGc0Ixjw2EIx5bMCLMQdHKAECBAjgUwQbeIAAAQL4FH7awPPywY0BBGMeGwjGPDbg+ph9cwYeIECAAAFy4ac38AABAgQIoEGwgQcIECCAT+GLDbzYkie7AULIVELIzwkhbxNCDhFC1mfKJxBCXiaEvJv5tzJTTgghj2VscIAQsmBkR2AfhBCZENJKCHkh8/c0QsjrmTH/iBASypSPy/z9p8znF46k3nZBCIkSQnYSQt7JzPc1o32eCSFfyqzrtwghTxJCSkfbPBNC/p0Q8hEh5C1NmeV5JYR8PlP/XULI563oUPQbuCZ58mcAzASwhhAyc2S1cgUJAP+HUnopgKsB/F1mXI0AXqGUXgLglczfQHr8l2T+Wwvg3wqvsmtYD+Btzd+PAPhWZsynAdydKb8bwGlK6cUAvpWp50d8G8BPKaUNAOYiPfZRO8+EkFoA6wAspJRehnS46Tsw+ub5PwF8WldmaV4JIRMAPAjgKgBXAnhQ3fSFQCkt6v8AXANgt+bvjQA2jrReHozzxwA+BeAwgJpMWQ2Aw5n//y6ANZr62Xp++g/pzE2vALgWwAtIp+Y7CaBEP98AdgO4JvP/JZl6ZKTHYHG85QCO6PUezfOM4Xy5EzLz9gKAZaNxngFcCOAtu/MKYA2A72rKc+qZ/Vf0b+AQTJ7sZ2R+Ms4H8DqASZTSTgDI/Ht+ptposcOjAO4HkMr8PRFAD6U0kflbO67smDOf92bq+wkXAegC8B+ZY6PHCSFlGMXzTCltB/BPAI4C6ER63t7A6J5nFVbn1dF8+2EDF0qe7FcQQsYDeAbAfZTSM0ZVGWW+sgMh5AYAH1FK39AWM6pSgc/8ghIACwD8G6V0PoA+DP+sZsH3Y84cAdwEYBqAKQDKkD5C0GM0zbMZeGN0NHY/bOCjNnkyIURBevP+IaX02UzxCUJITebzGgAfZcpHgx0WAVjx/7d3P60QRWEcx7/Pimz8WVvIK7CULBRZWFsoRXgVsvIG5A1YWVAkycYCa7IQQowoFkopa4vH4jxXkyyMkdu5/T41zdxzz+I880xP95xzp2tmD8A6aRllGegws+LpUPVxfcYc59uB1/8c8B94Ap7c/SiON0kFvcp5HgHu3f3F3d+BLWCAaue50Ghem8p3DgX88+HJsWs9AeyUPKammZkBK8CVuy/VndoBip3oadLaeNE+FbvZ/cBbMVXLhbvPu3u3u/eQ8njg7pPAITAe3b7GXHwX49E/qyszd38GHs2seNz6MHBJhfNMWjrpN7O2+J0XMVc2z3UazeseMGpmnTFzGY22nyl7E+CHGwVjwA1wByyUPZ4/immQNFU6A07jNUZa+9sHbuO9K/ob6W6cO+CctMNfehxNxD8E7MbnXuAYqAEbQEu0t8ZxLc73lj3uX8baB5xErreBzqrnGVgEroELYBVoqVqegTXSGv876Up67jd5BWYj9how08gY9Fd6EZFM5bCEIiIi31ABFxHJlAq4iEimVMBFRDKlAi4ikikVcBGRTKmAi4hk6gNoKGWb5CcQ8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# define dataset\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "df = df.head(1000)\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "for i in range(5):\n",
    "    print(X[i], y[i])\n",
    "\n",
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n",
    "# Neural Network Model using Keras (Tensorflow backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output shape:\n",
      " (54824, 11) (11748, 11) (11749, 11) (54824, 3) (11748, 3) (11749, 3)\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Model using Keras (Tensorflow backend)\n",
    "# model 1\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load and encode the dataset\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "# Mapping_Tier = {\"Basic\":0, \"Plus\":0.5, \"Premium\":1}\n",
    "# df[\"product_tier\"] = df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Convert label to categorical values\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Now scaling the dataset so that all the input features lie between 0 and 1 inclusive\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into train, validate and test\n",
    "# Can also use k-fold Cross-Validation - but it takes longer to process therefore I went with random split\n",
    "# Also to note: k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=0)\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "# Define the Neural Network Architecture \n",
    "model = Sequential([    \n",
    "                    Dense(32, activation='relu', input_dim = 11),    \n",
    "                    Dense(32, activation='relu'),    \n",
    "                    Dense(3, activation='softmax'),])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',            \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54824 samples, validate on 11748 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 0.1880 - accuracy: 0.9627 - val_loss: 0.1763 - val_accuracy: 0.9622\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.1739 - accuracy: 0.9628 - val_loss: 0.1752 - val_accuracy: 0.9622\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.1729 - accuracy: 0.9628 - val_loss: 0.1753 - val_accuracy: 0.9622\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.1718 - accuracy: 0.9628 - val_loss: 0.1742 - val_accuracy: 0.9622\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1714 - accuracy: 0.9628 - val_loss: 0.1740 - val_accuracy: 0.9622\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1711 - accuracy: 0.9628 - val_loss: 0.1746 - val_accuracy: 0.9622\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1709 - accuracy: 0.9628 - val_loss: 0.1732 - val_accuracy: 0.9622\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1705 - accuracy: 0.9628 - val_loss: 0.1770 - val_accuracy: 0.9622\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1703 - accuracy: 0.9628 - val_loss: 0.1743 - val_accuracy: 0.9622\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1699 - accuracy: 0.9628 - val_loss: 0.1741 - val_accuracy: 0.9622\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1699 - accuracy: 0.9628 - val_loss: 0.1738 - val_accuracy: 0.9622\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1695 - accuracy: 0.9628 - val_loss: 0.1740 - val_accuracy: 0.9622\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1694 - accuracy: 0.9628 - val_loss: 0.1742 - val_accuracy: 0.9622\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1691 - accuracy: 0.9628 - val_loss: 0.1726 - val_accuracy: 0.9622\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1686 - accuracy: 0.9628 - val_loss: 0.1760 - val_accuracy: 0.9622\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.1684 - accuracy: 0.9628 - val_loss: 0.1730 - val_accuracy: 0.9622\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.1682 - accuracy: 0.9628 - val_loss: 0.1727 - val_accuracy: 0.9622\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.1680 - accuracy: 0.9628 - val_loss: 0.1732 - val_accuracy: 0.9622\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.1678 - accuracy: 0.9628 - val_loss: 0.1739 - val_accuracy: 0.9622\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.1677 - accuracy: 0.9628 - val_loss: 0.1731 - val_accuracy: 0.9622\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.1670 - accuracy: 0.9628 - val_loss: 0.1736 - val_accuracy: 0.9622\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.1670 - accuracy: 0.9628 - val_loss: 0.1744 - val_accuracy: 0.9622\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.1666 - accuracy: 0.9628 - val_loss: 0.1725 - val_accuracy: 0.9622\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1664 - accuracy: 0.9628 - val_loss: 0.1721 - val_accuracy: 0.9622\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.1658 - accuracy: 0.9628 - val_loss: 0.1722 - val_accuracy: 0.9622\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.1659 - accuracy: 0.9628 - val_loss: 0.1744 - val_accuracy: 0.9622\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.1653 - accuracy: 0.9628 - val_loss: 0.1734 - val_accuracy: 0.9622\n",
      "Epoch 28/100\n",
      " - 3s - loss: 0.1648 - accuracy: 0.9627 - val_loss: 0.1726 - val_accuracy: 0.9622\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.1648 - accuracy: 0.9628 - val_loss: 0.1713 - val_accuracy: 0.9622\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.1645 - accuracy: 0.9628 - val_loss: 0.1707 - val_accuracy: 0.9622\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.1640 - accuracy: 0.9628 - val_loss: 0.1740 - val_accuracy: 0.9622\n",
      "Epoch 32/100\n",
      " - 4s - loss: 0.1640 - accuracy: 0.9628 - val_loss: 0.1714 - val_accuracy: 0.9622\n",
      "Epoch 33/100\n",
      " - 4s - loss: 0.1639 - accuracy: 0.9628 - val_loss: 0.1714 - val_accuracy: 0.9622\n",
      "Epoch 34/100\n",
      " - 4s - loss: 0.1635 - accuracy: 0.9628 - val_loss: 0.1736 - val_accuracy: 0.9622\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.1632 - accuracy: 0.9627 - val_loss: 0.1707 - val_accuracy: 0.9622\n",
      "Epoch 36/100\n",
      " - 4s - loss: 0.1634 - accuracy: 0.9627 - val_loss: 0.1713 - val_accuracy: 0.9622\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.1629 - accuracy: 0.9628 - val_loss: 0.1709 - val_accuracy: 0.9622\n",
      "Epoch 38/100\n",
      " - 4s - loss: 0.1631 - accuracy: 0.9627 - val_loss: 0.1710 - val_accuracy: 0.9622\n",
      "Epoch 39/100\n",
      " - 4s - loss: 0.1631 - accuracy: 0.9628 - val_loss: 0.1715 - val_accuracy: 0.9622\n",
      "Epoch 40/100\n",
      " - 4s - loss: 0.1626 - accuracy: 0.9627 - val_loss: 0.1705 - val_accuracy: 0.9622\n",
      "Epoch 41/100\n",
      " - 4s - loss: 0.1628 - accuracy: 0.9627 - val_loss: 0.1706 - val_accuracy: 0.9622\n",
      "Epoch 42/100\n",
      " - 4s - loss: 0.1624 - accuracy: 0.9628 - val_loss: 0.1693 - val_accuracy: 0.9622\n",
      "Epoch 43/100\n",
      " - 4s - loss: 0.1623 - accuracy: 0.9628 - val_loss: 0.1696 - val_accuracy: 0.9622\n",
      "Epoch 44/100\n",
      " - 4s - loss: 0.1623 - accuracy: 0.9628 - val_loss: 0.1714 - val_accuracy: 0.9622\n",
      "Epoch 45/100\n",
      " - 4s - loss: 0.1622 - accuracy: 0.9628 - val_loss: 0.1711 - val_accuracy: 0.9622\n",
      "Epoch 46/100\n",
      " - 4s - loss: 0.1622 - accuracy: 0.9627 - val_loss: 0.1710 - val_accuracy: 0.9622\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.1618 - accuracy: 0.9628 - val_loss: 0.1704 - val_accuracy: 0.9621\n",
      "Epoch 48/100\n",
      " - 4s - loss: 0.1616 - accuracy: 0.9628 - val_loss: 0.1721 - val_accuracy: 0.9622\n",
      "Epoch 49/100\n",
      " - 4s - loss: 0.1616 - accuracy: 0.9627 - val_loss: 0.1716 - val_accuracy: 0.9621\n",
      "Epoch 50/100\n",
      " - 4s - loss: 0.1614 - accuracy: 0.9627 - val_loss: 0.1702 - val_accuracy: 0.9622\n",
      "Epoch 51/100\n",
      " - 4s - loss: 0.1612 - accuracy: 0.9627 - val_loss: 0.1706 - val_accuracy: 0.9622\n",
      "Epoch 52/100\n",
      " - 4s - loss: 0.1614 - accuracy: 0.9628 - val_loss: 0.1709 - val_accuracy: 0.9622\n",
      "Epoch 53/100\n",
      " - 4s - loss: 0.1611 - accuracy: 0.9628 - val_loss: 0.1709 - val_accuracy: 0.9622\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.1609 - accuracy: 0.9628 - val_loss: 0.1703 - val_accuracy: 0.9623\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.1606 - accuracy: 0.9628 - val_loss: 0.1709 - val_accuracy: 0.9622\n",
      "Epoch 56/100\n",
      " - 4s - loss: 0.1610 - accuracy: 0.9629 - val_loss: 0.1705 - val_accuracy: 0.9622\n",
      "Epoch 57/100\n",
      " - 4s - loss: 0.1607 - accuracy: 0.9627 - val_loss: 0.1701 - val_accuracy: 0.9622\n",
      "Epoch 58/100\n",
      " - 4s - loss: 0.1607 - accuracy: 0.9629 - val_loss: 0.1717 - val_accuracy: 0.9622\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.1608 - accuracy: 0.9628 - val_loss: 0.1702 - val_accuracy: 0.9622\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.1607 - accuracy: 0.9628 - val_loss: 0.1726 - val_accuracy: 0.9622\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.1604 - accuracy: 0.9628 - val_loss: 0.1707 - val_accuracy: 0.9621\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.1604 - accuracy: 0.9628 - val_loss: 0.1718 - val_accuracy: 0.9621\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.1603 - accuracy: 0.9628 - val_loss: 0.1701 - val_accuracy: 0.9621\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.1601 - accuracy: 0.9628 - val_loss: 0.1699 - val_accuracy: 0.9625\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.1602 - accuracy: 0.9628 - val_loss: 0.1699 - val_accuracy: 0.9622\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.1598 - accuracy: 0.9628 - val_loss: 0.1708 - val_accuracy: 0.9623\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.1599 - accuracy: 0.9627 - val_loss: 0.1711 - val_accuracy: 0.9621\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.1599 - accuracy: 0.9629 - val_loss: 0.1738 - val_accuracy: 0.9623\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.1599 - accuracy: 0.9628 - val_loss: 0.1717 - val_accuracy: 0.9620\n",
      "Epoch 70/100\n",
      " - 4s - loss: 0.1598 - accuracy: 0.9628 - val_loss: 0.1710 - val_accuracy: 0.9622\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.1597 - accuracy: 0.9628 - val_loss: 0.1714 - val_accuracy: 0.9623\n",
      "Epoch 72/100\n",
      " - 4s - loss: 0.1597 - accuracy: 0.9630 - val_loss: 0.1704 - val_accuracy: 0.9622\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.1596 - accuracy: 0.9628 - val_loss: 0.1715 - val_accuracy: 0.9623\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.1594 - accuracy: 0.9629 - val_loss: 0.1727 - val_accuracy: 0.9624\n",
      "Epoch 75/100\n",
      " - 4s - loss: 0.1595 - accuracy: 0.9629 - val_loss: 0.1709 - val_accuracy: 0.9624\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.1591 - accuracy: 0.9629 - val_loss: 0.1717 - val_accuracy: 0.9621\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.1590 - accuracy: 0.9630 - val_loss: 0.1720 - val_accuracy: 0.9621\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.1593 - accuracy: 0.9628 - val_loss: 0.1708 - val_accuracy: 0.9621\n",
      "Epoch 79/100\n",
      " - 4s - loss: 0.1589 - accuracy: 0.9629 - val_loss: 0.1707 - val_accuracy: 0.9621\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.1588 - accuracy: 0.9628 - val_loss: 0.1734 - val_accuracy: 0.9622\n",
      "Epoch 81/100\n",
      " - 4s - loss: 0.1588 - accuracy: 0.9630 - val_loss: 0.1726 - val_accuracy: 0.9622\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.1583 - accuracy: 0.9630 - val_loss: 0.1712 - val_accuracy: 0.9624\n",
      "Epoch 83/100\n",
      " - 4s - loss: 0.1587 - accuracy: 0.9629 - val_loss: 0.1708 - val_accuracy: 0.9623\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.1587 - accuracy: 0.9629 - val_loss: 0.1709 - val_accuracy: 0.9623\n",
      "Epoch 85/100\n",
      " - 4s - loss: 0.1586 - accuracy: 0.9630 - val_loss: 0.1711 - val_accuracy: 0.9621\n",
      "Epoch 86/100\n",
      " - 4s - loss: 0.1586 - accuracy: 0.9629 - val_loss: 0.1720 - val_accuracy: 0.9624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 3s - loss: 0.1582 - accuracy: 0.9630 - val_loss: 0.1757 - val_accuracy: 0.9624\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.1583 - accuracy: 0.9628 - val_loss: 0.1715 - val_accuracy: 0.9623\n",
      "Epoch 89/100\n",
      " - 4s - loss: 0.1585 - accuracy: 0.9631 - val_loss: 0.1703 - val_accuracy: 0.9623\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.1583 - accuracy: 0.9629 - val_loss: 0.1721 - val_accuracy: 0.9624\n",
      "Epoch 91/100\n",
      " - 4s - loss: 0.1583 - accuracy: 0.9629 - val_loss: 0.1705 - val_accuracy: 0.9623\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.1583 - accuracy: 0.9630 - val_loss: 0.1718 - val_accuracy: 0.9622\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.1581 - accuracy: 0.9629 - val_loss: 0.1717 - val_accuracy: 0.9621\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.1579 - accuracy: 0.9629 - val_loss: 0.1725 - val_accuracy: 0.9623\n",
      "Epoch 95/100\n",
      " - 5s - loss: 0.1580 - accuracy: 0.9629 - val_loss: 0.1715 - val_accuracy: 0.9621\n",
      "Epoch 96/100\n",
      " - 4s - loss: 0.1578 - accuracy: 0.9629 - val_loss: 0.1715 - val_accuracy: 0.9625\n",
      "Epoch 97/100\n",
      " - 4s - loss: 0.1577 - accuracy: 0.9630 - val_loss: 0.1711 - val_accuracy: 0.9624\n",
      "Epoch 98/100\n",
      " - 4s - loss: 0.1578 - accuracy: 0.9629 - val_loss: 0.1715 - val_accuracy: 0.9621\n",
      "Epoch 99/100\n",
      " - 4s - loss: 0.1576 - accuracy: 0.9629 - val_loss: 0.1715 - val_accuracy: 0.9625\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.1577 - accuracy: 0.9630 - val_loss: 0.1713 - val_accuracy: 0.9621\n"
     ]
    }
   ],
   "source": [
    "# Now onto training & validating the model 1\n",
    "hist = model.fit(\n",
    "    X_train, Y_train,          \n",
    "    batch_size=32, \n",
    "    epochs=100,   \n",
    "    verbose=2,\n",
    "    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "11749/11749 [==============================] - 0s 16us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9647629857063293"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model 1 on test dataset\n",
    "# [1] gives the accuracy, [0] is for loss\n",
    "print(\"Accuracy: \") \n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11749/11749 [==============================] - 0s 15us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     11335\n",
      "           1       0.00      0.00      0.00        92\n",
      "           2       0.00      0.00      0.00       322\n",
      "\n",
      "    accuracy                           0.96     11749\n",
      "   macro avg       0.32      0.33      0.33     11749\n",
      "weighted avg       0.93      0.96      0.95     11749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "# Using sklearn displaying a classification report\n",
    "# Precision & recall can be highly important for an imbalanced dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "rounded_labels=np.argmax(Y_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(rounded_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2\n",
    "# Cost Sensitive (Class Weights) Neural Network Model using Keras (Tensorflow backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:  [ 0.34615028 45.32465278 11.23364888]\n",
      "Input and output shape:\n",
      " (54824, 11) (11748, 11) (11749, 11) (54824, 3) (11748, 3) (11749, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass classes=[0 1 2], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cost Sensitive Neural Network Model using Keras (Tensorflow backend)\n",
    "# model 2\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load and encode the dataset\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "# Mapping_Tier = {\"Basic\":0, \"Plus\":0.5, \"Premium\":1}\n",
    "# df[\"product_tier\"] = df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Define automated class weights \n",
    "# This can help to provide some bias towards the minority class\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "print(\"Class weights: \", class_weights)\n",
    "\n",
    "# Convert label to categorical values\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Now scaling the dataset so that all the input features lie between 0 and 1 inclusive\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into train, validate and test\n",
    "# Can also use k-fold Cross-Validation - but it takes longer to process therefore I went with random split\n",
    "# Also to note: k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=0)\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "# Define the Neural Network Architecture \n",
    "model = Sequential([    \n",
    "                    Dense(32, activation='relu', input_dim = 11),    \n",
    "                    Dense(32, activation='relu'),    \n",
    "                    Dense(3, activation='softmax'),])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',            \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54824 samples, validate on 11748 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.1893 - accuracy: 0.9591 - val_loss: 0.1644 - val_accuracy: 0.9655\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.1761 - accuracy: 0.9625 - val_loss: 0.1630 - val_accuracy: 0.9655\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.1754 - accuracy: 0.9625 - val_loss: 0.1635 - val_accuracy: 0.9655\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.1744 - accuracy: 0.9625 - val_loss: 0.1638 - val_accuracy: 0.9655\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1738 - accuracy: 0.9625 - val_loss: 0.1618 - val_accuracy: 0.9655\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1734 - accuracy: 0.9625 - val_loss: 0.1617 - val_accuracy: 0.9655\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1729 - accuracy: 0.9625 - val_loss: 0.1607 - val_accuracy: 0.9655\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1727 - accuracy: 0.9625 - val_loss: 0.1617 - val_accuracy: 0.9655\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1724 - accuracy: 0.9625 - val_loss: 0.1621 - val_accuracy: 0.9655\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1720 - accuracy: 0.9625 - val_loss: 0.1620 - val_accuracy: 0.9655\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1720 - accuracy: 0.9625 - val_loss: 0.1614 - val_accuracy: 0.9655\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1718 - accuracy: 0.9625 - val_loss: 0.1610 - val_accuracy: 0.9655\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1717 - accuracy: 0.9625 - val_loss: 0.1604 - val_accuracy: 0.9655\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1712 - accuracy: 0.9625 - val_loss: 0.1604 - val_accuracy: 0.9655\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.1708 - accuracy: 0.9625 - val_loss: 0.1613 - val_accuracy: 0.9655\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.1707 - accuracy: 0.9625 - val_loss: 0.1616 - val_accuracy: 0.9655\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1705 - accuracy: 0.9625 - val_loss: 0.1602 - val_accuracy: 0.9655\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.1704 - accuracy: 0.9625 - val_loss: 0.1600 - val_accuracy: 0.9655\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.1702 - accuracy: 0.9625 - val_loss: 0.1599 - val_accuracy: 0.9655\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.1699 - accuracy: 0.9625 - val_loss: 0.1597 - val_accuracy: 0.9655\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.1697 - accuracy: 0.9625 - val_loss: 0.1614 - val_accuracy: 0.9655\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.1693 - accuracy: 0.9625 - val_loss: 0.1612 - val_accuracy: 0.9655\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.1693 - accuracy: 0.9625 - val_loss: 0.1593 - val_accuracy: 0.9655\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1688 - accuracy: 0.9625 - val_loss: 0.1596 - val_accuracy: 0.9655\n",
      "Epoch 25/100\n",
      " - 2s - loss: 0.1685 - accuracy: 0.9625 - val_loss: 0.1585 - val_accuracy: 0.9655\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.1680 - accuracy: 0.9625 - val_loss: 0.1580 - val_accuracy: 0.9655\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.1676 - accuracy: 0.9625 - val_loss: 0.1609 - val_accuracy: 0.9655\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1671 - accuracy: 0.9624 - val_loss: 0.1585 - val_accuracy: 0.9655\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.1667 - accuracy: 0.9624 - val_loss: 0.1581 - val_accuracy: 0.9655\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.1661 - accuracy: 0.9624 - val_loss: 0.1595 - val_accuracy: 0.9655\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.1660 - accuracy: 0.9625 - val_loss: 0.1572 - val_accuracy: 0.9655\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.1655 - accuracy: 0.9625 - val_loss: 0.1574 - val_accuracy: 0.9655\n",
      "Epoch 33/100\n",
      " - 4s - loss: 0.1651 - accuracy: 0.9625 - val_loss: 0.1606 - val_accuracy: 0.9656\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.1652 - accuracy: 0.9625 - val_loss: 0.1581 - val_accuracy: 0.9655\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.1649 - accuracy: 0.9625 - val_loss: 0.1574 - val_accuracy: 0.9655\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.1648 - accuracy: 0.9625 - val_loss: 0.1588 - val_accuracy: 0.9653\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.1645 - accuracy: 0.9625 - val_loss: 0.1571 - val_accuracy: 0.9656\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.1644 - accuracy: 0.9625 - val_loss: 0.1582 - val_accuracy: 0.9656\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.1640 - accuracy: 0.9626 - val_loss: 0.1576 - val_accuracy: 0.9655\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.1642 - accuracy: 0.9625 - val_loss: 0.1584 - val_accuracy: 0.9654\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.1641 - accuracy: 0.9626 - val_loss: 0.1611 - val_accuracy: 0.9653\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.1638 - accuracy: 0.9626 - val_loss: 0.1580 - val_accuracy: 0.9656\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.1634 - accuracy: 0.9625 - val_loss: 0.1581 - val_accuracy: 0.9655\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.1633 - accuracy: 0.9626 - val_loss: 0.1580 - val_accuracy: 0.9655\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.1634 - accuracy: 0.9628 - val_loss: 0.1590 - val_accuracy: 0.9656\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.1632 - accuracy: 0.9625 - val_loss: 0.1569 - val_accuracy: 0.9656\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.1630 - accuracy: 0.9626 - val_loss: 0.1575 - val_accuracy: 0.9653\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.1628 - accuracy: 0.9626 - val_loss: 0.1565 - val_accuracy: 0.9655\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.1628 - accuracy: 0.9627 - val_loss: 0.1570 - val_accuracy: 0.9655\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.1625 - accuracy: 0.9626 - val_loss: 0.1569 - val_accuracy: 0.9656\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.1627 - accuracy: 0.9625 - val_loss: 0.1595 - val_accuracy: 0.9654\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.1623 - accuracy: 0.9627 - val_loss: 0.1583 - val_accuracy: 0.9656\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.1621 - accuracy: 0.9626 - val_loss: 0.1597 - val_accuracy: 0.9656\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.1622 - accuracy: 0.9626 - val_loss: 0.1568 - val_accuracy: 0.9656\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.1620 - accuracy: 0.9625 - val_loss: 0.1576 - val_accuracy: 0.9654\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.1620 - accuracy: 0.9626 - val_loss: 0.1580 - val_accuracy: 0.9654\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.1616 - accuracy: 0.9627 - val_loss: 0.1579 - val_accuracy: 0.9653\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.1618 - accuracy: 0.9627 - val_loss: 0.1573 - val_accuracy: 0.9656\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.1617 - accuracy: 0.9626 - val_loss: 0.1597 - val_accuracy: 0.9647\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.1617 - accuracy: 0.9625 - val_loss: 0.1592 - val_accuracy: 0.9654\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.1614 - accuracy: 0.9626 - val_loss: 0.1578 - val_accuracy: 0.9658\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.1611 - accuracy: 0.9625 - val_loss: 0.1586 - val_accuracy: 0.9656\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.1610 - accuracy: 0.9626 - val_loss: 0.1583 - val_accuracy: 0.9655\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.1611 - accuracy: 0.9626 - val_loss: 0.1595 - val_accuracy: 0.9648\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.1610 - accuracy: 0.9627 - val_loss: 0.1583 - val_accuracy: 0.9649\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.1610 - accuracy: 0.9627 - val_loss: 0.1603 - val_accuracy: 0.9650\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.1607 - accuracy: 0.9626 - val_loss: 0.1596 - val_accuracy: 0.9644\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.1607 - accuracy: 0.9626 - val_loss: 0.1611 - val_accuracy: 0.9647\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.1606 - accuracy: 0.9627 - val_loss: 0.1582 - val_accuracy: 0.9654\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.1605 - accuracy: 0.9626 - val_loss: 0.1579 - val_accuracy: 0.9657\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.1604 - accuracy: 0.9626 - val_loss: 0.1586 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.1602 - accuracy: 0.9627 - val_loss: 0.1615 - val_accuracy: 0.9654\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.1601 - accuracy: 0.9627 - val_loss: 0.1585 - val_accuracy: 0.9647\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.1602 - accuracy: 0.9626 - val_loss: 0.1596 - val_accuracy: 0.9654\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.1598 - accuracy: 0.9625 - val_loss: 0.1603 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.1599 - accuracy: 0.9627 - val_loss: 0.1591 - val_accuracy: 0.9657\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.1598 - accuracy: 0.9627 - val_loss: 0.1591 - val_accuracy: 0.9657\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.1596 - accuracy: 0.9627 - val_loss: 0.1616 - val_accuracy: 0.9649\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.1597 - accuracy: 0.9626 - val_loss: 0.1591 - val_accuracy: 0.9654\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.1597 - accuracy: 0.9628 - val_loss: 0.1593 - val_accuracy: 0.9651\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.1593 - accuracy: 0.9626 - val_loss: 0.1674 - val_accuracy: 0.9654\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.1595 - accuracy: 0.9626 - val_loss: 0.1614 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      " - 2s - loss: 0.1593 - accuracy: 0.9626 - val_loss: 0.1594 - val_accuracy: 0.9653\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.1589 - accuracy: 0.9625 - val_loss: 0.1603 - val_accuracy: 0.9653\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.1591 - accuracy: 0.9628 - val_loss: 0.1591 - val_accuracy: 0.9656\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.1593 - accuracy: 0.9625 - val_loss: 0.1619 - val_accuracy: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 2s - loss: 0.1590 - accuracy: 0.9627 - val_loss: 0.1595 - val_accuracy: 0.9655\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.1588 - accuracy: 0.9627 - val_loss: 0.1598 - val_accuracy: 0.9654\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.1588 - accuracy: 0.9627 - val_loss: 0.1623 - val_accuracy: 0.9652\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.1587 - accuracy: 0.9628 - val_loss: 0.1626 - val_accuracy: 0.9654\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.1587 - accuracy: 0.9626 - val_loss: 0.1595 - val_accuracy: 0.9654\n",
      "Epoch 92/100\n",
      " - 2s - loss: 0.1585 - accuracy: 0.9628 - val_loss: 0.1587 - val_accuracy: 0.9652\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.1586 - accuracy: 0.9627 - val_loss: 0.1590 - val_accuracy: 0.9654\n",
      "Epoch 94/100\n",
      " - 2s - loss: 0.1584 - accuracy: 0.9627 - val_loss: 0.1632 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.1584 - accuracy: 0.9627 - val_loss: 0.1589 - val_accuracy: 0.9655\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.1581 - accuracy: 0.9626 - val_loss: 0.1609 - val_accuracy: 0.9657\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.1582 - accuracy: 0.9627 - val_loss: 0.1594 - val_accuracy: 0.9652\n",
      "Epoch 98/100\n",
      " - 2s - loss: 0.1583 - accuracy: 0.9627 - val_loss: 0.1635 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.1580 - accuracy: 0.9627 - val_loss: 0.1587 - val_accuracy: 0.9656\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.1579 - accuracy: 0.9627 - val_loss: 0.1605 - val_accuracy: 0.9654\n"
     ]
    }
   ],
   "source": [
    "# Now onto training & validating the model 2\n",
    "hist = model.fit(\n",
    "    X_train, Y_train,          \n",
    "    batch_size=32, \n",
    "    epochs=100,   \n",
    "    verbose=2,\n",
    "    class_weight=class_weights,\n",
    "    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "11749/11749 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9632309079170227"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model 2 on test dataset\n",
    "# [1] gives the accuracy, [0] is for loss\n",
    "print(\"Accuracy: \") \n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11749/11749 [==============================] - 0s 16us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     11312\n",
      "           1       0.00      0.00      0.00        91\n",
      "           2       0.69      0.03      0.05       346\n",
      "\n",
      "    accuracy                           0.96     11749\n",
      "   macro avg       0.55      0.34      0.34     11749\n",
      "weighted avg       0.95      0.96      0.95     11749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# model 2\n",
    "# Using sklearn displaying a classification report\n",
    "# Precision & recall can be highly important for an imbalanced dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "rounded_labels=np.argmax(Y_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(rounded_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3\n",
    "# Undersampling the dataset\n",
    "# Neural Network Model using Keras (Tensorflow backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "      <th>calculated_ctr</th>\n",
       "      <th>product_tier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_tier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Basic</td>\n",
       "      <td>576</td>\n",
       "      <td>41</td>\n",
       "      <td>377</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>192</td>\n",
       "      <td>526</td>\n",
       "      <td>181</td>\n",
       "      <td>111</td>\n",
       "      <td>553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Plus</td>\n",
       "      <td>576</td>\n",
       "      <td>42</td>\n",
       "      <td>353</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>183</td>\n",
       "      <td>559</td>\n",
       "      <td>356</td>\n",
       "      <td>119</td>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Premium</td>\n",
       "      <td>576</td>\n",
       "      <td>39</td>\n",
       "      <td>348</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>183</td>\n",
       "      <td>573</td>\n",
       "      <td>386</td>\n",
       "      <td>105</td>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              article_id  make_name  price  first_zip_digit  \\\n",
       "product_tier                                                  \n",
       "Basic                576         41    377                9   \n",
       "Plus                 576         42    353                9   \n",
       "Premium              576         39    348                9   \n",
       "\n",
       "              first_registration_year  created_date  deleted_date  \\\n",
       "product_tier                                                        \n",
       "Basic                              29            34           192   \n",
       "Plus                               28            35           183   \n",
       "Premium                            27            34           183   \n",
       "\n",
       "              search_views  detail_views  calculated_stock_days  \\\n",
       "product_tier                                                      \n",
       "Basic                  526           181                    111   \n",
       "Plus                   559           356                    119   \n",
       "Premium                573           386                    105   \n",
       "\n",
       "              calculated_ctr  product_tier  \n",
       "product_tier                                \n",
       "Basic                    553             1  \n",
       "Plus                     573             1  \n",
       "Premium                  573             1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampling the dataset\n",
    "# model 3\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "\n",
    "# Shuffle the Dataset\n",
    "shuffled_df = df.sample(frac=1,random_state=4)\n",
    "\n",
    "# Put all the 'plus' tier in a separate dataset.\n",
    "plus_df = shuffled_df.loc[shuffled_df['product_tier'] == 'Plus']\n",
    "\n",
    "#Randomly select 574 observations from the 'basic' tier (majority class)\n",
    "basic_df = shuffled_df.loc[shuffled_df['product_tier'] == 'Basic'].sample(n=576,random_state=42)\n",
    "\n",
    "#Randomly select 574 observations from the 'premium' tier (majority class)\n",
    "premium_df = shuffled_df.loc[shuffled_df['product_tier'] == 'Premium'].sample(n=576,random_state=42)\n",
    "\n",
    "# Concatenate both dataframes again\n",
    "normalized_df = pd.concat([plus_df, basic_df, premium_df])\n",
    "\n",
    "# Displaying count per class\n",
    "normalized_df.groupby('product_tier').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output shape:\n",
      " (1209, 11) (259, 11) (260, 11) (1209, 3) (259, 3) (260, 3)\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Model using Keras (Tensorflow backend)\n",
    "# model 3\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load and encode the dataset\n",
    "# Mapping_Tier = {\"Basic\":0, \"Plus\":0.5, \"Premium\":1}\n",
    "# df[\"product_tier\"] = df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = normalized_df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Convert label to categorical values\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Now scaling the dataset so that all the input features lie between 0 and 1 inclusive\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into train, validate and test\n",
    "# Can also use k-fold Cross-Validation - but it takes longer to process therefore I went with random split\n",
    "# Also to note: k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=0)\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "# Define the Neural Network Architecture \n",
    "model = Sequential([    \n",
    "                    Dense(32, activation='relu', input_dim = 11),    \n",
    "                    Dense(32, activation='relu'),    \n",
    "                    Dense(3, activation='softmax'),])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',            \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1209 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 1.0922 - accuracy: 0.3631 - val_loss: 1.0890 - val_accuracy: 0.3552\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.0831 - accuracy: 0.4202 - val_loss: 1.0862 - val_accuracy: 0.3900\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.0749 - accuracy: 0.4185 - val_loss: 1.0748 - val_accuracy: 0.3977\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.0711 - accuracy: 0.4202 - val_loss: 1.0747 - val_accuracy: 0.3977\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.0659 - accuracy: 0.4359 - val_loss: 1.0773 - val_accuracy: 0.4054\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.0640 - accuracy: 0.4326 - val_loss: 1.0789 - val_accuracy: 0.3977\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.0611 - accuracy: 0.4326 - val_loss: 1.0815 - val_accuracy: 0.4054\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.0601 - accuracy: 0.4367 - val_loss: 1.0645 - val_accuracy: 0.4208\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.0556 - accuracy: 0.4376 - val_loss: 1.0692 - val_accuracy: 0.4440\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.0566 - accuracy: 0.4334 - val_loss: 1.0617 - val_accuracy: 0.4286\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.0492 - accuracy: 0.4458 - val_loss: 1.0739 - val_accuracy: 0.4054\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.0495 - accuracy: 0.4524 - val_loss: 1.0750 - val_accuracy: 0.4015\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.0468 - accuracy: 0.4458 - val_loss: 1.0873 - val_accuracy: 0.3822\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.0458 - accuracy: 0.4442 - val_loss: 1.0689 - val_accuracy: 0.3977\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.0425 - accuracy: 0.4541 - val_loss: 1.0675 - val_accuracy: 0.4170\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.0368 - accuracy: 0.4582 - val_loss: 1.0645 - val_accuracy: 0.4208\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.0393 - accuracy: 0.4500 - val_loss: 1.0751 - val_accuracy: 0.3977\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.0333 - accuracy: 0.4756 - val_loss: 1.0650 - val_accuracy: 0.4324\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.0296 - accuracy: 0.4673 - val_loss: 1.0696 - val_accuracy: 0.4131\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.0266 - accuracy: 0.4723 - val_loss: 1.0688 - val_accuracy: 0.4247\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.0250 - accuracy: 0.4665 - val_loss: 1.0697 - val_accuracy: 0.4131\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.0241 - accuracy: 0.4682 - val_loss: 1.0610 - val_accuracy: 0.3977\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.0210 - accuracy: 0.4690 - val_loss: 1.0643 - val_accuracy: 0.4131\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.0176 - accuracy: 0.4822 - val_loss: 1.0695 - val_accuracy: 0.3977\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1.0186 - accuracy: 0.4731 - val_loss: 1.0658 - val_accuracy: 0.4286\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.0152 - accuracy: 0.4806 - val_loss: 1.0725 - val_accuracy: 0.3861\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.0094 - accuracy: 0.4897 - val_loss: 1.0688 - val_accuracy: 0.4131\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.0117 - accuracy: 0.5070 - val_loss: 1.0769 - val_accuracy: 0.4093\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1.0058 - accuracy: 0.4971 - val_loss: 1.0787 - val_accuracy: 0.4131\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.0058 - accuracy: 0.4913 - val_loss: 1.0776 - val_accuracy: 0.4054\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.0020 - accuracy: 0.4955 - val_loss: 1.0687 - val_accuracy: 0.4170\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.9991 - accuracy: 0.5037 - val_loss: 1.0729 - val_accuracy: 0.4170\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.9962 - accuracy: 0.5203 - val_loss: 1.0901 - val_accuracy: 0.3938\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.9973 - accuracy: 0.5012 - val_loss: 1.0747 - val_accuracy: 0.4131\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.9927 - accuracy: 0.5186 - val_loss: 1.0808 - val_accuracy: 0.4170\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.9885 - accuracy: 0.5170 - val_loss: 1.0869 - val_accuracy: 0.4208\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.9866 - accuracy: 0.5070 - val_loss: 1.1031 - val_accuracy: 0.4093\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.9842 - accuracy: 0.5062 - val_loss: 1.0805 - val_accuracy: 0.4054\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.9856 - accuracy: 0.5211 - val_loss: 1.0820 - val_accuracy: 0.4247\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.9790 - accuracy: 0.5194 - val_loss: 1.1284 - val_accuracy: 0.4402\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.9804 - accuracy: 0.5203 - val_loss: 1.0831 - val_accuracy: 0.4131\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.9794 - accuracy: 0.5285 - val_loss: 1.0857 - val_accuracy: 0.4247\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.9789 - accuracy: 0.5277 - val_loss: 1.0863 - val_accuracy: 0.4286\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.9715 - accuracy: 0.5244 - val_loss: 1.0857 - val_accuracy: 0.4170\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.9697 - accuracy: 0.5178 - val_loss: 1.0914 - val_accuracy: 0.4324\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.9739 - accuracy: 0.5310 - val_loss: 1.0801 - val_accuracy: 0.4247\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.9683 - accuracy: 0.5252 - val_loss: 1.0879 - val_accuracy: 0.4402\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.9661 - accuracy: 0.5393 - val_loss: 1.0958 - val_accuracy: 0.4247\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.9657 - accuracy: 0.5261 - val_loss: 1.0889 - val_accuracy: 0.4170\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.9646 - accuracy: 0.5285 - val_loss: 1.0916 - val_accuracy: 0.4131\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.9640 - accuracy: 0.5227 - val_loss: 1.1011 - val_accuracy: 0.4402\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.9631 - accuracy: 0.5360 - val_loss: 1.1027 - val_accuracy: 0.4324\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.9595 - accuracy: 0.5318 - val_loss: 1.0949 - val_accuracy: 0.4286\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.9558 - accuracy: 0.5418 - val_loss: 1.0876 - val_accuracy: 0.4247\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.9542 - accuracy: 0.5434 - val_loss: 1.1104 - val_accuracy: 0.4402\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.9572 - accuracy: 0.5533 - val_loss: 1.1185 - val_accuracy: 0.4286\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.9525 - accuracy: 0.5327 - val_loss: 1.0917 - val_accuracy: 0.4286\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.9497 - accuracy: 0.5542 - val_loss: 1.1085 - val_accuracy: 0.4286\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.9489 - accuracy: 0.5393 - val_loss: 1.1082 - val_accuracy: 0.4440\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.9488 - accuracy: 0.5352 - val_loss: 1.1282 - val_accuracy: 0.4402\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.9477 - accuracy: 0.5343 - val_loss: 1.1142 - val_accuracy: 0.4170\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.9449 - accuracy: 0.5434 - val_loss: 1.1155 - val_accuracy: 0.4247\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.9421 - accuracy: 0.5459 - val_loss: 1.1281 - val_accuracy: 0.4054\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.9414 - accuracy: 0.5360 - val_loss: 1.1054 - val_accuracy: 0.4363\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.9405 - accuracy: 0.5459 - val_loss: 1.1166 - val_accuracy: 0.4402\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.9408 - accuracy: 0.5624 - val_loss: 1.1145 - val_accuracy: 0.4324\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.9376 - accuracy: 0.5393 - val_loss: 1.1118 - val_accuracy: 0.4131\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.9394 - accuracy: 0.5476 - val_loss: 1.1110 - val_accuracy: 0.4093\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.9350 - accuracy: 0.5558 - val_loss: 1.1196 - val_accuracy: 0.4093\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.9358 - accuracy: 0.5558 - val_loss: 1.1189 - val_accuracy: 0.4286\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.9297 - accuracy: 0.5409 - val_loss: 1.1187 - val_accuracy: 0.4402\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.9284 - accuracy: 0.5575 - val_loss: 1.1499 - val_accuracy: 0.4247\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.9310 - accuracy: 0.5583 - val_loss: 1.1228 - val_accuracy: 0.4015\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.9265 - accuracy: 0.5567 - val_loss: 1.1272 - val_accuracy: 0.4170\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.9294 - accuracy: 0.5567 - val_loss: 1.1188 - val_accuracy: 0.4324\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.9207 - accuracy: 0.5616 - val_loss: 1.1236 - val_accuracy: 0.4054\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.9234 - accuracy: 0.5517 - val_loss: 1.1220 - val_accuracy: 0.4208\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.9208 - accuracy: 0.5575 - val_loss: 1.1345 - val_accuracy: 0.4015\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.9214 - accuracy: 0.5517 - val_loss: 1.1299 - val_accuracy: 0.4208\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.9190 - accuracy: 0.5591 - val_loss: 1.1515 - val_accuracy: 0.4170\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.9151 - accuracy: 0.5509 - val_loss: 1.1305 - val_accuracy: 0.3900\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.9151 - accuracy: 0.5583 - val_loss: 1.1285 - val_accuracy: 0.4131\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.9182 - accuracy: 0.5649 - val_loss: 1.1447 - val_accuracy: 0.4363\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.9106 - accuracy: 0.5674 - val_loss: 1.1168 - val_accuracy: 0.4479\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.9134 - accuracy: 0.5649 - val_loss: 1.1352 - val_accuracy: 0.4054\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.9120 - accuracy: 0.5707 - val_loss: 1.1436 - val_accuracy: 0.4093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 0s - loss: 0.9092 - accuracy: 0.5649 - val_loss: 1.1499 - val_accuracy: 0.4440\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.9028 - accuracy: 0.5765 - val_loss: 1.1456 - val_accuracy: 0.4093\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.9088 - accuracy: 0.5575 - val_loss: 1.1425 - val_accuracy: 0.4054\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.9110 - accuracy: 0.5724 - val_loss: 1.1519 - val_accuracy: 0.4208\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.9053 - accuracy: 0.5682 - val_loss: 1.1501 - val_accuracy: 0.4015\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.8988 - accuracy: 0.5798 - val_loss: 1.1486 - val_accuracy: 0.4208\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.9008 - accuracy: 0.5715 - val_loss: 1.1409 - val_accuracy: 0.4517\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.8996 - accuracy: 0.5823 - val_loss: 1.1644 - val_accuracy: 0.4015\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.8963 - accuracy: 0.5806 - val_loss: 1.1512 - val_accuracy: 0.4131\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.8973 - accuracy: 0.5782 - val_loss: 1.1669 - val_accuracy: 0.4131\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.8943 - accuracy: 0.5856 - val_loss: 1.1553 - val_accuracy: 0.4208\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.8933 - accuracy: 0.5749 - val_loss: 1.1652 - val_accuracy: 0.4208\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.8926 - accuracy: 0.5773 - val_loss: 1.1682 - val_accuracy: 0.4093\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.8934 - accuracy: 0.5831 - val_loss: 1.1530 - val_accuracy: 0.4402\n"
     ]
    }
   ],
   "source": [
    "# Now onto training & validating the model 3\n",
    "hist = model.fit(\n",
    "    X_train, Y_train,          \n",
    "    batch_size=16, \n",
    "    epochs=100,   \n",
    "    verbose=2,\n",
    "    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "260/260 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4615384638309479"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model 3 on test dataset\n",
    "# [1] gives the accuracy, [0] is for loss\n",
    "print(\"Accuracy: \") \n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 0s 62us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.47      0.47        90\n",
      "           1       0.42      0.51      0.46        87\n",
      "           2       0.51      0.41      0.45        83\n",
      "\n",
      "    accuracy                           0.46       260\n",
      "   macro avg       0.47      0.46      0.46       260\n",
      "weighted avg       0.47      0.46      0.46       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 3\n",
    "# Using sklearn displaying a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "rounded_labels=np.argmax(Y_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(rounded_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4\n",
    "# Over-sampling the dataset using SMOTE\n",
    "# Neural Network Model using Keras (Tensorflow backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output shape:\n",
      " (158384, 11) (33939, 11) (33940, 11) (158384, 3) (33939, 3) (33940, 3)\n"
     ]
    }
   ],
   "source": [
    "# Over-sampling the dataset using SMOTE\n",
    "# Neural Network Model using Keras (Tensorflow backend)\n",
    "# model 4\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "oversample = SMOTE(random_state=12)\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "# Convert label to categorical values\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Now scaling the dataset so that all the input features lie between 0 and 1 inclusive\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into train, validate and test\n",
    "# Can also use k-fold Cross-Validation - but it takes longer to process therefore I went with random split\n",
    "# Also to note: k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=0)\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "# Define the Neural Network Architecture \n",
    "model = Sequential([    \n",
    "                    Dense(32, activation='relu', input_dim = 11),    \n",
    "                    Dense(32, activation='relu'),    \n",
    "                    Dense(3, activation='softmax'),])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',            \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 158384 samples, validate on 33939 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.9860 - accuracy: 0.5067 - val_loss: 0.9445 - val_accuracy: 0.5505\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.9136 - accuracy: 0.5630 - val_loss: 0.8881 - val_accuracy: 0.5809\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.8751 - accuracy: 0.5909 - val_loss: 0.8635 - val_accuracy: 0.5957\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.8499 - accuracy: 0.6072 - val_loss: 0.8398 - val_accuracy: 0.6107\n",
      "Epoch 5/100\n",
      " - 9s - loss: 0.8290 - accuracy: 0.6219 - val_loss: 0.8168 - val_accuracy: 0.6282\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.8125 - accuracy: 0.6311 - val_loss: 0.8030 - val_accuracy: 0.6376\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.8002 - accuracy: 0.6390 - val_loss: 0.8029 - val_accuracy: 0.6381\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.7892 - accuracy: 0.6453 - val_loss: 0.7885 - val_accuracy: 0.6460\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.7791 - accuracy: 0.6517 - val_loss: 0.7812 - val_accuracy: 0.6511\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.7711 - accuracy: 0.6554 - val_loss: 0.7645 - val_accuracy: 0.6602\n",
      "Epoch 11/100\n",
      " - 8s - loss: 0.7628 - accuracy: 0.6604 - val_loss: 0.7559 - val_accuracy: 0.6625\n",
      "Epoch 12/100\n",
      " - 8s - loss: 0.7557 - accuracy: 0.6650 - val_loss: 0.7600 - val_accuracy: 0.6591\n",
      "Epoch 13/100\n",
      " - 8s - loss: 0.7496 - accuracy: 0.6680 - val_loss: 0.7436 - val_accuracy: 0.6730\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.7447 - accuracy: 0.6709 - val_loss: 0.7434 - val_accuracy: 0.6691\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.7394 - accuracy: 0.6735 - val_loss: 0.7369 - val_accuracy: 0.6724\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.7351 - accuracy: 0.6758 - val_loss: 0.7338 - val_accuracy: 0.6762\n",
      "Epoch 17/100\n",
      " - 9s - loss: 0.7309 - accuracy: 0.6778 - val_loss: 0.7407 - val_accuracy: 0.6753\n",
      "Epoch 18/100\n",
      " - 8s - loss: 0.7267 - accuracy: 0.6799 - val_loss: 0.7253 - val_accuracy: 0.6823\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.7231 - accuracy: 0.6820 - val_loss: 0.7258 - val_accuracy: 0.6800\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.7197 - accuracy: 0.6843 - val_loss: 0.7231 - val_accuracy: 0.6803\n",
      "Epoch 21/100\n",
      " - 6s - loss: 0.7177 - accuracy: 0.6866 - val_loss: 0.7171 - val_accuracy: 0.6831\n",
      "Epoch 22/100\n",
      " - 5s - loss: 0.7150 - accuracy: 0.6869 - val_loss: 0.7277 - val_accuracy: 0.6838\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.7119 - accuracy: 0.6897 - val_loss: 0.7216 - val_accuracy: 0.6805\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.7101 - accuracy: 0.6902 - val_loss: 0.7123 - val_accuracy: 0.6895\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.7073 - accuracy: 0.6921 - val_loss: 0.7166 - val_accuracy: 0.6832\n",
      "Epoch 26/100\n",
      " - 5s - loss: 0.7057 - accuracy: 0.6918 - val_loss: 0.7065 - val_accuracy: 0.6912\n",
      "Epoch 27/100\n",
      " - 10s - loss: 0.7036 - accuracy: 0.6937 - val_loss: 0.7586 - val_accuracy: 0.6566\n",
      "Epoch 28/100\n",
      " - 9s - loss: 0.7006 - accuracy: 0.6949 - val_loss: 0.6989 - val_accuracy: 0.6960\n",
      "Epoch 29/100\n",
      " - 7s - loss: 0.6979 - accuracy: 0.6971 - val_loss: 0.6961 - val_accuracy: 0.6938\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.6959 - accuracy: 0.6991 - val_loss: 0.7221 - val_accuracy: 0.6768\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.6932 - accuracy: 0.6989 - val_loss: 0.7034 - val_accuracy: 0.6902\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.6913 - accuracy: 0.7005 - val_loss: 0.7042 - val_accuracy: 0.6859\n",
      "Epoch 33/100\n",
      " - 5s - loss: 0.6886 - accuracy: 0.7014 - val_loss: 0.7035 - val_accuracy: 0.6912\n",
      "Epoch 34/100\n",
      " - 6s - loss: 0.6867 - accuracy: 0.7025 - val_loss: 0.6851 - val_accuracy: 0.7041\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.6836 - accuracy: 0.7041 - val_loss: 0.6892 - val_accuracy: 0.6975\n",
      "Epoch 36/100\n",
      " - 6s - loss: 0.6822 - accuracy: 0.7043 - val_loss: 0.6819 - val_accuracy: 0.7031\n",
      "Epoch 37/100\n",
      " - 6s - loss: 0.6802 - accuracy: 0.7067 - val_loss: 0.6885 - val_accuracy: 0.6952\n",
      "Epoch 38/100\n",
      " - 6s - loss: 0.6777 - accuracy: 0.7068 - val_loss: 0.6881 - val_accuracy: 0.6976\n",
      "Epoch 39/100\n",
      " - 6s - loss: 0.6764 - accuracy: 0.7085 - val_loss: 0.6951 - val_accuracy: 0.7014\n",
      "Epoch 40/100\n",
      " - 5s - loss: 0.6753 - accuracy: 0.7088 - val_loss: 0.6798 - val_accuracy: 0.7052\n",
      "Epoch 41/100\n",
      " - 6s - loss: 0.6739 - accuracy: 0.7096 - val_loss: 0.6817 - val_accuracy: 0.7034\n",
      "Epoch 42/100\n",
      " - 6s - loss: 0.6722 - accuracy: 0.7112 - val_loss: 0.6763 - val_accuracy: 0.7074\n",
      "Epoch 43/100\n",
      " - 7s - loss: 0.6717 - accuracy: 0.7107 - val_loss: 0.6828 - val_accuracy: 0.7050\n",
      "Epoch 44/100\n",
      " - 7s - loss: 0.6708 - accuracy: 0.7115 - val_loss: 0.6965 - val_accuracy: 0.7009\n",
      "Epoch 45/100\n",
      " - 6s - loss: 0.6688 - accuracy: 0.7131 - val_loss: 0.6918 - val_accuracy: 0.7027\n",
      "Epoch 46/100\n",
      " - 6s - loss: 0.6689 - accuracy: 0.7116 - val_loss: 0.6796 - val_accuracy: 0.7041\n",
      "Epoch 47/100\n",
      " - 6s - loss: 0.6674 - accuracy: 0.7137 - val_loss: 0.6811 - val_accuracy: 0.7001\n",
      "Epoch 48/100\n",
      " - 6s - loss: 0.6671 - accuracy: 0.7125 - val_loss: 0.6673 - val_accuracy: 0.7123\n",
      "Epoch 49/100\n",
      " - 6s - loss: 0.6651 - accuracy: 0.7144 - val_loss: 0.6909 - val_accuracy: 0.6989\n",
      "Epoch 50/100\n",
      " - 6s - loss: 0.6647 - accuracy: 0.7146 - val_loss: 0.6757 - val_accuracy: 0.7072\n",
      "Epoch 51/100\n",
      " - 6s - loss: 0.6635 - accuracy: 0.7157 - val_loss: 0.6679 - val_accuracy: 0.7113\n",
      "Epoch 52/100\n",
      " - 6s - loss: 0.6625 - accuracy: 0.7155 - val_loss: 0.6843 - val_accuracy: 0.7062\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.6636 - accuracy: 0.7141 - val_loss: 0.6698 - val_accuracy: 0.7103\n",
      "Epoch 54/100\n",
      " - 5s - loss: 0.6623 - accuracy: 0.7154 - val_loss: 0.6752 - val_accuracy: 0.7108\n",
      "Epoch 55/100\n",
      " - 5s - loss: 0.6615 - accuracy: 0.7159 - val_loss: 0.6688 - val_accuracy: 0.7135\n",
      "Epoch 56/100\n",
      " - 5s - loss: 0.6613 - accuracy: 0.7151 - val_loss: 0.6776 - val_accuracy: 0.7067\n",
      "Epoch 57/100\n",
      " - 6s - loss: 0.6600 - accuracy: 0.7166 - val_loss: 0.6803 - val_accuracy: 0.7059\n",
      "Epoch 58/100\n",
      " - 6s - loss: 0.6598 - accuracy: 0.7164 - val_loss: 0.6593 - val_accuracy: 0.7179\n",
      "Epoch 59/100\n",
      " - 6s - loss: 0.6591 - accuracy: 0.7169 - val_loss: 0.6744 - val_accuracy: 0.7075\n",
      "Epoch 60/100\n",
      " - 6s - loss: 0.6582 - accuracy: 0.7173 - val_loss: 0.6629 - val_accuracy: 0.7163\n",
      "Epoch 61/100\n",
      " - 6s - loss: 0.6583 - accuracy: 0.7172 - val_loss: 0.6717 - val_accuracy: 0.7056\n",
      "Epoch 62/100\n",
      " - 7s - loss: 0.6572 - accuracy: 0.7174 - val_loss: 0.6638 - val_accuracy: 0.7120\n",
      "Epoch 63/100\n",
      " - 7s - loss: 0.6566 - accuracy: 0.7181 - val_loss: 0.6724 - val_accuracy: 0.7082\n",
      "Epoch 64/100\n",
      " - 6s - loss: 0.6561 - accuracy: 0.7177 - val_loss: 0.6624 - val_accuracy: 0.7143\n",
      "Epoch 65/100\n",
      " - 6s - loss: 0.6568 - accuracy: 0.7179 - val_loss: 0.6636 - val_accuracy: 0.7146\n",
      "Epoch 66/100\n",
      " - 6s - loss: 0.6561 - accuracy: 0.7172 - val_loss: 0.6611 - val_accuracy: 0.7173\n",
      "Epoch 67/100\n",
      " - 6s - loss: 0.6552 - accuracy: 0.7195 - val_loss: 0.6697 - val_accuracy: 0.7058\n",
      "Epoch 68/100\n",
      " - 6s - loss: 0.6556 - accuracy: 0.7179 - val_loss: 0.6710 - val_accuracy: 0.7120\n",
      "Epoch 69/100\n",
      " - 6s - loss: 0.6547 - accuracy: 0.7194 - val_loss: 0.6631 - val_accuracy: 0.7137\n",
      "Epoch 70/100\n",
      " - 7s - loss: 0.6543 - accuracy: 0.7191 - val_loss: 0.6559 - val_accuracy: 0.7187\n",
      "Epoch 71/100\n",
      " - 7s - loss: 0.6527 - accuracy: 0.7197 - val_loss: 0.6670 - val_accuracy: 0.7097\n",
      "Epoch 72/100\n",
      " - 7s - loss: 0.6535 - accuracy: 0.7190 - val_loss: 0.6603 - val_accuracy: 0.7132\n",
      "Epoch 73/100\n",
      " - 7s - loss: 0.6534 - accuracy: 0.7194 - val_loss: 0.6561 - val_accuracy: 0.7170\n",
      "Epoch 74/100\n",
      " - 7s - loss: 0.6510 - accuracy: 0.7217 - val_loss: 0.6673 - val_accuracy: 0.7133\n",
      "Epoch 75/100\n",
      " - 10s - loss: 0.6516 - accuracy: 0.7205 - val_loss: 0.6581 - val_accuracy: 0.7182\n",
      "Epoch 76/100\n",
      " - 7s - loss: 0.6514 - accuracy: 0.7203 - val_loss: 0.6545 - val_accuracy: 0.7176\n",
      "Epoch 77/100\n",
      " - 7s - loss: 0.6502 - accuracy: 0.7217 - val_loss: 0.6616 - val_accuracy: 0.7153\n",
      "Epoch 78/100\n",
      " - 8s - loss: 0.6502 - accuracy: 0.7215 - val_loss: 0.6687 - val_accuracy: 0.7081\n",
      "Epoch 79/100\n",
      " - 7s - loss: 0.6492 - accuracy: 0.7212 - val_loss: 0.6658 - val_accuracy: 0.7093\n",
      "Epoch 80/100\n",
      " - 6s - loss: 0.6486 - accuracy: 0.7225 - val_loss: 0.6566 - val_accuracy: 0.7163\n",
      "Epoch 81/100\n",
      " - 5s - loss: 0.6479 - accuracy: 0.7223 - val_loss: 0.6580 - val_accuracy: 0.7150\n",
      "Epoch 82/100\n",
      " - 5s - loss: 0.6478 - accuracy: 0.7226 - val_loss: 0.6560 - val_accuracy: 0.7182\n",
      "Epoch 83/100\n",
      " - 6s - loss: 0.6472 - accuracy: 0.7228 - val_loss: 0.6625 - val_accuracy: 0.7112\n",
      "Epoch 84/100\n",
      " - 6s - loss: 0.6458 - accuracy: 0.7237 - val_loss: 0.6646 - val_accuracy: 0.7183\n",
      "Epoch 85/100\n",
      " - 6s - loss: 0.6469 - accuracy: 0.7226 - val_loss: 0.6590 - val_accuracy: 0.7185\n",
      "Epoch 86/100\n",
      " - 6s - loss: 0.6472 - accuracy: 0.7215 - val_loss: 0.6536 - val_accuracy: 0.7187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 5s - loss: 0.6447 - accuracy: 0.7236 - val_loss: 0.6683 - val_accuracy: 0.7051\n",
      "Epoch 88/100\n",
      " - 6s - loss: 0.6453 - accuracy: 0.7233 - val_loss: 0.6988 - val_accuracy: 0.7028\n",
      "Epoch 89/100\n",
      " - 6s - loss: 0.6448 - accuracy: 0.7240 - val_loss: 0.6504 - val_accuracy: 0.7206\n",
      "Epoch 90/100\n",
      " - 6s - loss: 0.6444 - accuracy: 0.7235 - val_loss: 0.6547 - val_accuracy: 0.7183\n",
      "Epoch 91/100\n",
      " - 6s - loss: 0.6438 - accuracy: 0.7243 - val_loss: 0.6540 - val_accuracy: 0.7204\n",
      "Epoch 92/100\n",
      " - 5s - loss: 0.6433 - accuracy: 0.7237 - val_loss: 0.6573 - val_accuracy: 0.7219\n",
      "Epoch 93/100\n",
      " - 5s - loss: 0.6436 - accuracy: 0.7242 - val_loss: 0.6532 - val_accuracy: 0.7180\n",
      "Epoch 94/100\n",
      " - 6s - loss: 0.6428 - accuracy: 0.7237 - val_loss: 0.6672 - val_accuracy: 0.7119\n",
      "Epoch 95/100\n",
      " - 6s - loss: 0.6428 - accuracy: 0.7241 - val_loss: 0.6482 - val_accuracy: 0.7195\n",
      "Epoch 96/100\n",
      " - 6s - loss: 0.6424 - accuracy: 0.7253 - val_loss: 0.6550 - val_accuracy: 0.7186\n",
      "Epoch 97/100\n",
      " - 5s - loss: 0.6412 - accuracy: 0.7252 - val_loss: 0.6489 - val_accuracy: 0.7223\n",
      "Epoch 98/100\n",
      " - 6s - loss: 0.6415 - accuracy: 0.7249 - val_loss: 0.6500 - val_accuracy: 0.7212\n",
      "Epoch 99/100\n",
      " - 6s - loss: 0.6407 - accuracy: 0.7256 - val_loss: 0.6554 - val_accuracy: 0.7183\n",
      "Epoch 100/100\n",
      " - 6s - loss: 0.6407 - accuracy: 0.7251 - val_loss: 0.6538 - val_accuracy: 0.7190\n"
     ]
    }
   ],
   "source": [
    "# Now onto training & validating the model 4\n",
    "hist = model.fit(\n",
    "    X_train, Y_train,          \n",
    "    batch_size=32, \n",
    "    epochs=100,   \n",
    "    verbose=2,\n",
    "    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "33940/33940 [==============================] - 1s 28us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7223629951477051"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model 4 on test dataset\n",
    "# [1] gives the accuracy, [0] is for loss\n",
    "print(\"Accuracy: \") \n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33940/33940 [==============================] - 0s 13us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67     11321\n",
      "           1       0.75      0.87      0.81     11347\n",
      "           2       0.68      0.66      0.67     11272\n",
      "\n",
      "    accuracy                           0.72     33940\n",
      "   macro avg       0.72      0.72      0.72     33940\n",
      "weighted avg       0.72      0.72      0.72     33940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 4\n",
    "# Using sklearn displaying a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "rounded_labels=np.argmax(Y_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(rounded_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5\n",
    "# Using Feature Selection (manual)\n",
    "# Neural Network Model using Keras (Tensorflow backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output shape:\n",
      " (54824, 8) (11748, 8) (11749, 8) (54824, 3) (11748, 3) (11749, 3)\n"
     ]
    }
   ],
   "source": [
    "# Using Feature Selection (manual)\n",
    "# Neural Network Model using Keras (Tensorflow backend)\n",
    "# model 5\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load and encode the dataset\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "\n",
    "# Dropping columns 'article_id','created_date' & 'deleted_date' as I feel they do not have \n",
    "# any significant importance in predicting 'product_tier'\n",
    "df = df.drop(['article_id','created_date','deleted_date'], axis = 1)\n",
    "\n",
    "# Mapping_Tier = {\"Basic\":0, \"Plus\":0.5, \"Premium\":1}\n",
    "# df[\"product_tier\"] = df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Convert label to categorical values\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Now scaling the dataset so that all the input features lie between 0 and 1 inclusive\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into train, validate and test\n",
    "# Can also use k-fold Cross-Validation - but it takes longer to process therefore I went with random split\n",
    "# Also to note: k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=0)\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "# Define the Neural Network Architecture \n",
    "model = Sequential([    \n",
    "                    Dense(32, activation='relu', input_dim = 8),    \n",
    "                    Dense(32, activation='relu'),    \n",
    "                    Dense(3, activation='softmax'),])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',            \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54824 samples, validate on 11748 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.1874 - accuracy: 0.9609 - val_loss: 0.1811 - val_accuracy: 0.9611\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.1724 - accuracy: 0.9633 - val_loss: 0.1826 - val_accuracy: 0.9611\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.1716 - accuracy: 0.9633 - val_loss: 0.1816 - val_accuracy: 0.9611\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1708 - accuracy: 0.9633 - val_loss: 0.1793 - val_accuracy: 0.9611\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1702 - accuracy: 0.9633 - val_loss: 0.1806 - val_accuracy: 0.9611\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1698 - accuracy: 0.9633 - val_loss: 0.1791 - val_accuracy: 0.9611\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1693 - accuracy: 0.9633 - val_loss: 0.1791 - val_accuracy: 0.9611\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1691 - accuracy: 0.9633 - val_loss: 0.1802 - val_accuracy: 0.9611\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1687 - accuracy: 0.9633 - val_loss: 0.1794 - val_accuracy: 0.9611\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.1683 - accuracy: 0.9633 - val_loss: 0.1788 - val_accuracy: 0.9611\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.1682 - accuracy: 0.9633 - val_loss: 0.1810 - val_accuracy: 0.9611\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1677 - accuracy: 0.9633 - val_loss: 0.1771 - val_accuracy: 0.9611\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1668 - accuracy: 0.9633 - val_loss: 0.1767 - val_accuracy: 0.9611\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.1663 - accuracy: 0.9633 - val_loss: 0.1771 - val_accuracy: 0.9611\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1657 - accuracy: 0.9633 - val_loss: 0.1775 - val_accuracy: 0.9611\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1655 - accuracy: 0.9633 - val_loss: 0.1758 - val_accuracy: 0.9611\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.1652 - accuracy: 0.9633 - val_loss: 0.1761 - val_accuracy: 0.9611\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.1646 - accuracy: 0.9633 - val_loss: 0.1766 - val_accuracy: 0.9611\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.1644 - accuracy: 0.9632 - val_loss: 0.1757 - val_accuracy: 0.9611\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.1646 - accuracy: 0.9632 - val_loss: 0.1761 - val_accuracy: 0.9609\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.1643 - accuracy: 0.9632 - val_loss: 0.1753 - val_accuracy: 0.9611\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.1639 - accuracy: 0.9633 - val_loss: 0.1756 - val_accuracy: 0.9611\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.1639 - accuracy: 0.9632 - val_loss: 0.1749 - val_accuracy: 0.9613\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1638 - accuracy: 0.9633 - val_loss: 0.1752 - val_accuracy: 0.9610\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.1634 - accuracy: 0.9632 - val_loss: 0.1748 - val_accuracy: 0.9612\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.1631 - accuracy: 0.9632 - val_loss: 0.1751 - val_accuracy: 0.9611\n",
      "Epoch 27/100\n",
      " - 4s - loss: 0.1631 - accuracy: 0.9632 - val_loss: 0.1741 - val_accuracy: 0.9611\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1632 - accuracy: 0.9633 - val_loss: 0.1758 - val_accuracy: 0.9609\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.1628 - accuracy: 0.9632 - val_loss: 0.1745 - val_accuracy: 0.9610\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.1627 - accuracy: 0.9632 - val_loss: 0.1764 - val_accuracy: 0.9610\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.1625 - accuracy: 0.9632 - val_loss: 0.1740 - val_accuracy: 0.9610\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.1625 - accuracy: 0.9632 - val_loss: 0.1748 - val_accuracy: 0.9613\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.1621 - accuracy: 0.9632 - val_loss: 0.1753 - val_accuracy: 0.9611\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.1620 - accuracy: 0.9633 - val_loss: 0.1756 - val_accuracy: 0.9610\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.1620 - accuracy: 0.9633 - val_loss: 0.1752 - val_accuracy: 0.9609\n",
      "Epoch 36/100\n",
      " - 2s - loss: 0.1614 - accuracy: 0.9633 - val_loss: 0.1741 - val_accuracy: 0.9610\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.1616 - accuracy: 0.9631 - val_loss: 0.1759 - val_accuracy: 0.9611\n",
      "Epoch 38/100\n",
      " - 2s - loss: 0.1615 - accuracy: 0.9631 - val_loss: 0.1745 - val_accuracy: 0.9609\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.1614 - accuracy: 0.9633 - val_loss: 0.1757 - val_accuracy: 0.9611\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.1612 - accuracy: 0.9634 - val_loss: 0.1750 - val_accuracy: 0.9611\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.1612 - accuracy: 0.9632 - val_loss: 0.1738 - val_accuracy: 0.9610\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.1612 - accuracy: 0.9633 - val_loss: 0.1743 - val_accuracy: 0.9610\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.1608 - accuracy: 0.9632 - val_loss: 0.1759 - val_accuracy: 0.9611\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.1606 - accuracy: 0.9633 - val_loss: 0.1743 - val_accuracy: 0.9612\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.1606 - accuracy: 0.9633 - val_loss: 0.1753 - val_accuracy: 0.9610\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.1605 - accuracy: 0.9633 - val_loss: 0.1747 - val_accuracy: 0.9615\n",
      "Epoch 47/100\n",
      " - 2s - loss: 0.1606 - accuracy: 0.9632 - val_loss: 0.1736 - val_accuracy: 0.9609\n",
      "Epoch 48/100\n",
      " - 6s - loss: 0.1604 - accuracy: 0.9632 - val_loss: 0.1744 - val_accuracy: 0.9609\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.1602 - accuracy: 0.9633 - val_loss: 0.1742 - val_accuracy: 0.9609\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.1600 - accuracy: 0.9633 - val_loss: 0.1755 - val_accuracy: 0.9610\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.1598 - accuracy: 0.9634 - val_loss: 0.1747 - val_accuracy: 0.9610\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.1597 - accuracy: 0.9633 - val_loss: 0.1750 - val_accuracy: 0.9606\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.1598 - accuracy: 0.9634 - val_loss: 0.1741 - val_accuracy: 0.9608\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.1597 - accuracy: 0.9634 - val_loss: 0.1745 - val_accuracy: 0.9609\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.1596 - accuracy: 0.9634 - val_loss: 0.1747 - val_accuracy: 0.9608\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.1594 - accuracy: 0.9631 - val_loss: 0.1762 - val_accuracy: 0.9610\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.1594 - accuracy: 0.9632 - val_loss: 0.1750 - val_accuracy: 0.9608\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.1592 - accuracy: 0.9633 - val_loss: 0.1747 - val_accuracy: 0.9614\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.1591 - accuracy: 0.9635 - val_loss: 0.1798 - val_accuracy: 0.9611\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.1592 - accuracy: 0.9633 - val_loss: 0.1751 - val_accuracy: 0.9610\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.1590 - accuracy: 0.9632 - val_loss: 0.1752 - val_accuracy: 0.9612\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.1590 - accuracy: 0.9633 - val_loss: 0.1749 - val_accuracy: 0.9612\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.1587 - accuracy: 0.9633 - val_loss: 0.1754 - val_accuracy: 0.9609\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.1585 - accuracy: 0.9635 - val_loss: 0.1747 - val_accuracy: 0.9609\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.1586 - accuracy: 0.9634 - val_loss: 0.1763 - val_accuracy: 0.9610\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.1583 - accuracy: 0.9634 - val_loss: 0.1751 - val_accuracy: 0.9609\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.1582 - accuracy: 0.9634 - val_loss: 0.1755 - val_accuracy: 0.9610\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.1586 - accuracy: 0.9633 - val_loss: 0.1748 - val_accuracy: 0.9610\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.1583 - accuracy: 0.9634 - val_loss: 0.1747 - val_accuracy: 0.9612\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.1579 - accuracy: 0.9633 - val_loss: 0.1768 - val_accuracy: 0.9610\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.1580 - accuracy: 0.9635 - val_loss: 0.1759 - val_accuracy: 0.9608\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.1579 - accuracy: 0.9634 - val_loss: 0.1763 - val_accuracy: 0.9610\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.1579 - accuracy: 0.9634 - val_loss: 0.1757 - val_accuracy: 0.9608\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.1577 - accuracy: 0.9632 - val_loss: 0.1755 - val_accuracy: 0.9610\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.1579 - accuracy: 0.9634 - val_loss: 0.1757 - val_accuracy: 0.9610\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.1577 - accuracy: 0.9635 - val_loss: 0.1762 - val_accuracy: 0.9609\n",
      "Epoch 77/100\n",
      " - 5s - loss: 0.1576 - accuracy: 0.9634 - val_loss: 0.1749 - val_accuracy: 0.9608\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.1575 - accuracy: 0.9635 - val_loss: 0.1778 - val_accuracy: 0.9610\n",
      "Epoch 79/100\n",
      " - 4s - loss: 0.1576 - accuracy: 0.9634 - val_loss: 0.1748 - val_accuracy: 0.9610\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.1573 - accuracy: 0.9633 - val_loss: 0.1761 - val_accuracy: 0.9608\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.1573 - accuracy: 0.9635 - val_loss: 0.1752 - val_accuracy: 0.9610\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.1573 - accuracy: 0.9634 - val_loss: 0.1761 - val_accuracy: 0.9610\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.1569 - accuracy: 0.9635 - val_loss: 0.1802 - val_accuracy: 0.9610\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.1570 - accuracy: 0.9634 - val_loss: 0.1750 - val_accuracy: 0.9608\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.1571 - accuracy: 0.9634 - val_loss: 0.1760 - val_accuracy: 0.9609\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.1567 - accuracy: 0.9635 - val_loss: 0.1773 - val_accuracy: 0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 3s - loss: 0.1570 - accuracy: 0.9635 - val_loss: 0.1773 - val_accuracy: 0.9609\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.1568 - accuracy: 0.9636 - val_loss: 0.1766 - val_accuracy: 0.9608\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.1569 - accuracy: 0.9634 - val_loss: 0.1753 - val_accuracy: 0.9610\n",
      "Epoch 90/100\n",
      " - 4s - loss: 0.1569 - accuracy: 0.9632 - val_loss: 0.1763 - val_accuracy: 0.9609\n",
      "Epoch 91/100\n",
      " - 4s - loss: 0.1566 - accuracy: 0.9634 - val_loss: 0.1776 - val_accuracy: 0.9608\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.1566 - accuracy: 0.9634 - val_loss: 0.1767 - val_accuracy: 0.9605\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.1568 - accuracy: 0.9635 - val_loss: 0.1757 - val_accuracy: 0.9608\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.1566 - accuracy: 0.9634 - val_loss: 0.1761 - val_accuracy: 0.9608\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.1563 - accuracy: 0.9634 - val_loss: 0.1776 - val_accuracy: 0.9607\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.1563 - accuracy: 0.9635 - val_loss: 0.1773 - val_accuracy: 0.9607\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.1560 - accuracy: 0.9634 - val_loss: 0.1790 - val_accuracy: 0.9609\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.1564 - accuracy: 0.9634 - val_loss: 0.1786 - val_accuracy: 0.9610\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.1563 - accuracy: 0.9633 - val_loss: 0.1773 - val_accuracy: 0.9609\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.1558 - accuracy: 0.9635 - val_loss: 0.1760 - val_accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "# Now onto training & validating the model 5\n",
    "hist = model.fit(\n",
    "    X_train, Y_train,          \n",
    "    batch_size=32, \n",
    "    epochs=100,   \n",
    "    verbose=2,\n",
    "    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "11749/11749 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9629755616188049"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model 5 on test dataset\n",
    "# [1] gives the accuracy, [0] is for loss\n",
    "print(\"Accuracy: \") \n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11749/11749 [==============================] - 0s 29us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     11317\n",
      "           1       0.00      0.00      0.00        94\n",
      "           2       0.38      0.01      0.03       338\n",
      "\n",
      "    accuracy                           0.96     11749\n",
      "   macro avg       0.45      0.34      0.34     11749\n",
      "weighted avg       0.94      0.96      0.95     11749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# model 5\n",
    "# Using sklearn displaying a classification report\n",
    "# Precision & recall can be highly important for an imbalanced dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "rounded_labels=np.argmax(Y_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(rounded_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6\n",
    "# Using Feature Selection (manual)\n",
    "# Cost Sensitive (Class Weights) Neural Network Model using Keras (Tensorflow backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:  [ 0.34615028 45.32465278 11.23364888]\n",
      "Input and output shape:\n",
      " (54824, 8) (11748, 8) (11749, 8) (54824, 3) (11748, 3) (11749, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass classes=[0 1 2], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Using Feature Selection (manual)\n",
    "# Cost Sensitive (Class Weights) Neural Network Model using Keras (Tensorflow backend)\n",
    "# model 6\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load and encode the dataset\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "\n",
    "# Dropping columns 'article_id','created_date' & 'deleted_date' as I feel they do not have \n",
    "# any significant importance in predicting 'product_tier'\n",
    "df = df.drop(['article_id','created_date','deleted_date'], axis = 1)\n",
    "\n",
    "# Mapping_Tier = {\"Basic\":0, \"Plus\":0.5, \"Premium\":1}\n",
    "# df[\"product_tier\"] = df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Define automated class weights \n",
    "# This can help to provide some bias towards the minority class\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "print(\"Class weights: \", class_weights)\n",
    "\n",
    "# Convert label to categorical values\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Now scaling the dataset so that all the input features lie between 0 and 1 inclusive\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into train, validate and test\n",
    "# Can also use k-fold Cross-Validation - but it takes longer to process therefore I went with random split\n",
    "# Also to note: k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=0)\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "# Define the Neural Network Architecture \n",
    "model = Sequential([    \n",
    "                    Dense(32, activation='relu', input_dim = 8),    \n",
    "                    Dense(32, activation='relu'),    \n",
    "                    Dense(3, activation='softmax'),])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',            \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54824 samples, validate on 11748 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.1830 - accuracy: 0.9631 - val_loss: 0.1714 - val_accuracy: 0.9634\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.1736 - accuracy: 0.9631 - val_loss: 0.1714 - val_accuracy: 0.9634\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1728 - accuracy: 0.9631 - val_loss: 0.1696 - val_accuracy: 0.9634\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1722 - accuracy: 0.9631 - val_loss: 0.1691 - val_accuracy: 0.9634\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1719 - accuracy: 0.9631 - val_loss: 0.1688 - val_accuracy: 0.9634\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1715 - accuracy: 0.9631 - val_loss: 0.1691 - val_accuracy: 0.9634\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1711 - accuracy: 0.9631 - val_loss: 0.1689 - val_accuracy: 0.9634\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1708 - accuracy: 0.9631 - val_loss: 0.1684 - val_accuracy: 0.9634\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1705 - accuracy: 0.9631 - val_loss: 0.1694 - val_accuracy: 0.9634\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1704 - accuracy: 0.9631 - val_loss: 0.1684 - val_accuracy: 0.9634\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.1699 - accuracy: 0.9631 - val_loss: 0.1684 - val_accuracy: 0.9634\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.1699 - accuracy: 0.9631 - val_loss: 0.1676 - val_accuracy: 0.9634\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1696 - accuracy: 0.9631 - val_loss: 0.1676 - val_accuracy: 0.9634\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1692 - accuracy: 0.9631 - val_loss: 0.1682 - val_accuracy: 0.9634\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1689 - accuracy: 0.9631 - val_loss: 0.1691 - val_accuracy: 0.9634\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1686 - accuracy: 0.9631 - val_loss: 0.1669 - val_accuracy: 0.9634\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.1677 - accuracy: 0.9631 - val_loss: 0.1669 - val_accuracy: 0.9634\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.1673 - accuracy: 0.9631 - val_loss: 0.1671 - val_accuracy: 0.9634\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.1666 - accuracy: 0.9631 - val_loss: 0.1650 - val_accuracy: 0.9634\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.1662 - accuracy: 0.9631 - val_loss: 0.1660 - val_accuracy: 0.9634\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.1658 - accuracy: 0.9631 - val_loss: 0.1649 - val_accuracy: 0.9634\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.1655 - accuracy: 0.9631 - val_loss: 0.1643 - val_accuracy: 0.9634\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.1654 - accuracy: 0.9631 - val_loss: 0.1656 - val_accuracy: 0.9632\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1655 - accuracy: 0.9631 - val_loss: 0.1684 - val_accuracy: 0.9630\n",
      "Epoch 25/100\n",
      " - 2s - loss: 0.1653 - accuracy: 0.9631 - val_loss: 0.1652 - val_accuracy: 0.9634\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.1647 - accuracy: 0.9631 - val_loss: 0.1666 - val_accuracy: 0.9634\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.1647 - accuracy: 0.9631 - val_loss: 0.1654 - val_accuracy: 0.9631\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1646 - accuracy: 0.9631 - val_loss: 0.1645 - val_accuracy: 0.9634\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.1645 - accuracy: 0.9631 - val_loss: 0.1668 - val_accuracy: 0.9634\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.1644 - accuracy: 0.9632 - val_loss: 0.1659 - val_accuracy: 0.9629\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.1645 - accuracy: 0.9631 - val_loss: 0.1654 - val_accuracy: 0.9634\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.1640 - accuracy: 0.9631 - val_loss: 0.1643 - val_accuracy: 0.9634\n",
      "Epoch 33/100\n",
      " - 2s - loss: 0.1641 - accuracy: 0.9630 - val_loss: 0.1646 - val_accuracy: 0.9633\n",
      "Epoch 34/100\n",
      " - 2s - loss: 0.1640 - accuracy: 0.9631 - val_loss: 0.1653 - val_accuracy: 0.9634\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.1638 - accuracy: 0.9631 - val_loss: 0.1654 - val_accuracy: 0.9633\n",
      "Epoch 36/100\n",
      " - 2s - loss: 0.1637 - accuracy: 0.9632 - val_loss: 0.1636 - val_accuracy: 0.9633\n",
      "Epoch 37/100\n",
      " - 2s - loss: 0.1636 - accuracy: 0.9631 - val_loss: 0.1645 - val_accuracy: 0.9631\n",
      "Epoch 38/100\n",
      " - 4s - loss: 0.1637 - accuracy: 0.9632 - val_loss: 0.1666 - val_accuracy: 0.9634\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.1636 - accuracy: 0.9630 - val_loss: 0.1679 - val_accuracy: 0.9633\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.1635 - accuracy: 0.9632 - val_loss: 0.1652 - val_accuracy: 0.9634\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.1633 - accuracy: 0.9630 - val_loss: 0.1665 - val_accuracy: 0.9632\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.1632 - accuracy: 0.9631 - val_loss: 0.1651 - val_accuracy: 0.9632\n",
      "Epoch 43/100\n",
      " - 2s - loss: 0.1630 - accuracy: 0.9631 - val_loss: 0.1644 - val_accuracy: 0.9633\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.1633 - accuracy: 0.9631 - val_loss: 0.1643 - val_accuracy: 0.9632\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.1629 - accuracy: 0.9631 - val_loss: 0.1648 - val_accuracy: 0.9634\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.1629 - accuracy: 0.9631 - val_loss: 0.1648 - val_accuracy: 0.9634\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.1628 - accuracy: 0.9631 - val_loss: 0.1642 - val_accuracy: 0.9634\n",
      "Epoch 48/100\n",
      " - 2s - loss: 0.1627 - accuracy: 0.9630 - val_loss: 0.1643 - val_accuracy: 0.9632\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.1624 - accuracy: 0.9631 - val_loss: 0.1658 - val_accuracy: 0.9632\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.1623 - accuracy: 0.9631 - val_loss: 0.1655 - val_accuracy: 0.9634\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.1622 - accuracy: 0.9631 - val_loss: 0.1651 - val_accuracy: 0.9633\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.1622 - accuracy: 0.9632 - val_loss: 0.1644 - val_accuracy: 0.9633\n",
      "Epoch 53/100\n",
      " - 2s - loss: 0.1622 - accuracy: 0.9632 - val_loss: 0.1648 - val_accuracy: 0.9634\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.1622 - accuracy: 0.9631 - val_loss: 0.1647 - val_accuracy: 0.9634\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.1620 - accuracy: 0.9632 - val_loss: 0.1658 - val_accuracy: 0.9632\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.1618 - accuracy: 0.9631 - val_loss: 0.1651 - val_accuracy: 0.9633\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.1620 - accuracy: 0.9631 - val_loss: 0.1652 - val_accuracy: 0.9632\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.1619 - accuracy: 0.9632 - val_loss: 0.1653 - val_accuracy: 0.9635\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.1616 - accuracy: 0.9632 - val_loss: 0.1664 - val_accuracy: 0.9632\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.1618 - accuracy: 0.9632 - val_loss: 0.1648 - val_accuracy: 0.9629\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.1615 - accuracy: 0.9630 - val_loss: 0.1673 - val_accuracy: 0.9626\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.1617 - accuracy: 0.9631 - val_loss: 0.1642 - val_accuracy: 0.9633\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.1617 - accuracy: 0.9632 - val_loss: 0.1650 - val_accuracy: 0.9634\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.1613 - accuracy: 0.9631 - val_loss: 0.1644 - val_accuracy: 0.9632\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.1612 - accuracy: 0.9632 - val_loss: 0.1652 - val_accuracy: 0.9634\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.1609 - accuracy: 0.9632 - val_loss: 0.1649 - val_accuracy: 0.9631\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.1612 - accuracy: 0.9632 - val_loss: 0.1652 - val_accuracy: 0.9633\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.1611 - accuracy: 0.9631 - val_loss: 0.1648 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.1613 - accuracy: 0.9632 - val_loss: 0.1647 - val_accuracy: 0.9633\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.1608 - accuracy: 0.9631 - val_loss: 0.1655 - val_accuracy: 0.9632\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.1609 - accuracy: 0.9632 - val_loss: 0.1653 - val_accuracy: 0.9633\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.1612 - accuracy: 0.9632 - val_loss: 0.1657 - val_accuracy: 0.9635\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.1607 - accuracy: 0.9631 - val_loss: 0.1658 - val_accuracy: 0.9634\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.1607 - accuracy: 0.9631 - val_loss: 0.1646 - val_accuracy: 0.9632\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.1608 - accuracy: 0.9632 - val_loss: 0.1652 - val_accuracy: 0.9630\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.1605 - accuracy: 0.9632 - val_loss: 0.1665 - val_accuracy: 0.9632\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.1609 - accuracy: 0.9632 - val_loss: 0.1656 - val_accuracy: 0.9633\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.1603 - accuracy: 0.9632 - val_loss: 0.1652 - val_accuracy: 0.9634\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.1604 - accuracy: 0.9631 - val_loss: 0.1650 - val_accuracy: 0.9634\n",
      "Epoch 80/100\n",
      " - 4s - loss: 0.1603 - accuracy: 0.9632 - val_loss: 0.1657 - val_accuracy: 0.9635\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.1600 - accuracy: 0.9632 - val_loss: 0.1652 - val_accuracy: 0.9631\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.1603 - accuracy: 0.9632 - val_loss: 0.1655 - val_accuracy: 0.9634\n",
      "Epoch 83/100\n",
      " - 2s - loss: 0.1604 - accuracy: 0.9633 - val_loss: 0.1649 - val_accuracy: 0.9631\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.1601 - accuracy: 0.9632 - val_loss: 0.1650 - val_accuracy: 0.9636\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.1599 - accuracy: 0.9633 - val_loss: 0.1652 - val_accuracy: 0.9633\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.1601 - accuracy: 0.9631 - val_loss: 0.1652 - val_accuracy: 0.9631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 2s - loss: 0.1599 - accuracy: 0.9631 - val_loss: 0.1655 - val_accuracy: 0.9634\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.1599 - accuracy: 0.9632 - val_loss: 0.1652 - val_accuracy: 0.9632\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.1597 - accuracy: 0.9634 - val_loss: 0.1652 - val_accuracy: 0.9631\n",
      "Epoch 90/100\n",
      " - 5s - loss: 0.1599 - accuracy: 0.9633 - val_loss: 0.1654 - val_accuracy: 0.9634\n",
      "Epoch 91/100\n",
      " - 5s - loss: 0.1597 - accuracy: 0.9632 - val_loss: 0.1659 - val_accuracy: 0.9631\n",
      "Epoch 92/100\n",
      " - 4s - loss: 0.1597 - accuracy: 0.9633 - val_loss: 0.1685 - val_accuracy: 0.9633\n",
      "Epoch 93/100\n",
      " - 5s - loss: 0.1594 - accuracy: 0.9633 - val_loss: 0.1652 - val_accuracy: 0.9634\n",
      "Epoch 94/100\n",
      " - 4s - loss: 0.1596 - accuracy: 0.9632 - val_loss: 0.1659 - val_accuracy: 0.9631\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.1594 - accuracy: 0.9634 - val_loss: 0.1669 - val_accuracy: 0.9631\n",
      "Epoch 96/100\n",
      " - 4s - loss: 0.1593 - accuracy: 0.9633 - val_loss: 0.1653 - val_accuracy: 0.9632\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.1594 - accuracy: 0.9632 - val_loss: 0.1664 - val_accuracy: 0.9633\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.1592 - accuracy: 0.9632 - val_loss: 0.1653 - val_accuracy: 0.9634\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.1593 - accuracy: 0.9632 - val_loss: 0.1652 - val_accuracy: 0.9632\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.1591 - accuracy: 0.9632 - val_loss: 0.1653 - val_accuracy: 0.9631\n"
     ]
    }
   ],
   "source": [
    "# Now onto training & validating the model 6\n",
    "hist = model.fit(\n",
    "    X_train, Y_train,          \n",
    "    batch_size=32, \n",
    "    epochs=100,   \n",
    "    verbose=2,\n",
    "    class_weight=class_weights,\n",
    "    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "11749/11749 [==============================] - 0s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9620393514633179"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model 6 on test dataset\n",
    "# [1] gives the accuracy, [0] is for loss\n",
    "print(\"Accuracy: \") \n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11749/11749 [==============================] - 0s 11us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     11302\n",
      "           1       0.00      0.00      0.00        78\n",
      "           2       0.67      0.01      0.01       369\n",
      "\n",
      "    accuracy                           0.96     11749\n",
      "   macro avg       0.54      0.34      0.33     11749\n",
      "weighted avg       0.95      0.96      0.94     11749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# model 6\n",
    "# Using sklearn displaying a classification report\n",
    "# Precision & recall can be highly important for an imbalanced dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "rounded_labels=np.argmax(Y_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(rounded_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 7\n",
    "# Using Feature Selection (manual)\n",
    "# Over-sampling the dataset using SMOTE\n",
    "# Neural Network Model using Keras (Tensorflow backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output shape:\n",
      " (158384, 8) (33939, 8) (33940, 8) (158384, 3) (33939, 3) (33940, 3)\n"
     ]
    }
   ],
   "source": [
    "# Using Feature Selection (manual)\n",
    "# Over-sampling the dataset using SMOTE\n",
    "# Neural Network Model using Keras (Tensorflow backend)\n",
    "# model 7\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load and encode the dataset\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "\n",
    "# Dropping columns 'article_id','created_date' & 'deleted_date' as I feel they do not have \n",
    "# any significant importance in predicting 'product_tier'\n",
    "df = df.drop(['article_id','created_date','deleted_date'], axis = 1)\n",
    "\n",
    "# Mapping_Tier = {\"Basic\":0, \"Plus\":0.5, \"Premium\":1}\n",
    "# df[\"product_tier\"] = df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "oversample = SMOTE(random_state=12)\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "# Convert label to categorical values\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Now scaling the dataset so that all the input features lie between 0 and 1 inclusive\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into train, validate and test\n",
    "# Can also use k-fold Cross-Validation - but it takes longer to process therefore I went with random split\n",
    "# Also to note: k-fold cross-validation is not appropriate for evaluating imbalanced classifiers.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=0)\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "\n",
    "# Define the Neural Network Architecture \n",
    "model = Sequential([    \n",
    "                    Dense(32, activation='relu', input_dim = 8),    \n",
    "                    Dense(32, activation='relu'),    \n",
    "                    Dense(3, activation='softmax'),])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',            \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 158384 samples, validate on 33939 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.0174 - accuracy: 0.4791 - val_loss: 0.9805 - val_accuracy: 0.5086\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.9682 - accuracy: 0.5237 - val_loss: 0.9525 - val_accuracy: 0.5380\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.9432 - accuracy: 0.5441 - val_loss: 0.9387 - val_accuracy: 0.5442\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.9244 - accuracy: 0.5584 - val_loss: 0.9135 - val_accuracy: 0.5664\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.9083 - accuracy: 0.5701 - val_loss: 0.9008 - val_accuracy: 0.5726\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.8929 - accuracy: 0.5811 - val_loss: 0.8882 - val_accuracy: 0.5819\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.8809 - accuracy: 0.5888 - val_loss: 0.8847 - val_accuracy: 0.5816\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.8712 - accuracy: 0.5940 - val_loss: 0.8700 - val_accuracy: 0.5972\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.8628 - accuracy: 0.6003 - val_loss: 0.8650 - val_accuracy: 0.5977\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.8551 - accuracy: 0.6048 - val_loss: 0.8537 - val_accuracy: 0.6039\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.8483 - accuracy: 0.6093 - val_loss: 0.8644 - val_accuracy: 0.5909\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.8418 - accuracy: 0.6135 - val_loss: 0.8420 - val_accuracy: 0.6106\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.8355 - accuracy: 0.6169 - val_loss: 0.8372 - val_accuracy: 0.6137\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.8305 - accuracy: 0.6196 - val_loss: 0.8289 - val_accuracy: 0.6208\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.8255 - accuracy: 0.6238 - val_loss: 0.8277 - val_accuracy: 0.6176\n",
      "Epoch 16/100\n",
      " - 6s - loss: 0.8205 - accuracy: 0.6258 - val_loss: 0.8393 - val_accuracy: 0.6176\n",
      "Epoch 17/100\n",
      " - 5s - loss: 0.8163 - accuracy: 0.6278 - val_loss: 0.8258 - val_accuracy: 0.6242\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.8117 - accuracy: 0.6310 - val_loss: 0.8175 - val_accuracy: 0.6274\n",
      "Epoch 19/100\n",
      " - 6s - loss: 0.8074 - accuracy: 0.6332 - val_loss: 0.8093 - val_accuracy: 0.6313\n",
      "Epoch 20/100\n",
      " - 5s - loss: 0.8042 - accuracy: 0.6345 - val_loss: 0.8161 - val_accuracy: 0.6252\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.7999 - accuracy: 0.6376 - val_loss: 0.8043 - val_accuracy: 0.6332\n",
      "Epoch 22/100\n",
      " - 5s - loss: 0.7967 - accuracy: 0.6393 - val_loss: 0.8017 - val_accuracy: 0.6364\n",
      "Epoch 23/100\n",
      " - 6s - loss: 0.7940 - accuracy: 0.6418 - val_loss: 0.7992 - val_accuracy: 0.6362\n",
      "Epoch 24/100\n",
      " - 5s - loss: 0.7903 - accuracy: 0.6437 - val_loss: 0.7967 - val_accuracy: 0.6441\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.7867 - accuracy: 0.6451 - val_loss: 0.7930 - val_accuracy: 0.6387\n",
      "Epoch 26/100\n",
      " - 5s - loss: 0.7838 - accuracy: 0.6471 - val_loss: 0.8044 - val_accuracy: 0.6373\n",
      "Epoch 27/100\n",
      " - 5s - loss: 0.7802 - accuracy: 0.6481 - val_loss: 0.7824 - val_accuracy: 0.6476\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.7785 - accuracy: 0.6493 - val_loss: 0.7911 - val_accuracy: 0.6385\n",
      "Epoch 29/100\n",
      " - 5s - loss: 0.7747 - accuracy: 0.6513 - val_loss: 0.7910 - val_accuracy: 0.6407\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.7722 - accuracy: 0.6520 - val_loss: 0.7823 - val_accuracy: 0.6495\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.7701 - accuracy: 0.6541 - val_loss: 0.7765 - val_accuracy: 0.6510\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.7681 - accuracy: 0.6558 - val_loss: 0.7739 - val_accuracy: 0.6469\n",
      "Epoch 33/100\n",
      " - 5s - loss: 0.7666 - accuracy: 0.6556 - val_loss: 0.7719 - val_accuracy: 0.6505\n",
      "Epoch 34/100\n",
      " - 6s - loss: 0.7646 - accuracy: 0.6577 - val_loss: 0.7700 - val_accuracy: 0.6558\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.7625 - accuracy: 0.6583 - val_loss: 0.7768 - val_accuracy: 0.6483\n",
      "Epoch 36/100\n",
      " - 6s - loss: 0.7611 - accuracy: 0.6591 - val_loss: 0.7648 - val_accuracy: 0.6564\n",
      "Epoch 37/100\n",
      " - 6s - loss: 0.7592 - accuracy: 0.6609 - val_loss: 0.7662 - val_accuracy: 0.6566\n",
      "Epoch 38/100\n",
      " - 5s - loss: 0.7580 - accuracy: 0.6613 - val_loss: 0.7715 - val_accuracy: 0.6565\n",
      "Epoch 39/100\n",
      " - 5s - loss: 0.7557 - accuracy: 0.6624 - val_loss: 0.7554 - val_accuracy: 0.6639\n",
      "Epoch 40/100\n",
      " - 8s - loss: 0.7549 - accuracy: 0.6622 - val_loss: 0.7706 - val_accuracy: 0.6490\n",
      "Epoch 41/100\n",
      " - 6s - loss: 0.7531 - accuracy: 0.6641 - val_loss: 0.7660 - val_accuracy: 0.6507\n",
      "Epoch 42/100\n",
      " - 5s - loss: 0.7512 - accuracy: 0.6649 - val_loss: 0.7559 - val_accuracy: 0.6575\n",
      "Epoch 43/100\n",
      " - 7s - loss: 0.7502 - accuracy: 0.6638 - val_loss: 0.7576 - val_accuracy: 0.6620\n",
      "Epoch 44/100\n",
      " - 6s - loss: 0.7492 - accuracy: 0.6656 - val_loss: 0.7526 - val_accuracy: 0.6602\n",
      "Epoch 45/100\n",
      " - 7s - loss: 0.7473 - accuracy: 0.6663 - val_loss: 0.7568 - val_accuracy: 0.6633\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.7465 - accuracy: 0.6670 - val_loss: 0.7551 - val_accuracy: 0.6666\n",
      "Epoch 47/100\n",
      " - 6s - loss: 0.7447 - accuracy: 0.6687 - val_loss: 0.7529 - val_accuracy: 0.6670\n",
      "Epoch 48/100\n",
      " - 6s - loss: 0.7442 - accuracy: 0.6681 - val_loss: 0.7545 - val_accuracy: 0.6663\n",
      "Epoch 49/100\n",
      " - 6s - loss: 0.7431 - accuracy: 0.6695 - val_loss: 0.7511 - val_accuracy: 0.6700\n",
      "Epoch 50/100\n",
      " - 6s - loss: 0.7418 - accuracy: 0.6702 - val_loss: 0.7510 - val_accuracy: 0.6688\n",
      "Epoch 51/100\n",
      " - 5s - loss: 0.7403 - accuracy: 0.6712 - val_loss: 0.7532 - val_accuracy: 0.6644\n",
      "Epoch 52/100\n",
      " - 6s - loss: 0.7391 - accuracy: 0.6721 - val_loss: 0.7419 - val_accuracy: 0.6717\n",
      "Epoch 53/100\n",
      " - 6s - loss: 0.7393 - accuracy: 0.6722 - val_loss: 0.7512 - val_accuracy: 0.6660\n",
      "Epoch 54/100\n",
      " - 8s - loss: 0.7376 - accuracy: 0.6734 - val_loss: 0.7532 - val_accuracy: 0.6630\n",
      "Epoch 55/100\n",
      " - 6s - loss: 0.7372 - accuracy: 0.6722 - val_loss: 0.7536 - val_accuracy: 0.6628\n",
      "Epoch 56/100\n",
      " - 7s - loss: 0.7362 - accuracy: 0.6732 - val_loss: 0.7413 - val_accuracy: 0.6683\n",
      "Epoch 57/100\n",
      " - 8s - loss: 0.7351 - accuracy: 0.6742 - val_loss: 0.7390 - val_accuracy: 0.6757\n",
      "Epoch 58/100\n",
      " - 7s - loss: 0.7345 - accuracy: 0.6752 - val_loss: 0.7425 - val_accuracy: 0.6724\n",
      "Epoch 59/100\n",
      " - 8s - loss: 0.7334 - accuracy: 0.6764 - val_loss: 0.7553 - val_accuracy: 0.6644\n",
      "Epoch 60/100\n",
      " - 7s - loss: 0.7320 - accuracy: 0.6768 - val_loss: 0.7369 - val_accuracy: 0.6783\n",
      "Epoch 61/100\n",
      " - 7s - loss: 0.7317 - accuracy: 0.6759 - val_loss: 0.7360 - val_accuracy: 0.6768\n",
      "Epoch 62/100\n",
      " - 7s - loss: 0.7318 - accuracy: 0.6761 - val_loss: 0.7344 - val_accuracy: 0.6762\n",
      "Epoch 63/100\n",
      " - 8s - loss: 0.7294 - accuracy: 0.6772 - val_loss: 0.7387 - val_accuracy: 0.6716\n",
      "Epoch 64/100\n",
      " - 7s - loss: 0.7304 - accuracy: 0.6760 - val_loss: 0.7454 - val_accuracy: 0.6678\n",
      "Epoch 65/100\n",
      " - 6s - loss: 0.7297 - accuracy: 0.6778 - val_loss: 0.7569 - val_accuracy: 0.6564\n",
      "Epoch 66/100\n",
      " - 5s - loss: 0.7280 - accuracy: 0.6778 - val_loss: 0.7359 - val_accuracy: 0.6752\n",
      "Epoch 67/100\n",
      " - 6s - loss: 0.7277 - accuracy: 0.6779 - val_loss: 0.7402 - val_accuracy: 0.6682\n",
      "Epoch 68/100\n",
      " - 6s - loss: 0.7270 - accuracy: 0.6791 - val_loss: 0.7453 - val_accuracy: 0.6641\n",
      "Epoch 69/100\n",
      " - 6s - loss: 0.7275 - accuracy: 0.6788 - val_loss: 0.7422 - val_accuracy: 0.6654\n",
      "Epoch 70/100\n",
      " - 6s - loss: 0.7261 - accuracy: 0.6788 - val_loss: 0.7373 - val_accuracy: 0.6738\n",
      "Epoch 71/100\n",
      " - 6s - loss: 0.7258 - accuracy: 0.6796 - val_loss: 0.7417 - val_accuracy: 0.6721\n",
      "Epoch 72/100\n",
      " - 6s - loss: 0.7256 - accuracy: 0.6798 - val_loss: 0.7373 - val_accuracy: 0.6711\n",
      "Epoch 73/100\n",
      " - 6s - loss: 0.7248 - accuracy: 0.6788 - val_loss: 0.7302 - val_accuracy: 0.6791\n",
      "Epoch 74/100\n",
      " - 6s - loss: 0.7240 - accuracy: 0.6804 - val_loss: 0.7377 - val_accuracy: 0.6714\n",
      "Epoch 75/100\n",
      " - 6s - loss: 0.7237 - accuracy: 0.6810 - val_loss: 0.7382 - val_accuracy: 0.6746\n",
      "Epoch 76/100\n",
      " - 6s - loss: 0.7226 - accuracy: 0.6805 - val_loss: 0.7273 - val_accuracy: 0.6792\n",
      "Epoch 77/100\n",
      " - 6s - loss: 0.7230 - accuracy: 0.6806 - val_loss: 0.7253 - val_accuracy: 0.6822\n",
      "Epoch 78/100\n",
      " - 6s - loss: 0.7221 - accuracy: 0.6816 - val_loss: 0.7371 - val_accuracy: 0.6739\n",
      "Epoch 79/100\n",
      " - 5s - loss: 0.7208 - accuracy: 0.6817 - val_loss: 0.7530 - val_accuracy: 0.6597\n",
      "Epoch 80/100\n",
      " - 6s - loss: 0.7213 - accuracy: 0.6812 - val_loss: 0.7269 - val_accuracy: 0.6793\n",
      "Epoch 81/100\n",
      " - 5s - loss: 0.7197 - accuracy: 0.6831 - val_loss: 0.7271 - val_accuracy: 0.6784\n",
      "Epoch 82/100\n",
      " - 6s - loss: 0.7198 - accuracy: 0.6821 - val_loss: 0.7288 - val_accuracy: 0.6794\n",
      "Epoch 83/100\n",
      " - 6s - loss: 0.7191 - accuracy: 0.6820 - val_loss: 0.7310 - val_accuracy: 0.6747\n",
      "Epoch 84/100\n",
      " - 6s - loss: 0.7190 - accuracy: 0.6826 - val_loss: 0.7428 - val_accuracy: 0.6742\n",
      "Epoch 85/100\n",
      " - 6s - loss: 0.7183 - accuracy: 0.6828 - val_loss: 0.7391 - val_accuracy: 0.6705\n",
      "Epoch 86/100\n",
      " - 5s - loss: 0.7186 - accuracy: 0.6826 - val_loss: 0.7292 - val_accuracy: 0.6739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 5s - loss: 0.7174 - accuracy: 0.6841 - val_loss: 0.7267 - val_accuracy: 0.6799\n",
      "Epoch 88/100\n",
      " - 5s - loss: 0.7166 - accuracy: 0.6833 - val_loss: 0.7244 - val_accuracy: 0.6782\n",
      "Epoch 89/100\n",
      " - 6s - loss: 0.7161 - accuracy: 0.6845 - val_loss: 0.7249 - val_accuracy: 0.6803\n",
      "Epoch 90/100\n",
      " - 5s - loss: 0.7152 - accuracy: 0.6838 - val_loss: 0.7296 - val_accuracy: 0.6790\n",
      "Epoch 91/100\n",
      " - 5s - loss: 0.7152 - accuracy: 0.6851 - val_loss: 0.7373 - val_accuracy: 0.6775\n",
      "Epoch 92/100\n",
      " - 5s - loss: 0.7152 - accuracy: 0.6844 - val_loss: 0.7307 - val_accuracy: 0.6738\n",
      "Epoch 93/100\n",
      " - 6s - loss: 0.7146 - accuracy: 0.6851 - val_loss: 0.7303 - val_accuracy: 0.6757\n",
      "Epoch 94/100\n",
      " - 5s - loss: 0.7138 - accuracy: 0.6842 - val_loss: 0.7337 - val_accuracy: 0.6750\n",
      "Epoch 95/100\n",
      " - 5s - loss: 0.7139 - accuracy: 0.6841 - val_loss: 0.7407 - val_accuracy: 0.6704\n",
      "Epoch 96/100\n",
      " - 6s - loss: 0.7135 - accuracy: 0.6842 - val_loss: 0.7330 - val_accuracy: 0.6743\n",
      "Epoch 97/100\n",
      " - 5s - loss: 0.7132 - accuracy: 0.6854 - val_loss: 0.7245 - val_accuracy: 0.6781\n",
      "Epoch 98/100\n",
      " - 5s - loss: 0.7121 - accuracy: 0.6865 - val_loss: 0.7366 - val_accuracy: 0.6743\n",
      "Epoch 99/100\n",
      " - 5s - loss: 0.7119 - accuracy: 0.6856 - val_loss: 0.7178 - val_accuracy: 0.6820\n",
      "Epoch 100/100\n",
      " - 6s - loss: 0.7113 - accuracy: 0.6864 - val_loss: 0.7364 - val_accuracy: 0.6716\n"
     ]
    }
   ],
   "source": [
    "# Now onto training & validating the model 7\n",
    "hist = model.fit(\n",
    "    X_train, Y_train,          \n",
    "    batch_size=32, \n",
    "    epochs=100,   \n",
    "    verbose=2,\n",
    "    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "33940/33940 [==============================] - 1s 25us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6800235509872437"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model 7 on test dataset\n",
    "# [1] gives the accuracy, [0] is for loss\n",
    "print(\"Accuracy: \") \n",
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33940/33940 [==============================] - 0s 10us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65     11424\n",
      "           1       0.70      0.82      0.75     11177\n",
      "           2       0.67      0.59      0.63     11339\n",
      "\n",
      "    accuracy                           0.68     33940\n",
      "   macro avg       0.68      0.68      0.68     33940\n",
      "weighted avg       0.68      0.68      0.68     33940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 7\n",
    "# Using sklearn displaying a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np \n",
    "\n",
    "rounded_labels=np.argmax(Y_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=32, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(rounded_labels, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proves that, the Feature selection methodology I used, did not highly affect the accuracy of the model.\n",
    "But limiting the features, helps reducing complexity of the model and helps reduce over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As what we have seen so far, 'Over-sampling' gives a good overall precision to each class (70% on an avg).\n",
    "Even though 'Over-sampling' is not always a good idea.\n",
    "\n",
    "But for this particular use-case, \n",
    "we can get a better understanding on how a model would work with a balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating K-Nearest Neighbours and Support Vector Machine algorithm on the original dataset\n",
    "\n",
    "kNN and SVM, in principle are not very sensitive to imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output shape:\n",
      " (54824, 11) (23497, 11) (54824,) (23497,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "Mapping_Tier = {\"Basic\":0, \"Plus\":1, \"Premium\":2}\n",
    "df[\"product_tier\"] = df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "# y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basic       0.96      1.00      0.98     22636\n",
      "        Plus       0.00      0.00      0.00       172\n",
      "     Premium       0.08      0.00      0.00       689\n",
      "\n",
      "    accuracy                           0.96     23497\n",
      "   macro avg       0.35      0.33      0.33     23497\n",
      "weighted avg       0.93      0.96      0.95     23497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_kNN = KNeighborsClassifier()\n",
    "model_kNN.fit(X_train , Y_train)\n",
    "y_pred = model_kNN.predict(X_test)\n",
    "target_names = ['Basic', 'Plus', 'Premium']\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basic       0.96      1.00      0.98     22636\n",
      "        Plus       0.00      0.00      0.00       172\n",
      "     Premium       0.00      0.00      0.00       689\n",
      "\n",
      "    accuracy                           0.96     23497\n",
      "   macro avg       0.32      0.33      0.33     23497\n",
      "weighted avg       0.93      0.96      0.95     23497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import LinearSVC\n",
    "model_SVM = LinearSVC()\n",
    "model_SVM.fit(X_train , Y_train)\n",
    "y_pred = model_SVM.predict(X_test)\n",
    "target_names = ['Basic', 'Plus', 'Premium']\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basic       0.96      1.00      0.98     22636\n",
      "        Plus       0.00      0.00      0.00       172\n",
      "     Premium       0.00      0.00      0.00       689\n",
      "\n",
      "    accuracy                           0.96     23497\n",
      "   macro avg       0.32      0.33      0.33     23497\n",
      "weighted avg       0.93      0.96      0.95     23497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine with class_weights = 'balanced'\n",
    "from sklearn.svm import LinearSVC\n",
    "model_SVM = LinearSVC(class_weight='balanced')\n",
    "model_SVM.fit(X_train , Y_train)\n",
    "y_pred = model_SVM.predict(X_test)\n",
    "target_names = ['Basic', 'Plus', 'Premium']\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling only on the train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will do 'over-sampling' only on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output shape before over-sampling:\n",
      " (54824, 11) (23497, 11) (54824,) (23497,)\n",
      "Input and output shape after over-sampling:\n",
      " (158355, 11) (23497, 11) (158355,) (23497,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')\n",
    "Mapping_Tier = {\"Basic\":0, \"Plus\":1, \"Premium\":2}\n",
    "df[\"product_tier\"] = df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "# y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(random_state=12)\n",
    "x_train_res, y_train_res = oversample.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(\"Input and output shape before over-sampling:\\n\", X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "print(\"Input and output shape after over-sampling:\\n\", x_train_res.shape, X_test.shape, y_train_res.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basic       0.97      0.99      0.98     22636\n",
      "        Plus       0.09      0.02      0.03       172\n",
      "     Premium       0.31      0.08      0.13       689\n",
      "\n",
      "    accuracy                           0.96     23497\n",
      "   macro avg       0.45      0.36      0.38     23497\n",
      "weighted avg       0.94      0.96      0.95     23497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_RF = RandomForestClassifier(n_estimators=1000)\n",
    "model_RF.fit(x_train_res , y_train_res)\n",
    "y_pred = model_RF.predict(X_test)\n",
    "target_names = ['Basic', 'Plus', 'Premium']\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.ensemble import GradientBoostingClassifier'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basic       0.97      1.00      0.98     22636\n",
      "        Plus       0.26      0.03      0.06       172\n",
      "     Premium       0.50      0.09      0.15       689\n",
      "\n",
      "    accuracy                           0.96     23497\n",
      "   macro avg       0.57      0.37      0.40     23497\n",
      "weighted avg       0.95      0.96      0.95     23497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "model_GB = GradientBoostingClassifier(n_estimators=1000)\n",
    "model_GB.fit(x_train_res , y_train_res)\n",
    "y_pred = model_GB.predict(X_test)\n",
    "target_names = ['Basic', 'Plus', 'Premium']\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating different machine learning algorithms on a Balanced Dataset\n",
    "I will use SMOTE for over-sampling\n",
    "This would help show how diff ML algorithm work for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  9.5min remaining:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 18.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Support Vector Machine 0.332 (0.330)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed: 41.7min remaining: 36.5min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 76.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Random Forest Classifier 0.961 (0.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   11.9s remaining:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">K Neighbors Classifier 0.827 (0.003)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating different machine learning algorithms on a balanced dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(full_path):\n",
    "    # load the dataset as a numpy array\n",
    "    df = read_csv(full_path)\n",
    "    df = df.fillna(0)\n",
    "    # retrieve numpy array\n",
    "    data = df.values\n",
    "    # split into input and output elements\n",
    "    X = data[:, :-1].astype(str)\n",
    "    y = data[:, -1].astype(str)\n",
    "    # label encode the target variable\n",
    "    X = OrdinalEncoder().fit_transform(X)\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    return X, y\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, verbose=2)\n",
    "    return scores\n",
    "\n",
    "# define models to test\n",
    "def get_models():\n",
    "    models, names = list(), list()\n",
    "    # SVM\n",
    "    models.append(LinearSVC())\n",
    "    names.append('Support Vector Machine')\n",
    "    # RF\n",
    "    models.append(RandomForestClassifier(n_estimators=1000))\n",
    "    names.append('Random Forest Classifier')\n",
    "    GradientBoostingClassifier\n",
    "    # KNN\n",
    "    models.append(KNeighborsClassifier(n_neighbors=3))\n",
    "    names.append('K Neighbors Classifier')\n",
    "    return models, names\n",
    "\n",
    "# define the location of the dataset\n",
    "full_path = 'AS24_Case_Study_Data_Processed.csv'\n",
    "# load the dataset\n",
    "X, y = load_dataset(full_path)\n",
    "# define models\n",
    "models, names = get_models()\n",
    "results = list()\n",
    "# evaluate each model\n",
    "for i in range(len(models)):\n",
    "    # create pipeline\n",
    "    steps = [('o', SMOTE(k_neighbors=2)), ('m', models[i])]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # evaluate the model and store results\n",
    "    scores = evaluate_model(X, y, pipeline)\n",
    "    results.append(scores)\n",
    "    # summarize performance\n",
    "    print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))\n",
    "# plot the results\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now onto, training a few models with under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AS24_Case_Study_Data_Processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the Dataset.\n",
    "shuffled_df = df.sample(frac=1,random_state=4)\n",
    "\n",
    "# Put all the 'plus' tier in a separate dataset.\n",
    "plus_df = shuffled_df.loc[shuffled_df['product_tier'] == 'Plus']\n",
    "\n",
    "#Randomly select 574 observations from the 'basic' tier (majority class)\n",
    "basic_df = shuffled_df.loc[shuffled_df['product_tier'] == 'Basic'].sample(n=576,random_state=42)\n",
    "\n",
    "#Randomly select 574 observations from the 'premium' tier (majority class)\n",
    "premium_df = shuffled_df.loc[shuffled_df['product_tier'] == 'Premium'].sample(n=576,random_state=42)\n",
    "\n",
    "# Concatenate both dataframes again\n",
    "normalized_df = pd.concat([plus_df, basic_df, premium_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "      <th>calculated_ctr</th>\n",
       "      <th>product_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>23801</td>\n",
       "      <td>364652263</td>\n",
       "      <td>BMW</td>\n",
       "      <td>3299</td>\n",
       "      <td>8</td>\n",
       "      <td>2001</td>\n",
       "      <td>2018-11-28</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>3652.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.058324</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60740</td>\n",
       "      <td>360810732</td>\n",
       "      <td>Opel</td>\n",
       "      <td>9740</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>5647.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51112</td>\n",
       "      <td>363910792</td>\n",
       "      <td>BMW</td>\n",
       "      <td>39950</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018-11-20</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>16310.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>121</td>\n",
       "      <td>0.024954</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48905</td>\n",
       "      <td>357141929</td>\n",
       "      <td>Renault</td>\n",
       "      <td>13430</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>3839.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.030477</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41548</td>\n",
       "      <td>363210596</td>\n",
       "      <td>Kia</td>\n",
       "      <td>6950</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.077973</td>\n",
       "      <td>Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13175</td>\n",
       "      <td>363930531</td>\n",
       "      <td>Honda</td>\n",
       "      <td>9950</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>2018-11-20</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.022613</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59142</td>\n",
       "      <td>360768637</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>6995</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>2018-11-28</td>\n",
       "      <td>30395.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.025596</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3262</td>\n",
       "      <td>360810998</td>\n",
       "      <td>Renault</td>\n",
       "      <td>9844</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>2018-11-14</td>\n",
       "      <td>10448.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.049770</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22742</td>\n",
       "      <td>360086027</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>27950</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>12576.0</td>\n",
       "      <td>965.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.076733</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10096</td>\n",
       "      <td>359210182</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>7450</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>2018-11-14</td>\n",
       "      <td>18526.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0.043614</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id      make_name  price  first_zip_digit  \\\n",
       "23801   364652263            BMW   3299                8   \n",
       "60740   360810732           Opel   9740                5   \n",
       "51112   363910792            BMW  39950                6   \n",
       "48905   357141929        Renault  13430                3   \n",
       "41548   363210596            Kia   6950                2   \n",
       "...           ...            ...    ...              ...   \n",
       "13175   363930531          Honda   9950                3   \n",
       "59142   360768637     Volkswagen   6995                8   \n",
       "3262    360810998        Renault   9844                5   \n",
       "22742   360086027  Mercedes-Benz  27950                1   \n",
       "10096   359210182         Toyota   7450                2   \n",
       "\n",
       "       first_registration_year created_date deleted_date  search_views  \\\n",
       "23801                     2001   2018-11-28   2018-12-08        3652.0   \n",
       "60740                     2016   2018-10-16   2018-11-01        5647.0   \n",
       "51112                     2016   2018-11-20   2019-03-21       16310.0   \n",
       "48905                     2017   2018-09-04   2018-10-20        3839.0   \n",
       "41548                     2012   2018-11-12   2018-11-19        1539.0   \n",
       "...                        ...          ...          ...           ...   \n",
       "13175                     2007   2018-11-20   2018-12-07        2388.0   \n",
       "59142                     2009   2018-10-16   2018-11-28       30395.0   \n",
       "3262                      2013   2018-10-16   2018-11-14       10448.0   \n",
       "22742                     2014   2018-10-08   2018-11-22       12576.0   \n",
       "10096                     2010   2018-09-28   2018-11-14       18526.0   \n",
       "\n",
       "       detail_views  calculated_stock_days  calculated_ctr product_tier  \n",
       "23801         213.0                     10        0.058324         Plus  \n",
       "60740         101.0                     16        0.017886         Plus  \n",
       "51112         407.0                    121        0.024954         Plus  \n",
       "48905         117.0                     46        0.030477         Plus  \n",
       "41548         120.0                      7        0.077973         Plus  \n",
       "...             ...                    ...             ...          ...  \n",
       "13175          54.0                     17        0.022613      Premium  \n",
       "59142         778.0                     43        0.025596      Premium  \n",
       "3262          520.0                     29        0.049770      Premium  \n",
       "22742         965.0                     45        0.076733      Premium  \n",
       "10096         808.0                     47        0.043614      Premium  \n",
       "\n",
       "[1728 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_zip_digit</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>created_date</th>\n",
       "      <th>deleted_date</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>calculated_stock_days</th>\n",
       "      <th>calculated_ctr</th>\n",
       "      <th>product_tier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_tier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Basic</td>\n",
       "      <td>576</td>\n",
       "      <td>41</td>\n",
       "      <td>377</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>192</td>\n",
       "      <td>526</td>\n",
       "      <td>181</td>\n",
       "      <td>111</td>\n",
       "      <td>553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Plus</td>\n",
       "      <td>576</td>\n",
       "      <td>42</td>\n",
       "      <td>353</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>183</td>\n",
       "      <td>559</td>\n",
       "      <td>356</td>\n",
       "      <td>119</td>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Premium</td>\n",
       "      <td>576</td>\n",
       "      <td>39</td>\n",
       "      <td>348</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>183</td>\n",
       "      <td>573</td>\n",
       "      <td>386</td>\n",
       "      <td>105</td>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              article_id  make_name  price  first_zip_digit  \\\n",
       "product_tier                                                  \n",
       "Basic                576         41    377                9   \n",
       "Plus                 576         42    353                9   \n",
       "Premium              576         39    348                9   \n",
       "\n",
       "              first_registration_year  created_date  deleted_date  \\\n",
       "product_tier                                                        \n",
       "Basic                              29            34           192   \n",
       "Plus                               28            35           183   \n",
       "Premium                            27            34           183   \n",
       "\n",
       "              search_views  detail_views  calculated_stock_days  \\\n",
       "product_tier                                                      \n",
       "Basic                  526           181                    111   \n",
       "Plus                   559           356                    119   \n",
       "Premium                573           386                    105   \n",
       "\n",
       "              calculated_ctr  product_tier  \n",
       "product_tier                                \n",
       "Basic                    553             1  \n",
       "Plus                     573             1  \n",
       "Premium                  573             1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying count of the classes\n",
    "normalized_df.groupby('product_tier').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom sklearn.ensemble import GradientBoostingClassifier'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\nfrom sklearn.ensemble import GradientBoostingClassifier'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\nfrom sklearn.ensemble import GradientBoostingClassifier'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\nfrom sklearn.ensemble import GradientBoostingClassifier'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.countplot('product_tier', data=normalized_df)\n",
    "plt.title('Balanced Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 11) (1728,)\n",
      "Counter({1: 576, 0: 576, 2: 576})\n",
      "[1679.    5.  427.    7.   17.   34.  151.  887.  173.    2. 1405.] 1\n",
      "[1111.   34.  739.    4.   32.   24.  114. 1183.    5.   34.  198.] 1\n",
      "[1545.    5.  483.    5.   32.   32.  232.  335.  341.   25.  453.] 1\n",
      "[591.  38.  89.   2.  33.  14. 102. 919.  38.  67. 664.] 1\n",
      "[1.414e+03 2.400e+01 6.320e+02 1.000e+00 2.800e+01 3.000e+01 1.320e+02\n",
      " 2.950e+02 4.700e+01 9.300e+01 1.569e+03] 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydeXgc1Znuf6eqW+pFuyVbm8FsxsFgwIAh4JAAiR0jzBZsEgIhM4EkNwMoMAPYCdgCnGBgbojJvXOzMDNhsmIIEIKSwQkQwBB2g4kDBDCLF8nWvrWWrqpz/6iuVnXXqV5k2SCm3+fxI6uWc75zzldHVd95z/sJKSUFFFBAAQVMPWgftAEFFFBAAQVMDIUJvIACCihgiqIwgRdQQAEFTFEUJvACCiiggCmKwgReQAEFFDBFEdiXlVVXV8tZs2btyyoLKKCAAqY8XnzxxU4pZU368X06gc+aNYsXXnhhX1ZZQAEFFDDlIYR4T3W8EEIpoIACCpiiKEzgBRRQQAFTFIUJvIACCihgiqIwgRdQQAEFTFHktIgphHgXGABMwJBSHiuEqALuBmYB7wLLpZQ9e8fMAgoooIAC0pHPG/gpUsqjpJTHJn5fATwipTwEeCTxewEFFFBAAfsIexJCOQu4K/H/u4Cz99ycAgoooIACckWuE7gENgghXhRCfDVxbIaUsg0g8XO66kYhxFeFEC8IIV7o6OjYc4sLKKCAAgoAcp/AT5JSzgeWAP8khDg51wqklD+WUh4rpTy2psazkaiAjyo2r4fbD4eWCvvn5vW5nfsw4YO284Ouv4APPXJaxJRS7kz83C2EuB9YAOwSQtRJKduEEHXA7r1oZwFTCZvXw++ugPiw/XvfNvt3B37n5i3ft3ZmQqY27As7P+j6C5gSyPoGLoSICiFKnf8Di4C/Ag8CFycuuxj47d4ysoAphkduHJ94HMSH7eOZzn2Y8EHb+UHXX8CUQC5v4DOA+4UQzvW/lFL+txDieWC9EOIrwPvAsr1nZgFTCn3b8zue7dwHgYm04aNUfwFTAmJf5sQ89thj5V4Xs9q83n5L6dsO5Y1w2ipau19l3db7addghgkz+46jtLOWG4p+RjkDCIBwFSy5xfN52rq1lXUvraN9qJ3aaC3N85tpOrAp47kHNu3gtoffYGfvMPUVYa5efCjBvh+y9p376RV2ueWWZGVXD02BqqSN33/7fnbpUGNIpnXM5834RaxeOpezj27Iqb2tNY2sq6ygPd6f0dawFiRmjiaLCAud1YMmTR3baa2sYV1JEe26oNaUNA+O0dTTkexLp3/S235y48k8sf0J+3fTormri6ahWKqt5TPtn33bvO0QOpzzQ/v/zviFK+3fh3ugvJHnD7qcb/7tkGS/HnzgG2wa+BWW3kPEDLNicIBze9pytrVtqB3MMJYETY9RXjSdzx54it2OwZ3UGib7x8d4LhzGwv5cXRaLc91oMOlfzx90Oa2bd3L52J1UiUG7eaKUN+dfz3Fnfi1ljFqNbtZNq7L7NlpH8/xmAG5+9mb6xvrssdDDFAeK6R3pQQMsoM4wae7ppWkoxnarmnOqvkbx9Ifpj3d4xpnN64n9YRWh4XZ6ZRQpoVIM8ovoDH40vYp+EaMsWMPo7sX0xsYIz9iADPRSF63lpKqL2PBcA53FvyJY+SwgEUCRHiZujVAbrWVm8TE8t/sppN6DQAAWdYbJxT0Wz/Wcywtln+HqxYcmfVb1jACse+Zm2sd67T6WOs8VaVhIBBr64Mfp2baUYNkmimoeRgR7EWYl80u/wFtbD2VH7zC6EJhSUlO7xbcvnLrbhtoRRgWj/YcSKHsFoQ8jgEigjFUnfmu879LQurWVm5/5Hn1ju3HPksKKMNy+lGO0v9NZ/SIdAUGNIanumM8bYxexRD7JP1m/pF7rYiRcS2TJjXsc9hJCvOiicI8f/0hN4OlxQ6C1tIyWqjJGtPFoUciyuL6jhzNjQ6n3a0E4+99SHvyWp1sYMUfG79VDtJzYAqA8d0b9Ffz6sRqG42by+IlV63l9+ovEhUipLmBZrOnsBqHTMq3cY+MB7fPZNPgFbjvvSPUk7mpvazRCS3VVahkZbE2HJiXL+gf4bWmJx46Wzm57Mg6GYekdtJZEs5YXsiQtna5JPHEv4BmjJPQikBKsuLLMYVnEtfFLeNBaSKBsE6G6+xDa+LUTtTUjpAT3uEnJ+f0DXNfdC8CYDCAwCYrU52hMBnjlmO9y3KxK+N0VtBYJz/gEtSCGZSDJ/gyGLIuVHf382vwUf6vdktruxDg3DQ5h/PZyAmltVfmGtHRAIjTLdSyIGdsPPfo2aa7q2x3p9v2590L+qH+Sm889gmD5y56+D2pBpGViYPkWKiWYQwehR95Paae0goy0nYvRfzSA2gcy+LzKdl0E+M7CNZ5JvHVrK9dvXE1cjqKCkAJdmhhpz8qpu+pZPfwyETGWPG7oIQJn/WCPJvH/GRP47Yd73u4WNdbTFvRGiuriBhu27/SWUT4Trvyrfe+9i2gbavPeG60DUJ4TRiX9b16bcuygg69hd1C93FAXN+yyFDZOj1u8/datNFSEeWrFqd6bXe31bWcGW9OhSYmleDpT+qp8Jotm1udUXp0p2fD+ds8bMZvXw/1fB2lmLkCB7VY1C8fuIHrQWrSi3kmzNR9oUvLKu4qviDS0U0NteQj6tvmOTz4ojocZlsXqdkfr2LBtp/LrJp+6/SboXFAXN/iP98dYOHYHDRVhogevnXDf+9lhjVUw9La9Z9DXB/Lweef6DedtSDnm9+xnLSuHeWUi8JvA96ke+F6HIj7YHtCVl/odd5fRPtSuvtfnOICle9UEOgL+T4SvHa77dvYq3lYh1Va/dmawNR2Wz/GUsvu2016VG/u0XdegxfuAMW853PdV7/EcUC+6ABBBRblM3NZ84NdP6ZguO6FPYdcEMRIYRqD2hfahdt/4+GTUnQvaA3pyfHb2DlOah+/lCve4+/pAnvWqrs+3jOR9Ocwrk4kpN4G3bm1NiRlWWJIVnd2cYpXxh2gZP6qM0hbQk/FDP9Qa6rc/iaT1tjpumVaJ1DTla0BtPE5MCPoUg6UjKZ2zgjJLEheSYSEyfiBL7Niq6hqJ/ZYx1rGYK761kWMrfsPPq3TaAzq1hskVkTBCwM1Vlb51hOIhysUQ7YGJT2QpfVXeSLkI0CvVYQ7PfS3lSKCPUr5WfArvTH+DET1GbWMdzT29bCou4p6y0vEYsys84aA1GuHmqkr6dLsNDda1CNNS9r/b1t9FIghpISf6SukDd0+uqapgfVlpSv9XWBYrunpYPDiCkBZCQJmPvZMFK17OyqpaWssCOQRk9g5qDZOdchoAS7WN/C1usCs4uW0OGWGuqbqSn1fptKED3rEV0qI0j/6WUnLET48AYa9BNNVfDkYFBPKXdpLAwpkNCAF9mkats34RmJZ3WblgSk3grVtbuW7jdRjSSB7r1QTX11Rxbv8Avy0tTcb5Mk3eIcvisu4+5bnfRyOsqpnmiVe77z05FuO+slLvSVcIol8XqJzLAyFsW1XfjEKgFfUSqbuXyoF+flAaTravLRjg+poqLCGUYQ8AzdL5VvcOgsLyxED9bPGUISXNPYkJNRimtaqGPnM3ZCkrZFk0d3fbxQJPRU22Vr+UsEHQFgywsrrKnlwT9VrA3Yl+dSbx1miE66qrUmKN/TroUiNgWZ4YpGNrazTCjdWV6r7JECfIGkKQkgXD9lvwmqoK2960G3p1neurpwH2GkBrNEJM9/aXJiVSSvtFIQc41SjC8lhmEQ+VBXNyOWUh2HFxMzYrYwzcr4NClsXXuwe51biQM7WN3Bb8EX/qKc7N7zwNUsfANUunKdbJD2rCGcu0hGBQ13KLB6VdM2wOc897txHvP55gxYsp9buhioHbJ1Jf7NqCAVqqq3i7ZBFXMPmYUnKy615alzJ5O4gLwT1lpdkdBfuhOaB9Pn/qvZhuWUL6EsC6ygrfyVuTkpbObp6IRNTX5PKmJyWeShP3aj7nLM3kgbKIp32GpvlO3lIK/rkjxtmxQZqGYrR0dlMXNxBSErEsfzvSywGWDA6zQ1bD0jtYZ7RnnXCcfnKzUNZVVnjsV37hJMbSfZ/nIQFMISiRMtmmurjB6o7xOlX1Obad3z+QvM8ywlhGxJ4ExyqQVjBzhwjBe8EiANtOn/6Pa4J1lRVJW1T+UmZZ3NzZTblhJsfDMoNgRkHaY+jjKp7fteLduU/eqkIAaRUxvO1S4j0nIKXw9VOktE8lrqmLG1zeEefPvRfyoLWQawLrKRZmit/5+ZomJScMDyd9X5OSpv44w9suZaTtXHtMEmPzzx0x/hIpzuk5N10vBko4/q+4RmiSQMnrKfW7/1lGhNjO5RzSPj9j2xyMaBp39u+dtb8p9QaeMfacYxkmguf6Pg/Ag6ML2Vp8QYrfZ4oXSqBpKMbKmol/Djl1+YVMhM+5XNvnLu3CoV3JCpuGYikTqiUF8w6YmfWZl8CBo78A4N15TbS/lH0jidNPbuQTh3W3NdN9fZrGk++PL9pJpwMz3CdJvN1392JJkWybg5I52UU1nbKzjYlznZ8tfZqWMi6OPW4fycWeyYLQ7S+L0V1nM7rrbErnXOt77eDra5P/HwBWuc7Vi87k/532zZs109fnf7KrM+WYJQW/Boz+o5OME4ALiy/gX6fPzKNF/vB7zpLng72e+tPxHEezdeRBjjpA3TY3VGtjk4EpNYHXRmt9V4azxbwdzDAsNhdfwE5Zza3GcnbKahpdDldrmL4r9k58NdM12eCUobo/07lc2+dAxivYKWMpbXOjlygyXoFQrOKn1wugJ95Uak2TtkDmtqvWF/KJAbvfr3IZDwcmGoFEL/ndV2ZaLGqsT64j3NF9KT39H2e18Y8AOfWJU28u6yyt0YjvZJFuvxM/rq8IA7Cjd5jsU83kYYZhcaq2kQethUDm9v1j/Tf4x84Aj1hHcZr2MvWi0/eZAv/xkMCRs2Ym10Ac3vuCjl/zkjyU4gQPXMYr+HnPjD169tLt2RXQfdsn4xWcqW3kmsD6lLY5feNgp6zOySbNrNxjm5Xl7pVS9xJOblRraOlOXDLLp0zIklzV040moFHrZG3wTrbKGSm3Nff0ElSUE3DFV5t7eglZqUMflJKAlXmKdco4ORbz2iolJ8diPudg/vCop86AZdmfnmkQlmC0YzG3GssZlepJM8owcztnoVkZJlUpqe3dH4AvHD+TBzbt4LNdJRnb6Y5DO/CLATt1pP/uxJgBPhGLKecv3R2bx+ba/so6jZi0wxuqMQpYFjFdoy0YQAo7Dn9TTSXTyp7mhsB/ADDasThjGMXdvmX9A74+F7Ts8WyprvKNw58cG/9KickibjWWEw7qXL34UHvzly6I9xyv6iIF1OEWX6RdHLIsrurpZm3wTs7UNgLYY+8TRrmnrJSfVht8Sf8TjVpnyjP1iHWUx+9U4+GUZSXCHc7PtmCAN2tfIlK3Hq2o1w4RFfXyv2sifDymfg7Sn9lMz6Mzhn7jJy3B3M5ZrA3e6Wmb0zcAQV3wr8Zyvt49qG5bsrwgnzvgUt/ze4IpNYE/sf0J5fES02JrMJQx5lVnpm0sASJijJP011JuaxqKcVNHFxXmeFyy3DC5tiPGJwctpITTB2Os6uhOib/e1NHFGlecucI0CbtizeWGyZpEXPiJSEQZyHwsUuJzDl4NVnJ9R09KnWs6u/luR1dKDLXCNLmmcwSj/2g7Hhn/GqbiGSwWJrePPM1Q23kUx8MIKQlbFsIVi6zv3Z+3dv0TF56wH2vOPoLbHn6D5YPdrEmL2zr3zIibntg3ZF5XUPWDE2MGeDISUcZ2S0yLplhik0X5TAJn/YDSc9ex0riE7VY1SwaH+ZeOGDPiZrK/SqT02DGiadxRVcEX9UftcuMLWLb/lQkusUAaESwjjJQ2D/vyjjhLBmMYUuPbXb009RuJeHViLpCAGeXg9qN5LFLiH68Vgj9HolhSsF1WsyJ+CS+WfYabzz2Cs49u4OyjG7jtvCOJDCxLxqRlIi6O4o+yEBKsItd1JI0KWhZh00rxEfc6QF3cSI5bRIxxTcBWPXyj/RvUZ5nE04cvIsY4TXuZq+Nfo8sqSdqSSzzcDUPTkFrqdZZm0hqp5vKOeNL2sniAFR0xbtzdldKeG3ePP4+OPzvx+vN3h1k8OMJ13b2c3z+Q9F+kJGRJRtqW873hp1M24zht+1bRPQigoSLMbecdyaeWXcbzsS+n2BSWRWDau2CFUcmy/a9k9akXZW3zRDClNvLMu2uectea0wTluiKCzRdvtiU58/oUFRww8gvlHQJ4Z21i51be5WLHA1WLJ4mZStVGgWDzO+/nWJdI8q8PWNHK28UXoCnnT6HmafsgU1mWtD/1Vef82usHISWbExtlMvXV5os3K21M76F3ii9AiAxlOfW1eJlJqvIy2p746cSvMzXbrw0quO3wK1fK1Nj0Vt9xz4z0tQHfdkjJq4oNTen3p9uRrz+kVZnSRj/4td2xbaLn831mJgt+G3mm1Bt4bbRWeVzGK5Dxisz3lDeqCxU+IYTyxmQsMh0px/3KzQA/DnpttNa3jbXR2tzrcl1XXxFmp6zOeF3r1lYW3buIeXfNY9G9i2jd2qq8PFNZO+U033N+7fWD+/pMfeVnYzrMhJv7lmWYvn7g5wO6zwRUXxFO3uPnk8l6fdqQzQ6/ctPjrL7jngVtpC/S+7CyfO53Yvl+duTrD274tT1QtonoQWspmbOC6EFr+Xl0huea1miEz8xsoGTOCj4zs5HWaMTX9mzPjKfsHJ+hycaUmsCb5zcT0kMpx4KiGNm9RBm7DOmhpHgOp62y9TFSbg7DMV9WHz9tFVcvPpRw2kYEJ0aZhKpcvQhl12o6aEFlPNCxVdXGZDtUdaUjYbuDqxcfyvf5fDI27MDQQ7aIVkLvpW2oDYmkbaiNlqdblA7oV5YTv73VWO45Nyp1/ql7IGOMMKWtVmpsu7k/RkhkGFeFjeljdrc8DYk6DpuMaR/z5ZzLCwd1vnD8TF/fcO4Z7VhMwPLZT4Dm24Zsdvj5+ucOuDTFJtV4uDEmA941kmCYp/b/RsohVRweaWvnpMPxBTfS7fCNh7sQsCxEWt9JK8hox2LvtQlNlPR4+YOl5clrHD2Y3UENIWB3UKOlelrKJD7ssl3Vd84zk458nqHJht7S0rLXK3Hw4x//uOWrX53YFmqA2ZWzaShpYEvXFobiQ9RF61h5/ApOafwsr2yN0D9QQjCyE7RR6qJ1rFiwYlykZsZcqNgPdr4MowO2NsFn18InrlIfn7ecOXVlNFaGeXVHH4MjBg0VYVYtPSxVWEpV7pJb4WNL4d2nwEgsyIWrYOk6mNPE7Peep2Gwhy2hMEOaSLFV1cZkO1Lq6k+8Ncrxny7bHcypKyNWMYffvK1xsPEWJWKY4XAdxWfcBvOWc9kjl9E7mvpJaEiDLV1buOiw1LidX1kP1Tfz/7qO4XW5Hzuo4fjQ+4SsGDtlNavjF/Pe6FF8XvyNN4OSQU2gCQ2JrUHRdGAT3SPd421t+DRNu99L9uXsT3+HhoMXq/tDAdWYfeqMC/lY6Qiz33+RhnicLUVFdr8bJit6+mj62OfhjO/lXN6qpYfxjVMO9vUN555XtkboGShjWuQNRoWZ3HFbp4dZsfAm3zZks6O/r5ry4AyiZe2MWbFkn1w6/7zkNQMjBm+xP+9b1Rytv0uUYUS4CoJhpDFCG9Wsin+JP1rHcqT+DiUMIxL+M/ezl9I5OMqWHf122Cb2MQ6phwH5LhI7nry8f5DrzFI4YhkMdSbH6/4Zl/P/uo5JUmKjRTp/NWaygxoOF+9QIoaZGajGnLGETcM9SDGCQANhlyuB6Yakcfd8tg98Ei20A6GNUF40naWN/4tdO+cm+/uso+rpGhzDqL4TLZC67iKF5LXyGVxkFMPoAP9UW0tv2kK6IQRbQmEu6rNtf3nuSv6z/zgGRwx2hw9iJ9OZY73teWbSkc8zNFHccMMNbS0tLT9OPz6lYuAFTD781hXyic8WUMAHiVx8eG/6+b54hj6yYlZu7e2LS57jmuDdRIbbvQp4eZbl6HgDvNz6Yy4Z+/mk6vumo3Vra4pGcvOoTtMnVvGAeZLHpoz64BnacvbRDZ7jZfvV0Bf3ZsOrjcdttcPTcrchvexT5tTw2Osdvr/n2pZ84bajPBxECOiNxXOu06NhXX08TZvuh77txMK13Bo/n7sGF1BfEWbRgh081f2zFL3reN9RWfvrgU07+M7jvyAW/R1asJfyoumsPOGq5Fv5dQ+8yq+e3YYpJboQfOH4maw5+4iJdcjm9fT87jrKx3axU1bzr+b5lBz3hYmXN0nw89Gc4NLBr92vkTZdoVnkWmOoDZbRFvcuUuezDuEHv/0pZcG9nwN4SoVQ0vHAph2svO9VumNjnKltZDU/ImIkBmm0H976kx1ymDE3r7IABkYMHnltF8Wv/4ZV8kdM0+zED0FjEOPvf0Sr3D+ncnNB69ZWWjZeT68Zg4SOw8aApHbLQzz58hjPDtUlbXr87x00VoaZU1eWV1se/3sH7f3D/ODRt1KOG2MRikvfxGJ8YSlkWazo7mH2QBfG3//If2wxs9qgqnPzdvtT3u/3XNqSL9LtGDEsRuJWznU68Uznk3gwPsjGntdoGOxidjxO0BhkgfkS22Q1Lwd38XfzPxlM+NxgfJDHtz3Jw6+M0d07zbfOBzbt4Fsb7sKctt7+9Bcwag3x+LYnaSxt4L8eH+Xnz7yffKeTwObtfXQOjnLqHO/iXEZsXs/Y/ZdRYvbZoloixsnaK7RuC/LUwIz8y5sk+PloTv7g6ODHbOXDKsNgYziM4VpYDukhVixYwezK2bB5PVWb72VjKJh6jQiy4viV9jV7gKpQFY9vezLlGZJWkFjbGTRED5wU//YLoUypRcx03PbwG8nECdcE1nt4m/nkEHSXlbzdkvyzdren3IA5Mqm5Cde9tI6RNHW/EU3j/5RH+Sa/Tjk+HDe57eE3Mpanastw3ORXz27zHI/1HInevZy6aJ2HEwx2W3OxQVVnNuTSlnyRzY5sda57aZ0n+cOIS9cESHKli2se9ogdxeUoouoPGeu87eE3EFV/UN677qV1/OpZtda43/GMeORGitKSEjj2T6i8SYKfj+bkD2n5Qm2OeRd1pkRgrym1nNgyvsbwyI009fem6AHVxQ1aBsbyWofwQ9OBTejdy1N0W0baziXWc+Sk+3c6pnQIxa2TXe+zZTxXHV4/ze09LTcX+OqOu/SV3fDVB89y3vRZ7+hsn8vz37zGl9Oeiw3ZbPLDRO/bk/IyXZNpLNyoF12IoJeGBmqdanedO3uHidb6a1n7jZPf8Yzw8dN60TWx8iYJfmOQkz8o2mRrrgyrOdqJ69P1gPJT/8qMzva5SLxf5JPt3+mY0m/gbm5sLrzNBzbt4KS1j3LAilZOWvsoD2zaoSzLjXz5oBOBL/c7oa+cznGtrt2SsbyJcJcB3zal83pVdfjVmQ0TvW9Pyst0TaaxcGOnnObLSVYdd9dZXxHOuG/Bb5z8jmdEhjGdUHmThJz2WKRj83p7XcZva5XfM5nv8QlgQu2ZBEzpCdzNjVVyXl2caCfmtqN3GIktFLTyvleTk7iK7xvUBP/bOj9nPuhE0Ty/2ct1tiwu6xvimpKFHo6rWbU+I8d0ItxlQMkzN/QQ3+fz/vdkqDMbVOXsKbLZka1OJQ8/jZvucJ1VfGxnX0KmOq9efCiye4ny3ub5zXzheLXint/xjDhtFWOiOOWQY/+Eypsk5LTHwg0n7q1KiA2e/Q8p8NsDMonPcN7tmSRM6UVMNzf2xeF6hsL1LCh+j6Ax5OFEf+WuF5ILJg4MS/Lqjj6+svAAJd+35cy5zDpsgS+HerIwu3I2DaWNbGl7niFzxOYnj2gsPeU73D7yGKMydcOEhZmRYzoR7jKg5LRrS24hdujnMnPhfep0eLp+v6vK2VOk21ERDhIu0hmNWznVqeThu7jpsXAdt/IPrB/9OHXhAzlz7lx6zK2efQmZ+mtOXRkN0QP5yxuSMf39JM/ZyZB+6pwZKTxsXQi+mNCjyRsz5qJX7U/PW89RbMbYIau5yfwSpQsu+EBZKDntsXDjl+cnFy09UOx/SIHfHpBJfIbzbk+e+B/PA/fTtEjRNfkQosDTLuCjBg9Nc35z9sVEX82hD0abZF/jI6GFsif4oGJUe4qM2igFFDDFMOFt5/sgjj0V8T9mAv+gYlR7iozaKAUUMMWgpGmaI6x7aV3mG/dBHHsqYkrTCPOBE4ua8M6vDwjOp2Xen5wFFPAhhC9NM0O6RGA8Xp3YfTmRndYfRUz9GPjm9cT+sIrQcDs7rWncaiznydAprF4613dyvuHRn/Gbd36CpfegmZUcN/0kto2+OPkTpGu7r5/DZdtO7Jw/tv+PrCy6hxl08vuaRtZVVtAe7588e3Ow1Q8ZY5pZym3d2srNz95M35i9m7GiuCKjWNWE4qd7AXu0DXxfw28M8hjzyWrvonsXKbedVxRXEA6E9/q4ZvKfD/OY+sXApzQLhc3rMX57OcVjvQjsbcKf1F7hzbEq/u21Yvarini2sd7w6M+4573bQR+yReq1EbbH/s5gfBBIbJ3esZGGkoY922Kbtt1XtbU/23Zi5/zCkUdZG7yTSjHA76MRWsrD9MqxybM3B1v9oNx67tiz7eWM5bZubeW6jdcxbI5vdhgxR3h8++M0ljZ62pOxrj3cDp0P9mgb+L6G39j274Qnbs1pzCezvVWhKjbu2IghjeSxoBZkzByjf6wf2Hvjmsl//vZu9EM9ph/JrfQ8cqO9rd0FZ5tw3JTKbay/eecnni3M6fsZcorJ5WCbe7sv4Nnan207sXPeLROwrrLCk6Zrj+3NwVY/ZIxpZil33UvrUh7k5CVWXNmeCcdPJxl7tA18X8NvDF78ac5jPpntbTqwiZYTW2zphsS290gg4vGDvTGumfxnSo2pC1M7Bp5hmzCot7Faek9OG2izxuSywW+rvet4tu3Ezk/3dv70Ld3J43tibw62+iFjTDNLuZlsVp2bcPx0krFH28D3NfzGQProxSiun+z2Nh3YlBIemXfXPEJfls4AACAASURBVOV1kz2umfxnYCqNqQs5v4ELIXQhxCYhxEOJ3w8QQjwrhHhTCHG3EMI/9cckI5m+aFYjixrrPamRnK3fKopgetopP+wxTc+H3rTdmpbcxp+N2uj8dG/nzznFmLPtuKXC/rl5fd62qo6nyxH4SWZmTAGXOJ6pj1XnPiyUyg+KkppJCgJQj/kEUgmmYyLtzWqrC/tqXDPVM1VpxvmEUJqB11y/3wLcLqU8BOgBvjKZhvkhhUcqBG3BAC3VVclJ3NkmHNSFkiL4uQMu9WxhTl/HnRSanoL25NjmbOM/ZU5NRmqjQ310ywSo0lE5W7CTSNl2LO2fv7vCfxLPkaKlkiPo3nYawbSt2hlTwLnKbZ7fTEB4PwKDWlDZ/x8WSuUHQUnNJgXhO+aHLMo7lWA68m1vVlvTsK/GNVM9U5VmnNMELoRoBJqAOxO/C+BU4N7EJXcBZ+8NA9OhlvvUWFdZwXarmhXxS3gydAq3nXekcgV59akXsWz/KxFGJVKCMCo5ftoZKTG5FCnKiWLeclh6B5TPxEIkbXvQWgjY8bXHXu/g5nOPoKEijAAaKsLcfO4RSbvPPrqBm889ghfLPsPK+CXskNUsGRzm8o44xfFwUrpS716eam++MW2XrSDsn0vv8DASVHHCFDna9P7LUm7TgU2sWbiG8qLx3IUVxRXcdJI63ZgqfjopY5UnnHHxG7e9gawxWr8xf3ODegzO+F5OYw75tzffePK+GtdM9XwQYzoZyIlGKIS4F7gZKAX+Bfgy8IyU8uDE+ZnAH6SUhyvu/SrwVYD99tvvmPfee2+PDJ6KW8snaxt/zuXspW3HU1WO4KOArH3/IdpqXvCTyceEU6oJIc4AdkspXxRCfMo5rLhU+ZdASvlj4Mdg88BzttgHfumLkvGtBLe11ehmXVUl7boYT1G2/yL7jcThvR6yiNiW3yc55HcWXchRTV/1/aubMwc5jV97yvTjeLb0LUSwFxmvYLRjMUb/0XZ8LXGt7NvOLqq5eWwZL5R9RslBra7dQiz6O2U5Kbbt10hzVxdNQzFaoxGbMx7QqbWgeWtrCu/1hqdvIh59GoFECI3jaxfwWtdW+sZ2Y8UriHcsZqz/aBoqwlREgvTE4p7m+sYJ3WMxrYp2XVBWVI4Qgr7RvmQfQp4blVTlBqczunsxne1z9yg9197aIOIen7Jgja+tfj5WXxFmh2JBzen71ppG1hWb9jgbJs09vbb2dYat5s8/+CNmvnQb02UHu0UN2+ZfzXGzKvesLzav5y+hbzFddrBTVnOrsTz51enYOhl86zXPrOGev9+DJS00obGs6miue/MFO3QkdKQ02UVNxucJcnimPwCufD7I+gYuhLgZuAgwgBBQBtwPLAZqpZSGEOLjQIuUcnGmsiZjI48TA3eHUUJ6yP4UGhyC311Ba5GgpboqhW4XsqyUTDNAMnO2g5gsYpX8KgvP+Yan4zPWmz7gv7si+TnbGo3QUj2NEW28JmkFsXafx10fm8Zxr65O+fSNySJWxC/hj/onUz7hWre2cv3G1cRd2VWccs4/biYP7bwj1TZLctbAAL8tLUnth4TN8b6j+PYTNyDK/+KhUbohrSAjbedi9B9NUBMgIG6O+0w4qKs/NRP9oBoLN4JaECllCo1M2a85lOu21dcun/JSwg/BsG84YSJQ+Y7K1mD5y74+9pfN+/HzZ973lH3hCfvx8Xnv07Lx+pSsTiHLoqVnkKZPq5Uzn3/wRxz+4nWEXdmmxmQAXQPdTenLpy8UfZnuzwAr73s1JcSS81glsOaZNdz9xt2pB6Xk/P4BrutO/drwe54gh2c6D99w4v570q5M8HsDz2snZuIN/F+klGcIIe4BfiOl/LUQ4ofAZinlv2W6f7J2Yvr+1bz9cOjbxqLGetqC3o+LurjBhu07M5a93arm/MhPeGrFqSnH/XaQ1UXr2HDehvEDCRuS9/nYUh6czsZdu5T6xtutahaO3UFDRThph1/95cHpRIp05TlNSizF7FwXrWPorRX01X4TIbKPvzVWwdDbKwCoCAeJFgeyv2VkGYts8PRrjuW6bXX3ny/SxiuJ8plw5V/ztlsFv7FLtzV68FpfHxt6a4XyDTzjfcFyNlywUWlTe8vB1NKRWwNy7QufvmynhmfOepyzj27gpLWP+rYj61glcOR/HYklLc9xTUpeeTe35wlyeKbz8I3JaFcm7I2s9NcCvxZCrAE2Af++B2XlhXQeaRIOv9iPK+1z3I160aXkfubMQU7j0frV2R/vyIvH7ld/f7yDfm9UA0A5eTtlDfQOE63N7Y+3O0VY33Ccl1cvyn5TlrHIBl8OcJZy3bZOND1XxuMTgF9b0m0tnSBP2fe+eL+vTdNlR+4ZxXLtC5/raulM/pGfDE65avIGUB/13xeS9ZnOwzc+qL0BU18LJYHWra2s+/O1tGu2XyonLympc8cHFZCJuMrvoxHWVVXQrtsxxWFdp1dTe3ydYdHc3Q2Qck9zTy83V1XSp5hs6kzJhvfV2UXcbwxXLz6U2x5+g95pq9GKvItRdaaEUAVt8T7POYF6YaLOlDT2HsdzVS9kDJ84mB63mLv1zGQsE+w3i1Pm1PDwu38Yj8ubYUAg9BgzDIurerpZV1kxoTfwci1MJB6jXYNa0+Ty7l56ZCn/VRVgd0DzHeO6uMF927p5LKrx/aoqdgc0io0wi2IDvBCxJ/6QGaF715nIgfk8HrycRs0n72n5zGTM0/nqaxtqw4pXMLp7MRpQ0tBKnEGQYJkRRnctpSS+gHM+sYundtxBuznsa6tlRMAqsvvOqAAxZmepV0HaYynjpYSFwVggRq1hckVPL9+vrGSXIguRMCr595ovctzbP0jGhpEmsXAdI7EBqsRgxjFwr5+EtBpk9xJ6Y2OEZ2xABnqpi9bSXH08TZvuT6w5lSd9/+RYjCcikWRM/utDsHlgOT8dXOCpJ1C2ifCMDYhAb8Y1ECfG3FfbrPRbvzdwS8I349/gQWshuhCYUtpsk/2+Q198t+f6OlOy4dhVidi3+g289axbElGANmpNyeVd3Rw9EE6J+cPefwP/SEzgqliWzRFUz05OPPz0oZjyJcSOW6fGVwOWhRCCuE+ZqvNBKTHxPrwBS7Kms0v5R8SJ2T1oLeSkg6p46f0+huMmgbJNhOruS5EBcNphakG+XVUBWupYapZEF6TYFLIszhoY5LelpSlxeT84dZwyaKTQIAGlTen32nWV+MbAVQigIaSZYrey/9PG2LEV8Mbd067VLJ2htvM4fXCItcE7k1IFHgTDtJ50KS3b/zsthq0DJiKtWdLSifceR6TiWQz3eKTVb98vEZrlOqYBAqGZfrd5Fm78+lhaQQ5rn8tdI/+dEud2MCYDSCTFQr0xTPUMqOzzW2tRjc3Kjn7+3HthVh9SrYE4MeZ4+AVC9fcgRNr7tk8M3IEpBVfG/1dK3ZHKVwjV3ZeyrpRcKxuTcOQF8MovPTFwlT+onpN9EQOf2looCai44QiBJqV3lw7jvHG/P10qvRFD04iYFnVxQ1mmoWmeyT0uhPLNq0RanslbSjxc8We29iQXRYz+oxlpO5fpcQshJXVxI7koe+ZAH2WKz0pLE0mb3fc8EYn4Tt4n1J5ArSE9dTgaM24U1zzsO3mD3c+PRUpY1dGTtKHcMBEZXhrqonWUWKanL1X964xxuq2q8Uv/Y25pJsU1D/OgtZAV8UvYblWr/SE+zLqt93v8S2jeyds5HqxMm7zTbJ0et5BWUcrkbd9rH7fGKnBc1+M+6bo9msYTkQgtnd12uYm9ASNt5/K94aeVkzdAkTAYIowh1VOAqg+FZqVM3nb9gnvKSrP294im8cOqkpx8SKWD4nDLi2se9k7eQERK38kbQBfSU3dyD4Pp9aFMHPp1nc/67kVxnpN9xSOf2looCfjFssyEt6umqvaAjkinobjOqdCva2x8dxvzZs30nfxzQZ/ibVQiWDh2R8oxM22iM/qP5o+jt6Gaewd8/hQ7NruxssabZR5sLv1PFv/El1PsxBKT1wez84t3BTQu7/4JW4cuSNo9b5Y6ma5AsOG8Dcz7qWc7gS8ksDmtfbnG3R37H7QW8uDYQrYWX6D8aGvP+zVH7R2OrZYUzDvApw/0YQbfXA1AyZwVOdXWHtBpGoqxZHCYA0d/kTxeX3xbxvsqGPK1NZ+1C7/Ys6rMXH0o/Zl2Ysl+1w/nEAtMrxugs30uz/duR9kPfdtttkka46R90xq1zYk+a9S6JiVskgs+Em/gfhoHMl6BjFeo7zFMTNUrFBn0RhLH/c7nCtX9jn6LG2frT7Gx6Aq2Fl/AxqIrOFPbmKKL4kaNoX4Qaw2T1miERY31zJs1k0WN9ZSZ6keuNlprU6d8+iXdRr++VV2Tj55Lba4zgk9ZuY5Puv27RY2nr1qjkbzssaGeTBy7dsppvn2XS59mKtcNP18ZPz8tb39SIddJpNYwsRCcqY0zY3yfz2gtrVtbWfjL0zjip0cQOWgtgbJNGZ/nbFA9Y/UV4bzTtflqqjg27MM0bx+JCVylcSCtIKMdixntWIxmpb5NhCyL5v4Y7+2/nGHp1eBS6Y2ELIvmnl7f8wHLIpj2xiylpoq2cPJI6metoYf4Pp9POXZe0dPcWnQnjVonmoBGrZO1wTt5nKMx0tpq6CEWdNUrbT45FqOluoq2YCCpHRPTNQJWqmEhPURz9fE271WhVOfouLgx2rHYoyuT0n4riNFpbw3Ipufi1r5oPvAcQmn2qfrXPSZuqMpPHwjN0hntGN+2EA7qrJ97Ji3V01L6qqV6GidPP9bjX0EpEel1YI+5atCDUtLc04shBbcay5V95/isA2t0ureodN2eRB+MSt0zPrcaav+G8fF0j4v73LSO+Qr7tETs3l2/ZFn/QNb+duwMCIu1wTuTk7iqH0J6iJMbT+b6javtRUYBWlEvobr7MAbneK93+4HPy4eZ6Hc3kloneaZrU2qqODbs4zRvUzuhQwKzK2fTUNLAlq4tDMWHKA9OR3SfzVDXPOrCB3LG3MPpGf4rQ+YIdYbJihGNplO+Q9VnV/DyQDl628tEZQyZeHGaHY/TYBhsKS5iSIjxew4+G3reY3asP3E+xJAmqDMsvtXVzSmxYf5aVMyQpmEl3hQ03at33V1SzUVGMYwOQPlMtCW3EDv0c7y6o4/BEYOGijD/WfSvhOKpk1NQmBwcGab4jNtg58sp95/41m+ZNdzLlqKihE0mK7p7WF9eSq+e+tBZQlAWiFAZqWEoPkRdtM7OgvPnH4wL/Kdcr/HdwGXcPfpxdCGQ2KvrSz82n/d2hRjT3wdtBGmGkVYRiDgYFSw74DIuPOJcXt3RxwvD9eyghsPFO8w3+qnRSnijtJIha2y8/sSi1exZp9LQ18aW7tcYElBnmqzo6uGooQBvFwtirvap1hLqx3T2j4/yamJ8io0wpw+OMKBbDGmCsBmhv/0c5MD8ZFtWLT2MX/T8hF4jlZlhCEG3BisWrLD9a2yAOsNkZVcPn44N83xxMaOJz3fLjILUlWNealqs7RvlxaPW8J/9x9HfV015cAbRsnZGrRjCqGSk/QxmaCdy1lH1dA2O0dN+HMXlr4I+lGgcWPFSQpaOpcWpM0yu7erh44Ma3za+klw7ccZosPxQ5h95FA2x1+2EDcJeOI2F67iVf2D96McZLD+UY448isrev6IbQ+ywqvlB0VeonHtpcmyFNkJYqybQey5DPYcSjOwEbdQet4ZPc8nOrTQMdqf4XtPgEN26nuKLzlgFhckR4h3+w1yCNVqX7IcxK5b0hfVvrKdvLNX/hbAQ+iCju5aih3aANkLEDLNyYJSz+nvsGPXp/woj/dA7LtlhakXcFLjc47+rlh5mx6hnzLUTWbieKT671nfzUup8M0idKVnR1UNTYFrG+/YEfgkdPhIslA8L0jUgSuasUMZUc9JtyVfbwuf6ebNmIhVGKG34EOlp+MLXRgcTtzUnnZ0sfbSvtHo+dHojWcclFZYUHDj6C197/fpRShh8fS3wP0tb5aNHI3zoKjuriPtz38XbZfN6+MO1MNw9fj5cBUtuGf8LmY8GRlruzWf1Y1kSeoXHtP6kHgdGJbFdizD6jwYgetBaJXdbJOgFtdG6FM5r69ZWbn7me/SN7WZ6gketohquqargnrJSLCHQhMaCGQt4b8dfbM50gn8ONpOgLaCr6ZRSJnjEfZxmlRFZciM89E0YG/JeG66Coij0bScWruXW+Pn8dHBBCqfWd0dmhj72047IqClx++G0Gl1JfnKZaSGEvTBca5h8tXuIEwaDbCod5o6qKnYFxvuZ959h3db7k9zy5u5e+60pYdMnfv2JZLotNzQpWdXRz7lDfSnRbTdPerph8e7uCyie/jCaYqGt1rD45uAY66IB2gM6RUaE/t1nsvyws1hz9hE8sGkHL7f+mEvGfu6x/eTGk3li+xMpO4+f/+VzXDL2c14uiXFHVUWSb/2V7hFeG/sSxuHn8djrHck+/P5hbzL3tds9uj/B8pdz1qHx3QG9eT3c/3X/JBEKSAlPWnOZre+mlk4ob+T5gy7nm387xN6cdMgtyECP576yeIC73++nXnSyW9Tw4qe+wM07n04+M9/s6bH9ee7pqbpHLr/L2I40X33APInvPP4LYtHfoQV7KS+azmdqv8yvH6tmOG4RKNuUHPM6x8+Y/CTkH60J/KGr4AWfjZ/BsM3f3PQzMBUUKr0Izvq/9v9z1cBI5N50p2+TEn5fouLKjmtcLCj/NW/VbiKegW/tcF4Bj9ZJun6LlPCdaRXcXVbqy3EHO94qpcTIgXvt1LFkaARNyScQoAdT+tLNVXeg5Lxm0JJ4wDxJqR3xuWMa+M2LO3w1JVr/fD0t79zvS4P040WruOVuzm/rSZdy3fsPKVO8pVybGAsVT1qzdGr7Guguf9ejw6OyyeGiH19zGnXbHuJG8WMeKwlk1I4BCIkg13d0oltxpebPdR19PNJ7UXJ8ztQ2erjuMVnEJdHTeb12S6rP+ejQ+OqGNH6Wpqd+4pWyzQHpNMlhWcS1Cb8KlG0iWncvVgrn3GJ1RzdnxNxjkKoz5LvHI+F3rSXRnNth6CG+VPxZNte8mkJ1dJ5xwMNhz1vbJ0d8tCbwG6oy/7VP7DjzRXmCwpWrBoaPJoKfHocwKhl481r+EmrmvJlFyp2YbtRF6wCUugzT4xZ/3LYjoRYIR86a6btFPit8NjflohGTDme3qBueXWcZtCROGr1DqR3hvNWnwynbT7/CDT8NGBWcti/abyZteuZ73P3kN/bT4+M7UN3KgH47Uh09lI1FV9CodeasHVMXtycIP82f/3h/LDk+TtnpOK2xkd1B7x8KlQ6Nr25Ihh3FE4Hbr26supKfV+lehUXHpnw1j8pnsmhmfV7t8OsjayyxxqX4wlbBV9snR+wNLZQPDtk+1bKdz6TtoDrnc70vVzbQm9Bo/iL9enZKUabcf7sCGgeO/oJ3ii8Acufc5oOJ6JWoOLUe3YcMWhI7R9RvbKrJ2112LnkS8+kjp+25cL3d/eTXZx0BQdNQzBP68uXeJ8ItTt7TXMci03XpfGt3TtV0W5X355OPdJJ5bG67LxzaxZd8lAVgAppHfdtpr1Ib7NcOvz7KZQ9ESvl7KW/r1KQR+uXzy/V8eWN+3E8/Pmi2/JTljTnxU2ujtRm57ABmYqj2ZMD87p0Ir92XU+tGhj720xDXfd6cnetzyZOYTx8luf05zPrufvLrs0x8fBXSefK5jkWtYWbcr+Aen7z3DuSTj3SS3yhysTtZd5b9Gh6UN+bdDr8+yrTHRFn+XsrbOjUn8GO+7H/Oyfen++RY1ovsBY18uJ+nrfJwryE7n5nTVtHcH/NyZBXXN89v9uSWdPOCf2GeipSwrH9AyTNOaYaUBNLtQij5ug5/1fJzhQM+6Zvb0w1l/sAMfeyXg/ALx8/MmJtQxcFNb4+qnQE0fx55MGxzz7OU6+acX9HtHXvN0pnWMd/Dqwa1rzhc9JMOquL7fJ6YLFJz2NNtEUGa+2O++xX+qXsgZXz8uN4zuo/1z2eabr9fPskDz/GOcY5I9+LhNL/6Pp9XPndJm3p6PfsFnHHyPCEJv8unHYYeYkb3sb58fRWHPagFPXle92be1qnJA5+9GAY7oG0zKW7g8Dc/cRVUzoJ3nwLD9akeroIzbrcXKfPhfs6Yi1a5P7F3XyBgDCYXR5J8cYf/WlKfwmdmxlxmRxtoePsJtgiTIU1QblqEEYwKkcJ/nl05m8bSBp5v28yoOYQVr0DvOZvQ6HGMxi3+XnYin2oUnL1rE90avFZchEywUI6vPR5TmjanO1jOyv4RTu3rYUsobNsVrWPFCd/mkl3baeh4O2lvrWFyTXcvp1rlFJ35PYhOH+9TocOx/wjLf5rSTw6H2JdTm9Zvfn08p66MxspwCvd91dLD+MYpByuPO2V7OP9amLAZZxSYbkhO6qjna319HGoOsKV4vP3fOuHbnCpKPdxyh7s7+/jLPeWGjDhjAmYYFld2D3LmUGLsw1Xo00+nsXMrbxdJm1tuROjfdQ47BxbxvlXNEdo7lBKzv5yEZBYR9pOCLToJbnqEoV3ncP5hZ/F/v3gMsYo5/OZtjdOHX/PY3nRgE90j3eOc/eNX0tT4KWa/97yHf31Z1zCvjv0DwaPPp2twjMERw5frfdpnr+HTsz+WbHM6Hz/lkUvr9+S1R38tdYzDVfZmGitV3ySuR9BkPCnGJYWGdsDJIK2kb7w8dyX/2X9ccty/cMYSDvvY4an+c8QyGOqE0QFmR2pp+Ng5PB/rZtQcYrphcW13j+3PR52fvM7tdzm3I7G/Qj/gH/jLGzLJhy8vms7Sxv/Fa28ezNhwLVa8Ej28A6HbvPiVx6/k1P1OzalP80GBBz5ZmApc6QIKKOAjhY/WIqYDP47xQ1fBC/+R3AgwJEM8rH2KJaFXiAy3Q7gSzNFxznMwCoFiGO4ZLwdoffLGZJ7BIiNC7+4zeYJpbIrGPCyDXsr47k8+kcxXGRlayrc/+cXxt9LN62l98kbWhi16E7SvcstipfMW6Oap/vn6cb6yZW8tb/rUTYCaO+1weduG2tCEhiUt6oLl9qp9R3Ye7ElVF/HAxhnJfJcV4SAtZ84FSKlr0YId/LH9p8l8mZGhpSyetSSFb3z14kN5pedRfvPOT7D0HgQaCCvJkU1y3tPaeEbpIn62ozaFb7vyhKtyy0+YPL6N1pIS1lWU2WNTVEFz0UyatjxsL2wL3Q6vnfG9ZJFOfx7b/0dWFt3DDDoZC5bz2yKNOytD42M8qsPcc1jX+aytAW0YNo88Nuop013ubuvphH52j82OAerSxtRBet7MoZ5DGCvaksI/fu/lR3m/7Fl2B2zee3P/ME1xkeq7aTx7d9uGEzz+uwYXJMf0qe6fZeQsO+Xs6B3mbP0p/kW/m3qti5Fwrb1/wKWX7pSj4q43HdjEDY/+LOkbmlnJ5w64lNWnXpTbc53WT21D7YSNEJd19XJhbHeKPar+nN2+Hzf2PkGD1olEIBIi66umTee3ZWGkkOP7KgbeG7e9+nianv15ck/JaLCCm+WXuWtwAReXPMc1wbt5TOtjXVUFbbqOhr3bOd3n9wam7hu4H8e4cQG887jn8gzy4F5oQVqjYVqqynLi+QYtSRwtRY/byVf53UUXc7b+FK1/uprrq0o9kqgBy2KNoz+89A5au1/18JxDlqTlgHOIl3/dw51WaRqP3+fiLmfgwbq568m2CntBMZ6IMap0m1X3FZdvIlir1ghPct7ff8bTxoBlYaIjXX0YFMXctPCGzPkJXZrNKm62Khcqx34FzvheUmP6M+bjKTxpVTk2tx4MBee4aSiWLBPStKt99NKdMXUmcWXezDSfFZZAx0zh93val8azT28bjPP4f18SzarF7c71qOKTG3qIhz/xVY8+tqe9eoh55Z/m2c6HPT60bP8rxyfxLHkolXx0Vx8YeojAWT9Q870VvrCmKvu+CtV9YzLAr8xPsUx/IiN3fzI44PBR44GDP8d4kuDHMZVS5JRHEmyuaEXXDTxVfAWLSk1ffm+St1o+k0XlKPnIdaZkaLeXO+2329NTNmTkwbrzM6rgV0/6fVntidZB/86snGv39RnzE7o4/znzgoUOq7uTeQzTedL55PFMlp0oE8bzI2btC1Oy4R/tPQe58Nuz2uDAxbP344Bvt6pZPLNeneXJxVl253r0KysXDj0A0v4aS4cwKtn8lSfsX7LkofTlo+fo5+l9leu+ChW33JAaAWFl9Zc95YDDRzGEMok5C1Xw59nmkQQ62Gvzl0Pbaa/054Mn6+rzv65dQ5kXMRsfNaUdGXiw2crxO59+PKs9Q+15cZ+y5id0cf5z5gUn7nG45ek86Xx48clrXXZk065O3uvqhz3hCXvsdfHs/Tjg9aILEYyoy3PZ4ub2+5WVKxdcYimFdi3dtWU+Sx5KXz56jn6e3lf5aJmnQ0/cnc1f9hYHHKYqjTCDZrUKKo3nbNf6T9O574KcYVhcXPIcrTWNGe9y6wj78VHLTItDDv4XyuZcS/XBNxAo2wRk149O4cSGK335qDMMK0WnOR256ldntSdam5/edzyOXF2O6TcgLs5/rrxgS2jccc9VHHjwNZTNuZbPzkz1iXx48clrhU7r1lYW/XIhpXOuZfbB/+Kru55y7+2Hw+b1lBeX51ynrw0JxMK1aMLW3X4oGlX6fiZNctMIM+/fT+aIu+ZResgtSV/bU+1w4TPdaGbl+C9Z9mdk1eIG2qmmLFiT9TrIfQKU4Jk7nD9H2fxlb3HAYSpO4E6MTLXbMhi2ecsuOPHMVI3nKuUk7r5WFRPTLJ14z/EKXqieyBc4jpBlb6meH/5PWkp038+0QJqOsJ8WdkzXkm0YDQ4TrbvXFrjvXkKRz4eURy97bJCTQ/XeC6XklNhgik6zJiDoivfmol/td13S/M02nAAAIABJREFUHofzrmhjJvuFsFNieaJ9Duc/wd89ORbzcuSltI+P/8rt4YP52eDD7A5qSp9Q8auV3HpX/7bOXUzLxutpi/clyxzRhecez71922j909UMKkS0PBrmqhSBUrJ/PDUmvWroczSJJ/lUxc+5qabS4/v3RcoyaJLrCG0kISQlkYEeQnX3ESjbxCPWUarqObazPqMuPNhjv2Da6Uof+twBl44fyLI/I6MWN3Z8/7tjy+jedho6Rb7XOchlXwUACj+xsGPh2bj7JzeenL38CWLqTeCP3KgWzhG6vdBx8YP2gpK9xqzM7Teiaayrcv3VD0YhXKXOpQggJcXxMENt5xEZWMay/a+kLlqHwF5pXrb/PxPu+6IyX+X/KY8yovpQk5Jy07QXMAPTkos0TZ+6iZYDzqHOGM9jWSKlZ/HT0kwiMzbw3UUXc+NgPJmr03nIU/L7OTDHeGK3Yg1CCJ6IRJL5/CrCQb63/ChuW3aknb0bmKGdyLL9r6Q8ON3WpR6rINz3eT5/2FnJa3Qhkrk7x/M6CpB2HNBZzHHaqPk9OD72C2HHHS05np+QM76XzFv4RCTi/cObaJuU9r3/ZX6a31fF1D5RWYElBScO6VzdGUvJJXpTZw9rOrs9+UWdBcx1dDEi07jPQlCSyIEJ+I7NurIIKgmtsCVTfMpyOiGtfc+Fwzg5G9eIr3Pv2IlcE1jPD6u8yaRHNI210+r4nbUwOaZ10brkmKpzdcaJzNjAadrLquq5PLbVHvN4RfKZOP/Q81OekZYTW/j3pTezbP8rEUalvUBrVKYuYILNIFHkoXSYJU0HNtFyYktCP0gQNsJc3hFnyeBwSk7ZWM+RxHack/RDa6yCA9rnc+SA7QumFEgJ3+7q5ez+UZLJALLA8ROAoJDERJhTrHJWd3b7+vMT25/IqeyJYOotYubJw85Hn3mPtZwVtuWlx+1TVtYy8tBi9i1LykRuyYnz2fPVqPbt76QtXjg60u9OUEMaoGzOtb590P/6LWp7J6oDLiWb390+3qf5+Ihzr90Kjpg105ct8erFrwLjY7C1+AKOOiB333Puy6hh/877HtthfEwA5bjsbfj5XT5wxtxvHFOuTfFPe/wPWNFKdE/0/7PZ95FYxHRi36rwSYb8darV6PS4VOvWVoQQqP6gCSFo3drqqxmc5KiWN3pW0GsNNfska1zMVVbWMhT1+qHWgjbFmstE8/m5ubYls8NYUiL0YWS8AmNwDoGS19GCvSz85fcY3b2Yzva5VNduoXj6w74PSqYYuUDyVPEVsHkoyQF3dNprGhuUynHuWG+gbBMC9VRcY0j68Wq6tG5tZd1+jSl668kvA1dsVulnhpnap/n4iGGS3BUrbTUcVddoiVhs69ZWSg+5BUvv4TNGI+WW5cnG5NiajvqKMDt67XETCmZKWbAGyi2ln+2U05K62PPuWjkhDexxP2qj1pQ0d3XZHHtppur8K+DYng6VsmWgbJOd2T6xX8Pto4vuXUd5cblSE94Ngf1HN7k/wOl3n+sLMXDIHvvOJ39dmjaBwy21pHoILGnR8nQLrX++3rahbxsg7Z+/u8K2DZTxu+b+GCHhzfmXVRvBVZZS80IEUzRX0usdlTpjMm1S8NH8mGg+P6ff2oba7MlYj6EFhhGJHIbBymdsmpqAvvhuhst/TdGMBxgu/7Wd61CBpC6Fpo6pCgENotPu94euwvjt5USG29CQXNXT7eknd5ze4bKr1iNClsW0jvkeTZdkG3XhjZenx2bTxzmRezWlT/18BO8aSjJem/B5ZbxWSpYNDNk66U+3IAM9CAG7gxqDQnj1X9x+48Ipc+xFP7+1ju5tp/H8QZcrdXGuCp9IqO4+tGAvEknbUJv9vGxt9dSjQqof2TTaluoqWiMJnZb05ywNuerqOOOvFfUqfbRtqI3BsUGCPr5nd4YtVez4wnUlOtc/dX2y39MRFMV7TQcFppIWyi/PV+ZrROh2goac8teptQkue+SyrH91DWmwpfs1LupJs8EybP2Ej39Dqf0x+9PfoeHgxflrI7jKmj3QRYNpsaUoaGteFFWw4sRVKZorVOxH+2vPEJHD7JDVtBgXs8E6hiPEO5SIYURCDyJV82PP8vll6zdvvNRCC+1AaOpV+xRdioSWjTSG7ZfQ9IfDMqBtM5pLc8PRptlcFGJQE8h4BaO7liY3GoUb70ILePVJNSk5uH0+O8Q/eDRdVG00hGBLKMxFp4z31+zK2TSUNrKl7XlP7tWUPvXzkUOWpN6ryPd58kh8XAcH++1ref8A13V1c5m1k17S2TaCqCmZZppqv3Hh+ge2MDBiYI3W2foeiZyTTh+O9h3F0wMz+MoZn4SdLyNHB9gpq7khfhHPNm729KshDbZ0beGiwy7y1JUO3z4uKuKi/oFEY1zPWRpy1dUp2e+/xvOLJpDuVxYWpcFSqkJVtiZOUTnhQJhRcxQN4QmVW0j1i5+E8qLprDrxW5OyE3Pqa6HsRQ2SXOJekCk2++HQQdnXeRJz7Tc3/HbEZowTTjDfYjomkqN0X+W4TEEmXwfluQmvtSSQSxw577WMHOvOfS1kz56znJ9zH7vz8ffJ9o+pHwNXxA6TOQl/ejg1hiQ6chD95Z10m/3J+FTTJxKfr+n5MV33S7+8kWnw5buGKxM7yDLn1lRpkGx4rsGll9FLXSJ+uGn3Ju75+z1Y0kITGstmL+O6E65LKW/NM2u45431yTeAmkNhWAgsMwJINH2YGYbJN7t7eOhWWFdVyS5HQ8Ppm0Qc+b7HVvPDKEntj0v6JX+Lnc8vtGCqbdXHw5b7WVds5txvqVBHoANmgNgtc4gMt4HQkIk29cgS/lRSyZ2VIdoCejIOXKfI0OLAwuZAu1OKXRNYzz8aRT67ay0+fedhXNHTz5lDiTc+odE697O+rag1LR66rZ6bp1XRn6BbhvVSjpw+l+d2PWePG4JlIxbXtdl+0TrzCNb1v5rIySlpHhzj9J4OdlFNc/HHeW36e7ZmyqxGZRvvq6zjh6W6MhZfa5q0BRRxdNOyQw8ufRQn92a91kU8WE4xcbaGhpLD0i1LuMH4Er8viVJcY+d7dPJNtrdEuHlsGS+UfSapw+O3dlQbj9O67hDWVVXQbg7b+Us1jT5NENJKGY5boA3ZfDHlHx9XrLmnlyMHIjxy3ef4ov4oOham0Hhv/+W8/skzUzRPnLWW9HyqfusUHn9AsujeRTTPbybed1RSD6j0kApQ5OlUYW/Gvd2YOm/gm9fDA99IylSq9CrSX+9ClkVLVx9NsRhYqZ+XyvszQFiCOe1H8tOR/07RgkAL2nW6828qcmsqtS6sIPHeYwhWvJiiD6ELHVMR6z//0POTk/iaZ9Zw9xt352S7KkdmyLJo6RmkafbnePCNe7mpqtSjIXL6wDAPlJal5CXMJ99mOsbb+5yHqha0JDd1dnkm5EzjFLIsVnd2c4ZiEnf0PoCkfke2MXdrXrRGI1xfM81D3wQIWJLPDQxwX5lX28bbaMn5/QMcPTrmq9MCZGxjS2c3ozLADTXTPDkiWzq7OX0wps6Vmqj7uoHRpD7Kxvv/jRvFj1N9WIEHIiWsrqlR1nfKoMGK+CX8qbzUV4cHKTlheJiXQ6Gcn7H0+9Of5fN3h/nn2JspTXwoEqFl+nRGXVv03Ro97nyqNzz6M+557/ZULZYMGklBUcxI27nEeo4EoHjGAwQrn/Fen27rJOmfuPHR0EK55YDkW3Q+uQNV+fF87/cZ0VLDYuebtybf5upFF7tFNbVh0/NmD3hya/ppOOSjraIJjVe+9AoAR/7Xkb6LrrmiLm6wYccuFjXMUPZFPrkls0JqhHq/SGf7XEpm3+SJRSbtSRurrDoTGfJ5brfsnYNu/Q7nq6vN5+shmSMzQ70VpknYkjnrpWhS/n/2zjw+juLM+9/qOaSRZGl02ZIlO7YBc9rE3IchAYMNCAiXbchFNhA2bxIwybsQmzVGYAcc2AOx2by75NglmwNswpVoE0hgE2KyBAgmBmNMEtvgQ7Ik69bomJmu94+eHs1R3XNLGnt+n48+9vR0Vz/1VHVN9VO/+j3MsGCa2OW2NDHdr9NHKaOueKZFInsjdXbOHX2EJ3xfUOqZxCJReXZaKiay2n9IrX9EavSY+VTP3fgSB/Xfx7FQisp3hjYuxSOyHDttG00awZU6HVZ9/JtZVyBMO4QihCgGXgaKQuc/KaW8RwgxF3gcqALeBD4jpbT/Wc8Uw+NOzjR3YKp5IAdDYj3P6Yt5bsx4NXeVb2Vu9Y9od86Kp5f17aX1oZm0VFfR7hA2kbNUYrs6Cx9bSF1pXcaDN4R8IIOWvshmtiyJzmjlDzmmsY62ofjBO2xPEseS/d7IrxjtXzNf5cI5s5SeD+fItCm3T9PoS2FSqduU15ZEPzzo1IBhpRxDInsjdXYOjAwzsyjx4J1MeXZaKiaynb81lf4RqUNzoHcYtm3iCd8aZoouDuyt4cHAinCIbewglB2/BtWzKFy9lB232qBX2mjbSBiP1//gU7ah1GwimSnEKHChlHJQCOECtgghfgF8DfhnKeXjQoh/A24C/l+qBvj9fvbt28fIiLUUZRiX/tRYjQYecTgJJvHj7pCw49j4fW7JXi+R7B3ey9O7/p3IJQmTktSmGS406WVA+BW8uaYySjJVDStWsrU96arWxaIuYGhkW/GQU49vW0OIxLarNCUsbbO5xoSZX7FRIcJkz722v695TtIzcLCcgRuOsW9/k8eu4meb6zKJ6kNFIzOLPRzw1Sj9obrOrjxTS0VlU66QSv+I5P7fWPYa/OzfadSMN5hG0cVG13fBb0zIKjwuAv4K5QBtPgLC3WvbTNG2RVCMIaeDeMIeKI0Yy2Dooyv0J4ELgU+Gjj8GNJPGAL5v3z6mTZvGnDlzEIkGDN8MwzFSp17TOOB0IG1kogSSmYEgXoVOgep6ATiDbgKO0fBxKSU1A1WUj97J/31v/Pri6c9DjM6zuc22achnvS0/ApYxcCkNQljC+CpJaWtZxcBX9fvg1M/xFUUM3PqeEmeaMXA7qHQqwODA28WHb+tWDyA+6eahwAokxGlYD1PE9Y7j+X/6zriYtGnDqp5eZQzciWb4LTim/D4uAiclyy1i4GGYg7iivSN57Co99urOE/HJDqWfzPoMU4RnyTruCB7Lw09fz30ycQz81u5e1tbOiIuBr+rpDedEld3TcNnEwNOeAEiQ0hFFN5W6i0VddUh5IKrY27p7ubu2lkCMFr/pM4/LwZ2uJ2A4Ovxkykb8Sn4MIWCkYxnFM5+wNdmqmVxSKvsu/mFj018OB/CknkIhhEMI8RbQAfwK+CvQK6U0p7b7gAaLa28RQrwhhHijs7Mz7vuRkRGqq6sTD94AJVVGbNnhxqvrzAzK8EYFp5RUBoPhzy5pPXgDxvWB8fMdUhD0VzLir6XIX4LTLAf4SM105kyfH9b8aPB6EK4+ZbnJvIKPa6h8lZrRGxhtuwYRqAQE9f4A3+g8xMr+gXHxIouffgmGhkPoHI8uQYK3yEuF21C3m+EPcl/HIdZ3dlPnD47rePgETRc9BJf/E1de/A+s6dfDOh+JZoTrO7ttz/HoOhWBYKgs63IidVUW9JzBBXpIkU9oyFD9zh7UWNBzBhWu6cYtQ/Wt9we4tdPPof5zwrFuPXTdPr2GB11f4ll9Mc/pi1ntv5l9eg26FIZexthNfP5vnuIzZcuU+jVgvEWt7zyENxgMV7XCXcGG8+6n6aKHaHJWc19nN+VBGRpwQA94CA4dhQzpbCAFTf0B1nb30eSspnnaQlu/GX0gpNoX8stYaDEuUrdEIKhwTcfTdz2v913Pg64vcYFewbrOHkN3RRpx83WdPZw8UMLqsZtg4QquWtTA4qu/xIOuLxn+wDq0d/mQj6G269DHvPHl+W/mj+UXc//SG1m/+F7qS+ujdG9m+K3fipDG1MijTbPsGxLw9H2SCtd0BAItWMlI2zU80Xs7PwheREBqYW2bQ/3nMNC2IkrzxFzAbPB6eOCaBUYWLgVmaod44JoF9Pr8UUlJ7CAE4WcLwKtL1nd2K9lQQM5lr1NaxBRCeIGngXXAf0gpjw4dnwX8t5Rygd31qkXMHTt2cPzxx6dqtxoHt0ezQWLhcBsbKRR492A7utaLEEGkdCAD5QBozn4QQTo/6GSocoimeU207mplze/uQiqifPVByQsf7rVeBEok7h6xUGsi0UJN5PZgLVjJAxd8PaNFFLvkAvX+AN//cCypZAB2ZVW4prPlky/a2hGbPm5oNEDvcHx2G3ORKhaRyQiu1LZwmven/LDKMZ5u7aw1NM1r4tyNL/GE7wv8aVp8qryTB0pYWfIdXrmsyzbNV+S9IlFZ4mLruqXj/vj+SZYJO8zkDon8EEmNs6qvlX9iqayrDh6gqTN+b8M+vYbFY49EHTP7mebqpb5sPF1Y665W1vyPsYVf+r2Mdi4zzlP0D2+Rl99d/zvDF1bJGZJIgGBVV1WdEyWJSDYBB2BMHmJpuEncI1NYLWKm9B4spewFfgOcBXiFEOao0gioqQATiWn1WOqEC834XoHe0V5wdCOEMXMQIojm6kFz9UDoWFAP0vz7Zja8uoG7t9yjHLxdosjYBu7yqLe/J9pCv20TjA3GHV7VOxC3TdslipDdl8ZtD5bOnpS2Mauw6pRVyu3ETl3ni92DodfnS3GJoqjvVfVbdcqquPPMrdnPbN1vaYOZymt/7zAS2N87zNBYIEriFojb+h4Jc4v1ldoWPu79If9S6xqXVvX30bzlblp3tXLHsmO5s2yxUnb4zrLFPHzCn+0lFEL3cikG5sGRQFQ9VVK6xbo0+k2Sfljz1NtK31ltKTf9Eyt90DbURvM0N89Ni9YiN0MkkYjsZ+a2c/N5iNzCr7l7Ka5/isDgcUg9/i10cGww3DeTkbmwgqquqjoDCSVqzbLspJDDMPtGiaT113eE+8DrR93KsIyWrx2WbkN+IIdIOIALIWpDM2+EEB7gImAH8D/AdaHTbgSezZWRSSMixBIFh9s4XlKlvOymz9/Eecefx1XnXWVb/EhwhM3vb1bG/KQUOLoNOViueMR4Ze7qoT5ovDJGyqla4sX7lG8QTUEXzYvXR8lzrl98L/cvvZGSGS/E5VwcCY7Q8maLbV3s0DSvifXnrsdb5DUrR0UgyN91Bfht76fjXp8jJUNj69c0rwlHd/wrrq/nZB56fqelDQ89vzMq9yeAPygpK3ZGhbJMjq8KVy1q4IFrFnCXe7NaWlX6aXmzhasWNfBh4z6l9OqHjfs4/a//Ei9hbMY3I+5V6o5/S/LrMqqeYbngoDRCN8Ho3JjJ+GHYH1T6zqyvlX9a3myJy1s5Iv18q342Pk89OkaI6a7AF3hOX0yD18Onz5pNg9djvOEp+tnm9zfHlSk0P0XlOylxxrNUAjIQ7puR0rB2fUiFyLqCIVyFos5AQolas6wZ2jmMhmRxjZBYCXrAo4x6jWgaLeUl4T5w+7vH8PWYUN3X/Tdz+7vHJKxLJkgYQhFCLMRYpHRgDPibpJT3CSHmMU4j3Ap8WkrVasY4shFCSfZ1MhU89txjlJSWcNdX7uKZ3z2jPKd9dzu3v3u7ZRlSwtB7GzPbsp6GXMCkbPVOEels8c+qLECzl4VzGm23mtv60UJGNbZdciFlkM0yM+krqcomCJMEMMX7pgqxPreUYIiQCs61jEXaPHAp5TYgLsIvpdwFnJGxZSkgMkM2jL9OAhkN4mcvPps9e/Ykda4mNCUHW/q9cTKkYSgkaFvLSml59QHax3rHt7Z7Ki02BVlLvCYrlzuZsJL7jPRXbGy2pu4iOtvj1yssfRyJWH97KhNK8tr60UJGNbZdkqlnUvZGxNfTLlOBTPqK5TZ0i0TFZpnZ7pu5mMDFItbnVnTJSKngbLZTKsgfOVlSe51MBdNLp8exYAQi7lixo5jl85crY7qy+1J1LNaUwY2In7b++g6af3dXVPqt5hJJqzMQL6OaQOI1kzjiRCGd2GywahMllX+yvMYSCn8zNmisI9hI8tr6MUEMNdl6Jm1vRHw9rTItkElfUV0rdRdjPWfExY3DqfOy3DdTWQ/IBLHrGaOdy9Bi4vmxUsHZbKdUkD9iVkRnyE7meLLwFnmZUTIj/Nrn0lxML50OQMdQB37dj0NzhONzi6Yv4oFX/4m+sQ50v5eSoSv4+6WfUs8EFCngWspL4tKsjWgaLRVlNAWc4C5NKIxlwowXRjELUhTTzzVMv1jNnFSxWb8cpWrWi1TKs1KbbalS7gXHaAqWgU/QUhSIY6FAkn60YaEkU8+k7Y3gD6dVpgUy6SvmObFsk0D/IoLDH6Fkxgvg7FWWma2+aTeBy+Ys3Czr3p9tpydEMZRuB9UzfhYtlHfRQ1FxdNPGXL4dxGLStVBSiYEnQ5NKF3v27OHyyy/nnXfUlJ+06Y7ppNCaAtK0E4msxvFzKDucE+SZvRMtWTxV7j3ZyH85WeDLFzZy73N/YTRC1nUiXlMyQqoptFJMaZYyrOKtdqniUkQc1zjBrCurcfyQv8NSwyane9RBNh/xrMRi00gRaIVUfQ7p1SHTWG+qdkbaqClSpIHx83fuxpds7U9U1w2vbkgo3zwVkTcx8N7RXj56VIBbl1ZTW+5AANPLHdx9xbyMX1NuuOEGzj77bHbu3EljYyPf+973smM0pJZCKzb9VrZhFW/9+dcS8pyThZJrnICXns1Y6etH3crTJeVxnO51Za6MuPGRyEosNs0UgSqk4/N065BJrDdVO2NtVA3eJuzsT1RXU5rZJCfoUueJnU+w4dUNCes02cibEMr73e/j1+N34bk0F/Or5mfNRitktGM0WRbKeenPepOC1W6xUNLcOKSxiyzd3XXpzCBVOHfjS4zWrFZLryaxwy/Ze2QcyrNri6v/LaV+kI7PM6lDum8fqdppZaMqWbGd/YnqaiXNHCnfPNnI+xCKavC2Oz6lsHBF3APZBBO/0Gily6AavO3Ot0H7kFp3wuq4iaZ5TVnxx4HeYUrrLKRXE9iQyj1SOa6EZVvoKf+Ip+PzTOpw1aKGtN56U7XTyhY9pKeiGsJV1ySqq10y86mOvAmhWGWKts0gXUA0rOKqwkJ4K414vFXceqJ46TO9nigp0VzYYBXvTYnza+XbCfJ5VuqQIhLauW2T8WbS7IVvzmVr8d+yq+iTbHHfxpXaligbU7E/0bmahfyG1fGphKlvYQhKrrYQYbpfAUnAis986ueS4jkng8nmpd+x7Fhk96Vx3GSXKMqaDVnh/CbJLU8G6fh8MnjLtnbGrs8Md+NlAE0YGZU2ur7LldqWsI2p2J/o3OXzlyvttTo+lZA3IRRTl8PkZZtc7bBeRwGJYb6aq9gms8/KCgtlsnnpxqv9jXzjt058pT9Dc/VS4Z7OmrO+ljUbssL5tWuLFJGOzyeDt2xr5z+fFM+Hj0CJGOMu92Yu/MRXomxMxv5EdTXZJvnIQsmbRczJRr7YWUABeQlLPnwkpiY3fiKQ94uYBRRQwGEMxX6JWPg8dVy88aUJ3ek41ZE3MfBc4pe//CXHHnssRx99NBs3bpxscwoo4MiDak0gAgFHMeuGrs25Dkq+If8G8MiV6n8+Ka3NJpEIBoN8+ctf5he/+AXvvvsuP/nJT3j33XezZGwBBRSQFGI1uz1Vxl9Iv3uD+CJPjp0TdUk2hOzyHfkVQjFXqs3Fjixkfn7ttdc4+uijmTdvHgDXX389zz77LCeccEI2LC6ggAKShWK/hInHVqt3a2YqZJfvyK8B3EK5Tb6wlmD1sSDAgU6f0027QyMYIuI7NAd1pXVKxsr+/fuZNWtW+HNjrZc/vPJbOLA1+sT+btj2duIfiphdl62LrqblwP9M7I7LCUAmWiCJdl0mVXYWtVsmEznRt962Cd8v1lE83M4BvZrvuj/NR5tuwVXxVtTu35t7RrhocAyvGGLEU0fJpfcZO4QTsFkytTmy/ctdtQz1HMOYe7stYyjbetuqPgjJM3nsfDARmuUm8msAt9i9JgY7cIZE5Xs1jQOaREbsogrqQQ4MGik7YwfxKBaOrxt8h5TZN9ADiWf7MW8IrYFDNO9+ykjVZep+O3T49R2GsFIeDjiQWWINUw/DlI819TDAoJklVXYO3sQmAzlJULJtE4Fnb6Uk5N9GrYs7/d/m5l/tYeeMbYwRCPfFh2pKKGWEpiFJyXAbz/3q71hfW8OINHY3x7ZNNmyObf8+fweytAMz1Wmfv4O7t9wTdU8wuNyR94X0eeuqPnj3K3cjpSQgA5Z1N2HnAyAnSWeskF8xcKtdamXjm3k6HA6kYiO1lJKOoY64442NjezdG1r9HmhjX9tBZs6oVd8nJg9iHGLeEFoqvco8i5G59PIRmSTWUOZljMjhmVTZdhraeYScJCh58T6cMf4tEWMcrHrDGLwjMKJptFSOT2i+VVEaHrzD58TkV83UZlX7x06Y/HI0LqdronyfqUCpP6/7w4O3CavcsnY+yFXSGSvk1wx8ybromReAswhOvzn80a+cPoe+U+imnH766fz5z39m9+7dNIghHn/2eX78r/db22CnDxLzXbtTvUW93elIS2dkqiATHY1EehhJlW3luzzzaU4SlFj4oNOpfi4i+6hlf41os0xtTlaPRnVeuhos6dpgdW46PshVrD6/ZuCxK9VlM+C8v4NjLg6f4rLZmKTSTXE6nXzrW99i2bJlHP/xa1lxxcWceOxR1jbYaVXEfFcXUItETYjudw6RiY5GIj2MpMrOoo5Ismjd1crSJ5ey8LGFLH1yaVakaXOiR2Lhg9qA+rmI7KNW/bXcVcu5G19i7upWNIsJUrI2J61HE/BmlyIYwV6rCyYvUqWy167dJlpjJr8GcDAG8a++A3fuQn5yU9TgDTA9GERY5O2w0k257LLLeP/99/nru3/i71d9wfreibQqYrisq3p64/MwToTud46RiY5GIt0WLwhAAAAgAElEQVSOpMrOoo5IMkhHbzsZ5ESPZMk6AjH+9Uk3M7pPwx3zwl2s66zqGd/Z+JW+IYpFvIZM994ltprcqdiszK0ZU6TUXfgOLs0ezztGZ2XVoUMU69E3dWkunCLGPxZ6MnbtNtEaM47m5uacFKzCo48+2nzLLbdEHevq6qK21iLmbAeXB+FwExz1IdAJSg1dCDxSR5MaQ0LDDIVLqaHpVcyqqElYJg43jA4Su623a2CU2hM/br9INuNE8M6GA2/B6ADzS+poOP4atvvaGAqOUB8IsnpEo+mCb+TVYlssjqsvp7HSw9v7+xgcCdDg9bDuihOSer2dXzmfhrIGth/azpB/iPrSelafsTq8UJRU2TF+pmIWXLIxZz79yotfoXc0egt3QAbYfmg7nznhM2mXm4kfLTHjRLTKj+Db8waOwBD79Rr+xX0TSy65k4vmn8D2ttfDffHW7mE+NqhTJPwMe+o5adkDNBy9LKptRg9eQV/XgrjbOEIz8VRtjm3/Ctd0gv0fJcAAaCNGrs2DVxDoX0RAl7y9v4+bFs9N3x8AP14JvkPjNvj9NAQCbC/2MKRp1JfWs+bMNVw4+0LLfhkJu3bLSZsC9957b1tzc/OjsccPOy2UbfustRIWNqYvfFXQQjlykdWcnXmGicpDmdP75FneURWOGC0Ut0NjTBHjcjvSjxb1+MZo7xvhstWteaPBkK0MN9bltlEXlKw61E2Ts2pK87Az9UVWc3bmALnkHWebfz0p97HSWcnjdSgT+RcDT4AZFcVxCy2aEMyoKLa4wh49vjH29wwT0GXeaDDkKmYbXS60OQTNNZW0Bg6lnUMz18iGLyZb49wOWcnPaYOJiunm9D4TvGYykTjsBvDKEjcNlZ7wjNvt0Gio9FBZ4k6rvIN9I+gxYaaprsGQiGud1XJNLvEU5WFnwxdN85poPqeZ+tJ6BIL60nqaz2me+JR4CuSad5xN/vWk3SeWvVYxy/g8Rd8YU8FhF0IBYxBPd8COhSocA1NbgyHdvJRpl2vyh6cgDztbvshWzs5sIydc8hhki389qfex0VnJZ+TfDNzXDQe3G1olB7cbnzPE3r17ueCCCzj++OM58cQTaWkZn51Zxc5zmTswZcQoNNa5ypWnpRKzVfGeLTncJn94kmKKlhztbZssOb9TJX6dKSYjt2UBUwf5NYD7umnd8ThLf/NlFv7qsyz9zZdp3fF4xoO40+nkH//xH9mxYwevvvoq//qv/xqWlFXF1HOdOzAlxOYS7NvLqva9cXzeVGK2VnHj8xvPj48Fm1ziSYopWsa4f3M3/Oy2EOc3hos/ReLX2cBk5LYsYOogrwbw1p2baX73e7SNHDIW0UYO0fzu92jduTmjcuvr6znllFMAmDZtGscffzz79xuLQGZM3amJnMYA04ZCF6Spv5fmgbG0Y7ZWceOX970cEQuG+qCkuauHJmf1pMUULWPcu54G/zBNQz6au7qp9wcQUho2T5H4dTYwUTHqAqYmEsbAhRCzgB8AdYAOPCqlbBFCVAFPAHOAPcAKKWVP7kyFlvd/wog+FnVsRB+j5f2f0LTob7Nyjz179rB161bOPPPM8LHKEjd1FcVZ5b1mDRZx56bOfTR9+Z20irSLG0+1WLClrRFTk6YhH01DvtAnAVPI/mxgomLUBUw9JDMDDwD/V0p5PHAW8GUhxAnAauBFKeUxwIuhzzlF+4g6VGJ1PFUMDg5y7bXX8vDDD1Nero4jTznkQBckkV5JpsimroilrVZyF4cB97eAAkwkHMCllG1SyjdD/x8AdgANwCeAx0KnPQZclSsjTdSVqLVMrI6nAr/fz7XXXsunPvUprrnmmozLmzDkgOOaS95ztjnqlrbOu/qw5f4WUICJlGLgQog5wCLgD8AMKWUbGIM8kPkomgCrTv0qxY6iqGPFjiJWnfrVjMqVUnLTTTdx/PHH87WvfS2jsiYcOeC45pL3nG2OuqWtH19/2HJ/CyjARNJaKEKIMuC3wDeklE8JIXqllN6I73uklJWK624BbgGYPXv2qR988EHU96lqjORii/iWLVs477zzWLBgAVooAcP999/PZZddlradBahxJOuKFFBAushIC0UI4QJ+CvxISvlU6PBBIUS9lLJNCFEPxKe7AaSUjwKPgiFmlZb1ETAX0Xp8YxzsG2EsqPNeWz8zKoqVm3d6R3vpGOrAr/txaS6ml06PS6u2ePFi0hH1SjcvXta0KxLkhVTex/FK+JrW2kZaKr20+/uVP4aRP5YVRRWMBkYZDhqMF2+R11KtzQ7Z1hVJ5Qfd7lzLNrHycTo5OWOvOWYp/PmFuDJSqVOucmpG2vn6Ubdy+7vHxN3DvHeH/ns8M15AOnupz6LuzmQgVxpCuULCGbgQQmDEuLullLdHHH8IOCSl3CiEWA1USSnvtCsrW2qEpj5J5BZ3TYi4LfO9o70cGDwQNTgLIZhZNlOZ4NgOsXbG5sUDg3/7wDWG9GY636X04MXmhQQjxhsKE6jsu879eza6voszOEJraQnNNVVRKd+KHcXhUEls3kAVXJqL9eeuT6mDq8qNvG8qSKUsu3P9fR9VtskPTv+A09++J97HJ38S/vRjS98roWqvWLg8tJ77BZr3/TKpOtn1wUxyasbaOSzdfN1/M8/pi8P3uPbUBn76x/34PW9QXP8UQhvPdpVue042stk3sw2rGXgyA/hi4HfA2xg0QoC7MOLgm4DZwIfAcimlLR0kWwP4e239loqDx9WPs0fe735fmUbNpbmYXzU/pXvG2nnuxpeU6mkNoR1w6Xz3yuoLkzfon0+yUFibBV99R2nfFvdtNGpdACxtnEmbK/4FrL60nheue4GlTy5VzpStzk8F2ZrlWNmossnu3KG/rFa2yavFq6ijM/7GwgFSkb0m5HslrNorBktnz6LNEZ/1RlUnuz6YUl9Kws59eg2Lxx4Jf3YIQVBKSo/aiOaOl2RNp19MNlLpTxONtEMoUsotoMgSbGBJpoaF7oGwyWUZid7RXgLOdhyuIFI6kIFyZLAEiNctUQ3edsej4OuGgTYIjiE1F4yNRL2uWv3sJZsXz1m+laLa5xGuXqTfS0fnMiCFh84mL+QzW/erpTlFV/j/ifIfppu7MJlX+lgu+TNb93PuxpeSDgOY9+ira4tLiGtlu1V92gbbGLBos+myU93zVYM3pJQv1QrtFrSCbOVmTAgLO2eKQ1GfxbQ3KQ31XxXaBw8Y0g7JhpdyCKsJQ2xf7a+32v/QFvphM0JKG445jc3dW9GljiY0ls9fztqz1k5wrQxM+k7M4uJiDh06lFQM2gyJCGE8QEIE0Vy9CIexSSNWt0SVA9PueBi+bmMWEhxDSsmhfh9F7X9ky9PfDst2WqHC40qYM89ZvpXi+qfQ3L0IAZq7l+L6p1Kj0lnwmX2eOtY89bbyuwNyPCORZb7OUCw62Zh05HnpSJumek3U+X51GExlu1V9dIsyADqERaYoof7xSyVfqhUsc1emmJsxbVjYeUBWh/8f239VMPqXIe0wmVLDVrTVe1/6r7h+J/0VyjLqAsGwVMUGxwBPdL2BLo3Joi51ntj5BBte3TBxlYrApA/gjY2NDAwM8N5777Fjxw7bv7feeYu2XW20726P+GujY+9OOvfuYqjjg6jzB/cPcnD3wajzD+4+yOD+Qft7vb2VHXva2fFBB+992MHArjeY9cf7uZ3HE9ZHiMQ584qnPx8VMwRA86dGpbPgfz/oXxknL2riYa4P50tU5uuM4Hqr+NWxcGmuKG54OtKmqV4Tef5o5zKknpzmizIXo+5itHOZ8j4el4O9p9yh5pKf+rnUOeaq9oqBT7qp7jwl6TrlKqfmMNFUXZ9082BgfAat7L+R9sbk2pxMqWEr2upPd38nrt+NdCyDWN9Lyaru8Q3mm8unofrV2vx+ZnIe6WLS5WRdLhdz5yaX827lYyuVFDQkrD/5lyw5Of61W/X6dOG8BKGK5rNRpWCamUSYp9fnD7/+W4US7t7Wp7w2JYlT85U0hgnx2I9LLS9ZfPWXcDpOhhfvo6lvH5QIWiorlCwU899UWCjpvNKnek3k8UD/IkYgHIqaWVZvGU+PrU9wrILRzmUE+hfFndsQaq/TF10CcyrVbJPZZ6XGQlG11zFL2ffas8wUhzggq3kwsILXRhfjlEZ4zeHus10jSNTP0sLCFax+fCt3ODdF2WUuYDZ4PfS71P0XoN4fYFVPb4R0QQiTJDVs9UzpjnjVD7M/zZ3/8vh4sfudqLpYbfA1Z+QTjUnPiZkKsrLIEKZI7aW1rIwWbzntTgd1bi+rZl5A09anLRebIhdyzBi25uplekDnY75BWqeV4YsY5Ff2D7C2uxfcpeAoguEeqGjkvNoSeoPxA1RFIMgLXToll94XPRiEbJZ9+zhIDQ+MLeeN8ou5Y9mxuCreouXNFtqG2tCEhq7rSAQgjQSxoUHKIQSXi9+xxr2ZGXQhQoNOa/fbtOx6mnbN2H6+at7VxiaYCDyzdT/P/c9aPih/jU6nYEYQPjbjNF4eOTDe0WvO5NTf/ITpspMDsoYX9Y9yheNVKhkEAcJTBZd+M65e7U/dFb4mdqB45bKuuEHy9Jf24Cv9Wdjvt3d3c+6QhiYEXgbtB9MIetwBqrm96By21+wx1iGCJYBEcwxTX1bP+Y3n8/K+l6PjpoNDloO2aqIAhNqmHRHwMnxwKdO1c6LbbbCNooCH27p7qWSAB6qrGHBoSKDS6WF1n4+mzgQ/EgpKY2tZqf1Cccw1myr+hjvfP07Z701UlrjYum6p9XPoD/DC/oPhNYLW0hI2VlfSazKd9FJG2q/A43YgK38Bjh7qAwFu6+nlct8of529nM8eXJnUj5FqreVPPS/x5O7vgKOHGYEgt/f08EilV7lYLwKV9P/563HHpzU8i1bxh/H49nCQtW3j48HJc2ahKyZyUoaWS4Qxublo+i288FpD1n5Y02ahZBOZDuAZ03wiKFJKGp2u09zVHT97wHiNXB2iUpkxwKjXSCnjX62kHB/EzTqUlrC2ppqAFt8JXFKyvvMQy0Z0nJ/4l3G+cQyty7Tl1xXTKK5/Cr8ctayy1F2MtF3DZYNDbHR9lxIxLgbWWjaN5uqKGB9ImueOD+LPbN3Ppl/dxZ9r34g6L7a+xbqkuetQ2Hcqd6C54KpvJ6zXrxwfU1L4Wsu9rKuuYoxAxH0Vbaai9MXcT9X+digWLqN+/RGhgdB9WstK4/qlUzgRQkQtmJtt4XZoce3m1HV0IeIGB7NPNA35kqqX6afmmmpGpAW1z8b35g+oCi5N8NDyk3H1/RvNu59mRIts//F2kBL+u6yEu2ur8cfUx5ioOhBaMO7aywZ9/CB4EfcEPg9YUyJV9Mmiiq246mLojLrOJwYGeXZaWRxd9vKZt/HDX1fj18fHv6IZz+CqfDWu364c8LG2yyAAbKjy8oRFGCW6ng5G2q4Lv+FlSu+0GsAnPQaeCjLe4h0hvdpS6Y17eMPpwWLQTm1U5y6qVcQAVQ0qhBEzi0BLpVc5eAP4haCl0oszODIeM1TIxZaIMe50bkJU/cJ28AYQmp+i2ue507kpavAGaPFOU/hAGFKsITz0/E4OVr0RP9DF1HdEE1G+U/Zv3Z+wXne5N/PANQs4/a//Evd9S3lJ1OBt3FfRZqqYa8z9VO1vhxHpp6W8RHkfVZw1IANxbCezLVTtFtA05czO7BPJ1gsMP0UO3hAjV2DTp+zg1yUPPb+Tpq1P09x1aFyi1x+I+hEVwvBv7OBt+ICowRvG21AI+JTjpfBxq7UQ1bqJsyb+mRzRNF4uKYmWEw6NGfdc+BnKiqNn5q7KPyj77eZppWFJhrXBaaysOQ1NaOpE9+F6BimqfT5hXTLFpMfAU0VGcqYRcThLGl3cccHZIy1RbWVFnVIhNjJmdd+4701bbWhdwlWi/C4WwtUbRSFMZEskle1A7zDT6pKjeCaqG5CwXnV0GbOUZ+O/T77NFOXHfE7K1iTv016V/A9BKn1Hed8E9Yo7P/K4GQ9OkiqowoHeYSjeRxNS+aaayIZE5ztinhjVWojqmCWd0emIkBMW0DzO0+/1xS7EqkdkHRnF718b+jvpPxdY8qtVNuUiDWNezcCt8MzW/Sz8hwc48TvncdJ/LmDB987n3pf+K/qkbZvQhaC1tISljTMtfzzj6HUVjVG0rHud32dmIECyiHWwFX0v7nuTzmVD67Ki0cViZiCg7GiWVMJgEL3Zy751R3Gv8z+o0JNboIksz/TzwjmzWNo4k9bS0I+Np9KQk53dGP8d2Nbb0l7V8djrQ58Ttb8drO6TigyA9HuRwdRoflH3jajXM1v3006N/fkRKHfVcu7Gl9inVyu/j6QKqnCltoX/LV4VRyRQtbUVHdIKps3BmCdGRYmMPeYs34rVVpXyiL0h7dRE0VMrPLF0YnUZmhi3KVIKWSQYPmOfz1ykucv7AfyZrfv5+i//A7168zgv1dnD5g/+eXwQ37aJwLO38ouSYpprqoxFDdW7kpSc74uJpS5ZF6Zr3ev8Pp91/FpJwUO1liAly/sHog4prw3BpF8FHMVhStrrR93KsIzWeDFpXSoanVWZqup+ubs/nkqo66zq7kVD0qh1UVX+Cv1JhBqcugxTx8z4cpvLiRSCNpeT5poqWktLaHUGaN5yN20OEfddFBVPQbtb1e+LTxUXS1kDNaVvybpQbNim/W1gdx81RVFD6o6YYy4Cg8chtOhQFoDQdTRFH3LJcb+iucL1MuPA948txxfTP1R+cokiuvcuYX/vMA8GVsRdE0sVjMWV2ha+6foudXRGDXNWbe0cnBNXf8MHxB03fSsl/Cg4zhBzOYSSEhlJnwyvRwn1D4bPodFaWkJAatw/tjy8x+CZrfsZGoueiAWH5ikf4zNmnGHUNYZTjtCV5xv1dERRVHOV5i7vQiixeOj5ncr4l9D8/HT3d7iHz8CL9+EMjtBSOdM+7ikEL5dNg+6+qFV/U+j88mdfQkD41bGl0mswWAJBFvt8cSyUFeEFTIMVQsy1bU4HGkaYpT4Q5LaeXi7QK3B+YpyFcvu7x3Cq/2buVNG6+mEEKJnxAtLZY7BQpDEQmGWqKF0SOEgtL/YuZ25wH4dq36TTKahTnP9IlVcZm41FmauEU4dG0OUw/1QZvzgYGauOi89qGi3V1TSdFsGyUNDumpasgzC7oo26oGTVoR6a9GLwFIdZPkq2xsIVtLzzCCP+eAqccsEVkFKgoSv9gnCEFxTNgN6a//kmuqMnzP4BwkwlEaxk5OBSQ/RJi58hl0vB6s5DbKyupC+0Ic2r66w+1DN+36Jp4XqZceDnWAx+wv2jQ9TQdNH9EX4yWCg9+y7C13MigNF3zGu0Q2gVjfy84m94LoaFcsz0UnxjOgd6h7nLvRkP8T88VmtJbdMGGG27juK6n4NjyPgiWMKoBQtl2eBI1AImQKnbqVz0i6RP9lbbc9LNNYSzBvqNeuvjsWh/MHr01dyHlP3ggwFDQVW11iEEIAUyxP2KYqEcbOAAWRQZUyCvWCgqzF3dSulxq60m1LzzubeNLb1IFs6ZhUwwGNnKmjard2pJCXNHf6z8bs/GpvD9VXej2T4mOnd1a8LXfQHR6d4s7zd+xdyRH8Wdsavok8SurybjM6NEwcCOB5BAmUV7iFBfU5U3EXKyVlK21gM4bNv9YZxPDMS3nVVbRbaPrZzu7g9J1G7mPZO5V6q22cKiT1n1j1TaMxPbrPwZVY6UvLV7H/NGfxQuF+JrY9lvQ3WZTCnkw4KFosJMr8cyFqwFQ/LkobhhovgzJNhCbrGFOjZuZ8Jh9gaLOHZsTE6FZOJmceck2rYdE9c3EbnV3kQyPgPDb2aZllvcA8GEW/gTYtsmQ5ei2Wv8m8IWbet7qH+gpN+r9Amg9PGNZa+xxX0bu4o+yRb3bVypbQGi28c2XV0S7WYi1W30GW+7t7Atla3/pubN3NWtnLvxpXDfz8S2ZPpNXSAYFd83JS1ikUiaoc6lTrOYrVSD6SDvB/A7lh1LoCs+Fix1F9fO/YLxYck6Ao5i2/gzJJE27NTPKQ+/Xv0J5fEbzpwVvn9sPNcn3VExOSuotktHQhlbs9u2HRPXj8TDXM+YiN5GfVt3L64Eb2mm38wylVvcQ3FOZRw72XRtJn85pEuRqs7GqlNW4SA69it1F/6eM+OOu0QRsvtSZbxYGWPftom18t9o1LrQBDRqXWx0fZfr3L+Pah/bdHVJtJuJVLfRZ7zt3qIPJ7v1307zJhPbEkk+FOs6X+weDMf3IyUtYu9pK82wbROr2vfGrxkJV3J9N0dwNDc3T9jNHn300eZbbrklq2UeV1/OrLKj+M32ALprL2gjiGAly+d8mXsu/Ixx0owT0So/QuOf/5fZw3287S5mSBN4HNMoc5cwGhylvrQ+cYKC+ctgsBPatgHSmJGf9nlmfeb/0TU4yvb9/UiMmfenzprNhqsWhO+PdzbtO16lRA6zX9Zwb+AzPKcvJqBL3t7fx02L1XICx9WX01jp4e39fQyOBPB6XHjcDkb9Og1eD+uuOCE+tha6HwfegtH+0JuDNLisl2yEhSviym3werjh8ks58YQF+Pa8gSMwxH69hg+CZ/Mx0c5bLslI6I3Co0vKgFEhovxmlvmnXSX0D5ThKjkA2gj1QWnEcp3VzL/oGzQcvYzth7Yz5B9Kzu8mfrwSfDFUNz1g1PPsLyW8fH7lfGaVN/LK3rfwSx/S78V/8ApWzL+RG884JcqmNWeu5oLGS3hyXwU7hr0scuyhlGFEhA9jbdOGo9WUXSLI4pK9LLjurigbGsoa1PVPot1MqNpP2RfSPD8OEbbpIwPhPvzSyGXo/kocxfsR2gj1Zer2vOmxN+j2RcfQzb7/0PKT07Yt1p8V7go8aIzqfuoDQb46KNk2/Gk2jZ4dVa7pj1+9ezAcFNFH663r8uOVzO/voCEQYLvbzZAmqA8EWe2TNC17ODkfZoB77723rbm5+dHY43kfA88nZByHPNKRwVpCzjGVbcsy0unHU7XvJ23XJLdvRinVCsgOauq24yv9WVgD3NQpyQU/NGOkkzIs16hotEhikZxUa05hYVs7NZy9ujWnTIRMkWpatplej1pv3qYfp3NNxkiiDydt1xTte3kfA88XtO5qJVi1KU4DvKTyTznhh2aEDGPNOYOFhK6tjOtEQWHbcGidI1lt9MlAOhru6cSscyJ9a4ck+3DSdk3RvlcYwCcILW+2xOlfCM1P1awXp96sTKGVMZmazmEsXGFwr0O6FFTMss9DOZGIsa2d2qg8kpA7PYxMkI6G+1WLGnjgmgU0eD0IDOXIREJN6VyTEZLsw0nbNUX7XiEGPkGYTA5pyjiC4rm5wlSN+cYiX+xMGYdZHy7EwCcZdaV1Sg3lyeSQWmKKxvvyCbmO+aYat7bCRMWms2Vv0jhC+nAhhDJBsOX/TjVM0XhfPiGXMd904taTYaeJbNqbNI6QPlwYwCcIGWuZTySmaLwvn5DLmG86cevJsNNENu1NGkdIHy7EwAsoIM+Qb3HrfLN3KuKIjIGP5yk0leu6aXJWwTFL4c8vTC2OswVSjh1mg789FTngMZjwmOoE2KLKq6l6Q5sUTnUGSMfeZH1xpOOwDaFEa/dCm0PQXFNJa+AQvPG9qcdxViDl2GE2+NtTlQMegUmJqebYllit6bahNpp/30zrrta4cyecU50hUrU3FV8c6ThsB3CVdq9VzsspwXFWIOXYYTb421OVAx6BSYmp5tgWZX+NzGMZgQnnVGeIVO1NxRdHOg7bEEo4/1/scatcfRZ5AicTVjn0LHPrWdUhlbplo4wcI2W/5BDZssWyv1ocv2pRw5QdsFVIxd5UfXEk47CdgVvqLlvpW08AP9RKD9kKKeskW9Uhlbplo4wcI2Nt6ywiW7bY6oQfYSj4InkctgO4knetymsIE8IPnRDNiWxwX/OAPzuVYsDZsiWv9gnkGAVfJI/DNoRirljH5U90VsNpN0w4C8UuVmr1ahmZ+y8phoMij2TKdctGGTlGyn7JA1ui++uRzbwo+CJ5FHjgE4QCF7aAAgpIF2nzwIUQ3wcuBzqklCeFjlUBTwBzgD3ACillTzYNtkUMT/n1o27l9nePiZ8BbdtE6+/uo6UoaGSPD0pWdffQ5KyiddHVtHT9IfEvfJY40VZcWE0Ijrl/g5Gt3NlLhbscIQR9o32JZx4Rtvk8dTzoX8ljg2fwD54fcDUvoEndyOpy6ufg8n9Kry5Zqv8zW/ez5elvczuPM1N0cUDWcGfZYj5s3EefvwNNaOhSp7603qjz4BAb/vc+NheBjhHrWz4Ka8827m9yr/f3DuMQgqCUNJht73glut3dXladtQaIn9UB3Pe/9+ELhDK/S8nK/gHW9gyADBo7+JKs8zNb9/ON3/4IX+nP0Fy9VLins2bmOVzwh80UD7dzQK/mu+5P89GmW3BVvJX0DNOSE23XNqHvZN8+DlLDA2PLeaP8YvXbQaI23rYJ3y/WxdXhKscrCa+z+z4bXO+EHPwk+69ZTof+ezwzXgBHD3WBALf19NI05OMfPcfwwxqdoMPIKuSVsHru1TR9fH1K9mYbCWfgQojzgUHgBxED+INAt5RyoxBiNVAppfx6optlZQZu8pQjqG7D0h0l3elxOfjB6R/Q8Zf7aa4sY0QbD/UX6zqfGBjk2WnTGIlIN17sKI7f2q64Fy5PWltyzRh4bBjFWb6V4vqnEJpfeZ3SLgvbfNLNG/oxnKdtj8+uPfdjsO+11OqSpfo/s3U/v9n8Le53fZcSYTwAraUlNNdURbVNuM7CxUd9g7xa7I5OFy8lKweHWTb7Tj77+kfifAlwnfv3nF/xX6yvmhZVthMNoTnw6+N+dgonutTRicmTag7i3b1J1/mZrfu564XH0KY/GdWWxbpOc1c3TUPGD4RPurm59DLeq9seJS9s1c4mJzqSVtndmWQAACAASURBVFfsKKa58RKaXvmOum1A2TdW+2/mV46PRVP4ErXxtk0Enr0VZ8T9fdLN0/JjrHT9Lup47HV25VrWKwV5CdUz5XE5xuuXZP81y/F73oh7Fs3x4qfTygjE9FWXlKyfMzGDuNUMPKkQihBiDvDziAF8J/BxKWWbEKIe+I2UMuGqTVYG8H8+Sakytk+vYfHYI+HPrxav4rONLtpc8S8ZmpTocSMc1JfW88J1LyS8FxWz4KvvpGx65GxBC80aS4/aiOa2l7eMs8vGNimJH7ztYFeXLNX/3I0v8YTvCzRqXeFjSxtnKtsmDIuKaFLy/J4RzhpRc4K3uG/j87Pd9mUnAU1K/rQnou4J6nzuxpforb5H2Zb1/gAv7DsQ/ryksZEOV/wPl6qdlz65VKliWR+UvPChRduA7TPS4PXwyuoLjYOJ2tji+4DUcApFgvAE15nfW9ZL1dctcO7Gl5RvteH6Jdl/zXKsnkWr8QJC7fD51MeCVJHtrfQzpJRtAKFBfLrNjW8BbgGYPXt2mreLgAUfeaaITnY7XXbS7pylPNcqL30czzTLnOhILuzc1cauMuFKrE2s5L9mi5dtV06W6n+gd5iZRV1Rxyz5+AmgA9Nll+X3M0WXZbunep8oJKjzgd5hSuvUbRlb106nejBQtbMlJ9qKP2Zjp/mMRHHUE7WxxfcOq6cowXXm8WxwvRNy8JPsv+b5Vs+i1XgBNu0wQcj57aWUj0opT5NSnlZbW5t5gRZ85AOyOupzh6i15HxbVTqOZ2pxL58ncz6qyROWfsXO0ER2QfZ42XblZIkTPtPr4YCsiTpmycdPAA3oEDWW3x+QNWmXHXufKNjU+Zmt+9GEsGzLWHtqA+q3XlU7W3KirUaVisaEz0gURz1RG1t8H7R6imKuay0tYWnjTBbOmcXSxpm01hrHM+V6mz5XIVy/JPtvomfRbpC0bIcJQroD+MFQ6ITQvx3ZMykBLHIPPhgYj2l5XA72nnIHq/p9FOvRHi7WdZb3D1CsRz9ESp7pknUEYvioPulm3dC1GetumPzh0c5lSN1leZ4l/1XhB5908zv9RJRRsbkfS53fnSVO+B3LjuUfAivwSXf42Kqe3ri2MVGMxlkjY8RVREqWDw6z95Q74rjXJh7mer7SNxRXthMNlxbtZ6dwIlAMAlJyxnBM3NSizmb8NCilsi1j9x74pJsZ3afhEkXR51m0syUnet7V1m1j0TceDKyI56gnaOPXj7o1qt3Msn6iL4l7NqL8tGQdreVemmuqaHM5kULQ5nLSPM1N667WjLjekT6PRVT9kuy/ds+iOV44FX3VJaXRDpOIdAfw54AbQ/+/EXg2O+YkAYXO7zunbuCP5RdH6SycfuXf0nTRQzT7BPX+AEJK6gM6zV09rA1Oo3nu1Ym1uReuYIP4Ivv0GnQp2KfXsNp/M0+OnZOx7oapDzFDO4fRtmsQgUpAUOGuwFvkTawZHuMHn6eeB11f4kb/3/OUdgm6CDWtcMBpN8GNz6Wuj5wlTeWrFjXw8eVfYZ28JezLkwdK+LtOH/X+AEiJJiVISb0/QPNgkO+cs4GVo4SPa1KychTWnv8Ap1/5t2FtDQBHaCbW4PWw+OovceXF/xDd7q4KNpx3P+vPXR/V5hsWb6DcXR5vsBB84A4NWgnqHMnvD/QvYqTtGvQxL1JChWs6zXOv4QK9Ah2j/zzo+hIrLr6f9YvvTUob3lJH/uPrrdsmot1kKD/nGv/N/LH84ngNkgRtfPu7x7Daf3PcM/CPzltwfuJfrPvGwhW01M2KW6QekX5a3mzJSB9ftacCjH4QVb8k+6/qWRTSWLu4p6ubv+/u5VMdHhwBlzGpkBKvPnELmHZIhoXyE+DjQA1wELgHeAbYBMwGPgSWSym7E90sH3ngBf52DjEF8hZmmqv0cO8fmdQvV3lgD3efq5D2IqaU8gaLr5ZkbFWWsPaZt/nJH/YSlBKHENxw5iw2XLUgK2Uno2WcqR60UrdcD71iD/fQWtvIQ+XlHAoOoPu9lAxdwd9/7FM51ZxWIk1OuKV/0sxbmHQdkrA3Ya7SBGXkmzZ3qsikfrnKA5sPPp8ovXpHc3Nz1gu1wqOPPtp8yy23ZLXMtc+8zQ9f/TD8iyyBbfv66Boc5cLjZmRcfnWpm9++30kgImbucTlYd8UJHFdfHo7HdfsMfvPASIDfvt9JY6WH4+oVr+cxMPmwvaPGjHNQE2zxFNMwPMB8X7/Bl67wMIAfBAjHCP6iHfx6m5+G0nlJ3cPyXv5BtuzfQkNZA/Mr59tfbHJqfSG2z2g//OXX4J0NM060vMzWP0fNM8rQA+MXuDxwyUbLMpOuQ5L2VhVXsWX/FgJy3IZiRzGrz1jN/L1vJSwjUf/Id2RSP1vfJupvObJpIpDpmKDCvffe29bc3Pxo7PG8F7P6yR8UMzib46kikZZxpnrQiXTLWyq9cXFEofkRVb/IqeZ0HNLUCbf1Txox9qTrkKS9trHYJMrIN23uVJFJ/XKVB3aq+3wi9erzXsxKtRJtdzwd2GkZZ6oHnUi33IovLVy9OdecjkKanPCE/jEX3ZJE0nVIwd6meU3qQSXJMvJNmztVZFI/S99miKns84nUq8/7GbjDggtqdTzbyFQPOpFuuRWnWfq9E6s5nSYnPNva3UnX4QjRRi9gYpGMpv9E6tXn/QB+w5nqXXdWx7ONTPWgE+mWq/jSUnchuy+dWM3pNDnh2dbuTroOR4g2egETh2Q1/SdSrz7vQygm2yRXLJREyFQP2lK3XC8GTzFNQz1QIniofFo0C2Vp6iyUjHSW09QJz7Z2d9J1OEK00QuYOCSr6T+RevX5rweeJbnTAgooYOrBVjZ4gmPgk8k/z7aY1dRArFxk317jMxQG8QIKyHPEysWaxAQzdAFM6CA+Ffnn+R0DT5PaVkABBUx9WG2Zh9zR8uwwlXKxmsjvGXiW5V4LKKCAqYNEtLtc0PLsMJVysZrIrxh4ON69l9ayMlq85UbKrECQVaHUR62lJbRUV9Pu0KgrreP8xvN5ed/LtA21jaftclUY53eG4ubHLLVNcqzcFhubTipUhuzbxwFZzTf9K2iV57F40Qe0aU/bLrhFlu8tcSElDLleo3L6c4w4fdQFgtzYozP/2K9x+pV/C0Drb+6mZdfTtGlGDE6GaJMV7grWnLlm/B4hn7UGummprqLdIagrrY/wSzsi4GX44FKma+dwx7JjI9J9mYuqh2jyjdJaUhTy7XgZz+95PrwrEsBb5GV13cdp2vq04RtPpfHFcA9UNNK66GoeOPB7+sY6omQB3hn9Dzbv3IQudTTgKp+O6F7OY4NncGPZa9zpeoKS4fb01zmSTcP386/BH//TSKcWSkfXesISNr620ainNHb7CjBSpp31tbj23PDqBja/v9moi9A4rfIy3tt+cVT79g378c76GcGy/0VinLd8/nLWlsyPslOV+g+MRdy2oXYIetDxo2nGTl1vkZfVZ6yOzywVSq/WRjW3F53DrtqdjEX0rdd6ruGN8os5et5Otg78BN3Rgyfg4dbuXj7t62DEU0fJpfdZpkQrd9Uy2rGMrvYTo+o40+th6Rn7eaX7v9TPgKJ/FgsXI/pYRLxZoPu9jHYuI9C/iCu1LZzm/Sk/rHJEpcxrmtfEvS/9F0/u/g7S0YMMlgAS4RhGJiFBYdYnaqwwU/xF+DM2dZ5Hq8E/cCxj7u1orl6k8UQi/V4cfZdx35LPZjzIZ5SRJ1vIaACPiHer0nFZpUqzQmyqqyhEpF1SpW26zv17Nrq+G51OKgY+6eZzxZfwbt326BRNMWmjVOU7y7dSWv8kujZ+rFjXuauzn8bj1tJRvo/m3U9b1tMpnGxYvIGmwSH42W20uoVl+jITUncx0nYNbodGcf1T0em+wr4tsy3DhEtK1nceivOt0W7VUXZL3YUc/gha6V9iDJJc0+9jXsciljteDqdiM26QYlq3JNPw/Xze0xz1weNxNt89vRa/cvkKXKKI9YvvDbfnhlc38MTOJ2Krgr/nLEYPXhU+VjTjGVyVr8YlHVo54GNtV1f43rH+cmkupJRR29PjbNJcrD93/XjezIi6Wz07azr7eTz48fj+GvGcBBzFhgKhRUo0sw8F+heFj6lSBoafgRT6p1n+Ce0ncr3jNzxQWx5dB+FiYeUy/tD1vGV6Qqm70Duu4/6lN8YNqKr6xNk7r8kydZ5VJiypu/C3X8M3L/mbjAbx/B/AI9IjWaXjskt9pEJsqqsohNIuqdI2bXHfFpUezArJpM5SlW+V2qneH+AH+/x8dnYxbQ77etaX1vPC3gPQtzdx+rIQ9DFj+36qaaWU91f41soOq86vSckfd++3T92VDJJMw/eX4k/jjMm/kozvItvz5B+cjC7j7ZVSMPjeA+HPZcetQYj4Zy8ylVuy7WZrU0zdrcqs9wcIoqn7a2RbJkiJpo95Gfrr6vBny76cRv8EmO7XcaCrz5caqPpKjH3eQ/eOp5QLwao+UfZe94Jt6rxU75kK8p+FEhHXttpensoAY1dO5P1UcbaZIvHgDcmlzlKVb5Xaqd3pYLpso11LvBOwfah9PH1VkunL7NK7pZp4RHXPVNOo6SSRuisZJJmGzyF1YvM7JGNzZHuqBm8DsYO1euIUeXW6aeeibIqpu1WZdveK+i5BSrTYPmTZl9Pon2A+U+rzJboqPUecPapnLpGchPm9Xeq8VO+ZDeTPAB4hPVoXCKpn4KG4VbKQwJkfacQXGvg1YHk4G7mk9aF65h1dRYdTC8fgAM6b0Uh/aAZcIiUuXdLv0KJi8XZ2Rm77jqQmGa/Vf7C0tzyo0y6qqQ1IOlz2XVUIwYI5jWhYDRUKf4RSSgnVDJzUBvFICYDW0hJaKr1J22HCiCTGjanh8tr/8yTD56MOODE6VmzG+NuH2qmb1cCq7vhwWWwaviBaeAaeis11rnGFOes+GFsLs3bxR9P1VySCYxWc/vCDVMxqpMNBuG9a9slAMDQDj+9XElgwZxYuKSlF0PfYQoQQWL29lx61MRyvln6vsj+Vu2rBMwDD3ZY2qVAbkJYzcJFULxWUHbeaBd/7JsMHlwLgmfECOO29XR4Mwjfn8tfiHi4ONCjfVKyQjuxFssgfGuGSdeAwsqSc7/Mp023NdVWlVqYQ+DTNeH8XAl0IniifxoYqbzhW2OEyVgk1dy/F9Zvx1D9Bv3P8Gp+m0ed0jKeMqqmitbQEUG+DLxauqG3fJjVpPCYqLbPKDzo0vlZ8Lqd1zbRMR2ZCl3q4TurgXExKOV3nxK45yO5L49N9hdPQJTeEu6QMSwGYfmxzOZV2SN1F1XB1fHtiDGb/HfKlicjyTJ/fXQprdz9N21AbEknbUBtP7Hxi/LNTi2oXgDHpiErDB/Cj4IVImdjmWN+sat9rxJqB5fOXx9dRgr/nzKhj/p4zlb+sEri7ttrGXw6kbv/YunRJ41A5wxWPc9Apovrm+T51msEvdg9S3XmKOr1fqA/5NY1eTSCRlhMlEX5WnsJZvlWZpkzqLho/bCA40g8Yz4kqZVl83V1Ud57CF7sHlc/VGdWX2aYnNOyTRsdy9lBc/yTF9ZvB2ZPw3oOaoFUbQUPytZ7u+GfB4sesWNdZcGhuzqiG+TOAL1wB7jIAXi4pie/cQrB7tDPz+wjB5vJpFjKuekKPRUrBNg35aO7qHk/t5Q/QPDAWtaJtSmO6K19LNFYQFIK3q3dzq29XuFykRITSPCGlOsejRT210LX1/gDNXd08Mvq/3L/0xnC6L6QRc1zX2c3qQ/3c09nNdL8O0ogJrjx2Jd6i6ESw3iKvkWrKWQ0IWqrUi1NSGrFBT9/1/LK/HY/iAdCF4JGq6PJV7eIXgkCChevIdgGQ7mm0yvOizrkn8Hl+ELxIeY8owyPTv3V109TfG957sPastaw8diVaKKWdJjTOrL6cmtEbEEBliQuvx8XYwasoVj30QuBXDdwhf420XcdI2/Jw2rZpAR2Pro+n+goGWd91iEDZnrjFvBFN4+WSEpq7upnhD4bb/vauAL/t/TR/7L8hKiVcJhCan6La55EDp0SVadThGv7B9wqO0EJs05CPMrsbRlz3Wt/1/Kb309za6Y9Kmde8eD3fu+IBln/kqxCoDLkjwVuqFjSe6SQQFML2uV7ZP6BOD9jVzffFazmjGubPIiaEU3AtnDMrTJuLgtVqWKqQMoqalyqElGzbY6VHrk4XtuCx5LRbpIRtuz9EPV4JFs6drUxjlZyd0bZlY+uwVVotKWHovY1GOc1eFs5pVPo71kbLtk8C0WUJ5o78SFm/suNWK7uRQLBt94dkKw3cwv88Kem6SAmD722MO76r6JPKvmDlp3EfxNsb2d5WPkgFAsHAjgeU3oq1265drepu3MO6L1r1vXRh/1zbXplxikCrRcz8mYFDWMbTSmI1W5XRbO6RDGyvtZAiNWdsiSD9Xg7IGsuyU0lXFWdnjG3ZkMW0sicqLljRaOmz2ONZa5eKRst6aMFK9fWldVmVmK1LYVHBXJ+IhVVfqA2oB66wDxT2Rvsj84lQXWmdpY9j7bZrV6u6g31fzDR1W1x56fa9HMoP59cAHoqDK2PLus7ymtPipEZj4RROXJpNnExKlvcPWMi4agnXSIp1nS93D6i/tJEiVcVOY+EQTmT3pTwYWIFPupVlq+RWVXDq43FqK9uysXV41Smr4mLqcXK4S9axql8dm72tJ3rmomoXl5Q4dfuZVqREr1lXq/pdO/cL1pK1WZSYXTXvaopj7HbqOq6Yt2Kpu8IL6LF4mOsZi/GvT7qV8WzTBwFHsdLeSH/4e85MGEZxaS6cQr34aPrrjmXH4lK8IvyjvtKwIwQjDq54U9MdlnVP1BcTPQuq9QSncKIphsXIdR2AgBRq/4gYhkyO5YfzKyfmjBOhcg7z//wbGoYH2O52M6QJ6oOS1fOu4ealj9BQ1sD2Q9sZ8g9RX1pP07wmuke6w5/vOvMuLpx9YficEmcJft2IFWpSsiLEQpkfCNLg9/NOkYdBYewE8x+8Ev/gSZSUvo8ujF/jEgklumRMQL0Oy6ctY3fHWRwd+AtlwocUGgJp8Gcv2Wi5+eT8xvPpHulmR/cO47VPCnQZuja0w+6es9dxQeMlPLmvgh3DXhY59lDKMCKi7PmV88M+GPQPogkNSXRsvMJdwT2zLqWp4wMYHbC07bj6chorPby9v4/BkQANXg/rrjghpXje/Mr5NE5r4PW2bYwGh4zdlwPXcu+Sz4yXM+NE5pc20PDXl9kugkabBoKsHtG4/Oir8PW04wgM0SPLmDUmmOcf5p2iInyh89YMa1w4/2q2B/rU7e6qYPXAKE293VF1tarfF89ZHNePwrsbZ5xo5MQ88Jat75LyzZwLaehrY3v3DoYE1AeD3HWohwt9w2wvKmZQE4hAJSPtl1PmPwOP28GIX8chBBIjldgNl1/KiScswLfnDRyBIfbrNawPfpYXhy+jwjUDV8kBAtLH9IDO17t7uFCvoOjyh5T2Rvqj99DRlHqGke5xGqJLuCgvKmc0OEp9aT1rzlwTfpYi+1qkv46rL2d2VQmv7jrESMD44a0scXHjVU2ccPxJYT/OL6lj1vFX88rAfgKhXZhCL2W2/DQd7fH5UZPpi5HPwpB/CIIl6LoLhB/p9zJ68EoCgyfiKN6PcIyGx4clH1nC6+2vMxocNdYVdJ11/WM0+TVkYISD1HK3/0Z8rmqOE7tCz6gDTvs8nPXFrPSNWFjlxMyvGHgBBRRQQJqYTDnYTHF4xMALKKCAAtJEZLz8Sm0LW9y3savok/zOfRvNG+5Rpkeb6igM4AUUUMARATPGf6W2hY2u79KodaEJaNS6uNP/bbY8/e28G8TzZydmAQUUUEAGMOPlZz37FUoYi/quRIxxu3yclc8vmbLZ7lUozMALKKCAIwZXLWqgDrWW0UxxaMI1xjPFYTsDj9QqNjWI/X0fTSzGPsVybCq1yCdwhqDyo0prOlZvPFGyZFW5oEhWPDg0ZdrDzhe5bKfWXa088Oo/xWmoT4WZ4uvP/Tuz3nyI6bKTDlHLy7P/Dy0di6ZMwgMVfJ46SobjlQcPyOpJTY+WDg5LFopK29clihhpuwZfz8nhYx6XgweuWTDewRS60SlrT2cRKq3wOJtzCJUfo/TMQ/5S6TnH6p4nKtcpnAghwpROMPQtmrsOGVvVTUxSe9j5wt/30Zy1U+uuVu7eck+UPrudrvVE4vXn/p2T/rgWT4RWu0+6WR2jsz5R/TUZPLN1P1ue/jb3iUejNOZ90s06eQuLr/7SlLE1EkcUC6XlzZY4YXa/HEVU/SLqWFxevSmWY1OVE3AicwGq/DgSHKHlzRbjQ8hfKu2QqPOSKDcgA1GDN8CI9NNSHi1mNVntYeeLXLZTy5stUYM3GDojouoXE54TMhaz3nwoavAGI5Z8p3NT+PNk5K60w0PP7+TJsXNY7b+ZfXoNuhTs02u4K/CFKTt42+GwDKEkq1UMMXrcUyzHplU8bqLidFZ+jNWattSYTnR9Mjaoyp6E9rCry0AO28muL092vHa67FTuuI/VWZ9sOyNh2vKcvpjnxhaHjwvg4TwbvCHDGbgQ4hIhxE4hxF+EEKsTXzExsNPfiEVUzCuLOhfZQDa0SDKBlR/DxxNo0yS8PhkbVGVPQnvY1SWX7ZSUlswkoUPUKo/H6qynamfrrlaWPrmUhY8tZOmTS2nd1Zq2jbGwsqWmbnvO7plLpD2ACyEcwL8ClwInADcIIU7IlmGZQKWB4BJFyO5Lo47FaSlkUeciG8iGFkkmUPkxrAkCYX8ptWkiz0uiXJVGTbFwsao/JmfpJLWHnS9y2U5JaclMEvaecgfDMZo8PumO0llP1Q/mWkOktnvz75uzNqCq2qqk8k8Eqzbl7J65RCYhlDOAv0gpdwEIIR4HPgG8mw3DMoG5cJYyC8VcGJsirAfTtslioVj5MbwwGfJL04v3QVfyLBSrcpX3miIslIS+IDftZJYfx0JZOvkslNOv/FtehxALpYsOUcPLH/k//LFjESJNP9itNdixmpKF6pkSs16kzx+9zpDNe+YSabNQhBDXAZdIKW8Off4McKaU8isx590C3AIwe/bsUz/44IPMLC6ggAIOW1hpeAsE227cdtjcM1XkgoWiEgyO84KU8lEp5WlSytNqa9UxswIKKKAAyM66ST7cM1vIZADfB8yK+NwIHMjMnAIKKOBIRsJ1l8PkntlCJjHw14FjhBBzgf3A9cAns2JVAQUUcEQimbWGw+Ge2UJGOzGFEJcBDwMO4PtSym/YnV/QAy+ggAIKSB1WMfCMNvJIKf8b+O9MyiiggAIKKCA9HJZb6QsooIACjgQUBvACCiiggDxFYQAvoIACCshTFAbwAgoooIA8RWEAL6CAAgrIUxQG8AIKKKCAPEVhAC+ggAIKyFNMaEo1IUQnkA01qxqwyEw69ZBPtkJ+2VuwNTco2Jo7pGvvR6SUcWJSEzqAZwtCiDdUu5KmIvLJVsgvewu25gYFW3OHbNtbCKEUUEABBeQpCgN4AQUUUECeIl8H8Ecn24AUkE+2Qn7ZW7A1NyjYmjtk1d68jIEXUEABBRSQvzPwAgoooIAjHoUBvIACCiggT5F3A7gQ4hIhxE4hxF+EEKungD2zhBD/I4TYIYTYLoRYFTreLITYL4R4K/R3WcQ1a0L27xRCLJtge/cIId4O2fRG6FiVEOJXQog/h/6tDB0XQohHQrZuE0KcMoF2Hhvhu7eEEP1CiNunkl+FEN///+2dW2gdVRSGv5/WFtTWpt4I8ZJE6kOebCwS0fZFiU3RxgtIRGhQQQR9EBEsBMTXKvqkWBDFVqotosW8FFt80BdbpbGxkdbmYsHSmEArWlDU6vJhr2kn4eTIxHPmAvuDYfZZmXP4978na/asfQ4jaVbSWCqW2UtJg378uKTBHLW+Ium469kraZXH2yX9nvJ4e+o9t/r5M+H9qfVs3GZozTzueeSKBbTuSek8KemIxxvvq5lVZiM8+WcS6ASWAaNAV8GaWoFub68ATgBdwEvA8zWO73Ldy4EO78+SHPWeBK6aF3sZ2OrtrcA2b28C9hEeYN0DHCpw3H8CbiyTr8AGoBsYW6yXwGpgyvct3m7JSWsvsNTb21Ja29PHzfucr4DbvR/7gL6ctGYa97xyRS2t8/7+KvBis3yt2gz8NmDCzKbM7E9gN9BfpCAzmzazEW+fA44BbXXe0g/sNrM/zOwHYILQryLpB3Z4ewdwfyq+0wIHgVWSWgvQdxcwaWb1fsWbu69m9gVwtoaOLF7eAxwws7Nm9jNwANiYh1Yz229m5/3lQcKDyRfE9a40sy8tZJ2dXOxfU7XWYaFxzyVX1NPqs+iHgQ/qfcb/8bVqCbwN+DH1+hT1k2WuSGoH1gKHPPSM356+k9xKU3wfDNgv6bCkJz12rZlNQ7ggAdd4vGitCQPM/Scoo68JWb0si+7HCTO/hA5J30j6XNJ6j7UR9CXkrTXLuJfB1/XAjJmNp2IN9bVqCbxWXagU34OUdDnwEfCsmf0KvAncBNwCTBNupaD4PtxhZt1AH/C0pA11ji1aK5KWAZuBDz1UVl//i4X0Fa5b0hBwHtjloWngBjNbCzwHvC9pJcVqzTruhfsKPMLciUfDfa1aAj8FXJ96fR1wuiAtF5B0CSF57zKzjwHMbMbM/jazf4C3uHg7X2gfzOy072eBva5rJimN+H62DFqdPmDEzGagvL6myOplobp90fRe4FG/fcfLEWe8fZhQS77ZtabLLLlpXcS4F+3rUuBBYE8Sa4avVUvgXwNrJHX4zGwAGC5SkNe53gaOmdlrqXi6VvwAkKxSDwMDkpZL6gDWEBYw8tB6maQVSZuwiDXmmpJvPwwCn6S0bvFvUPQAvyTlgRyZM4spo6/zyOrlp0CvpBYvC/R6rOlI2gi8AGw2s99S8aslLfF2J8HLKdd7TlKPfua9bwAAAPNJREFUn/dbUv1rttas4150rrgbOG5mF0ojTfG10auyzd4Iq/knCFevoRLouZNwu/MtcMS3TcB7wFGPDwOtqfcMuf7vacIqfh2tnYTV+FHgu8Q/4ErgM2Dc96s9LuAN13oUWJezt5cCZ4ArUrHS+Eq4sEwDfxFmUU8sxktC/XnCt8dy1DpBqBMn5+12P/YhPz9GgRHgvtTnrCMkz0ngdfzX3DlozTzueeSKWlo9/i7w1LxjG+5r/Cl9JBKJVJSqlVAikUgk4sQEHolEIhUlJvBIJBKpKDGBRyKRSEWJCTwSiUQqSkzgkUgkUlFiAo9EIpGK8i92UOwaUNIwQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "data = normalized_df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "for i in range(5):\n",
    "    print(X[i], y[i])\n",
    "\n",
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: article_id, \n",
      "Feature 1: make_name, \n",
      "Feature 2: price, \n",
      "Feature 3: first_zip_digit, \n",
      "Feature 4: first_registration_year, \n",
      "Feature 5: created_date, \n",
      "Feature 6: deleted_date, \n",
      "Feature 7: search_views, \n",
      "Feature 8: detail_views, \n",
      "Feature 9: calculated_stock_days, \n",
      "Feature 10: calculated_ctr\n",
      "\n",
      "Feature: 0, Score: 0.09580\n",
      "Feature: 1, Score: 0.07221\n",
      "Feature: 2, Score: 0.09224\n",
      "Feature: 3, Score: 0.07955\n",
      "Feature: 4, Score: 0.08638\n",
      "Feature: 5, Score: 0.05690\n",
      "Feature: 6, Score: 0.10657\n",
      "Feature: 7, Score: 0.09499\n",
      "Feature: 8, Score: 0.09991\n",
      "Feature: 9, Score: 0.08739\n",
      "Feature: 10, Score: 0.12807\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "print(\"Feature 0: article_id, \\nFeature 1: make_name, \\nFeature 2: price, \\nFeature 3: first_zip_digit, \\nFeature 4: first_registration_year, \\nFeature 5: created_date, \\nFeature 6: deleted_date, \\nFeature 7: search_views, \\nFeature 8: detail_views, \\nFeature 9: calculated_stock_days, \\nFeature 10: calculated_ctr\\n\")\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that even with a Balanced Dataset, search_views, detail_views & calculated_stock_days are important to predict 'product tier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and output shape:\n",
      " (1209, 11) (519, 11) (1209,) (519,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Mapping_Tier = {\"Basic\":0, \"Plus\":1, \"Premium\":2}\n",
    "normalized_df[\"product_tier\"] = normalized_df[\"product_tier\"].replace(Mapping_Tier)\n",
    "data = normalized_df.values\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "X = OrdinalEncoder().fit_transform(X)\n",
    "# y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Input and output shape:\\n\", X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basic       0.31      1.00      0.47       160\n",
      "        Plus       0.00      0.00      0.00       183\n",
      "     Premium       0.00      0.00      0.00       176\n",
      "\n",
      "    accuracy                           0.31       519\n",
      "   macro avg       0.10      0.33      0.16       519\n",
      "weighted avg       0.10      0.31      0.15       519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier after undersampling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "model.fit(x_train_res , y_train_res)\n",
    "y_pred = model.predict(X_test)\n",
    "target_names = ['Basic', 'Plus', 'Premium']\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\nfrom sklearn.ensemble import GradientBoostingClassifier'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basic       0.31      1.00      0.47       160\n",
      "        Plus       0.00      0.00      0.00       183\n",
      "     Premium       1.00      0.02      0.04       176\n",
      "\n",
      "    accuracy                           0.32       519\n",
      "   macro avg       0.44      0.34      0.17       519\n",
      "weighted avg       0.43      0.32      0.16       519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier after undersampling\n",
    "model_GB = GradientBoostingClassifier(n_estimators=1000)\n",
    "model_GB.fit(x_train_res , y_train_res)\n",
    "y_pred = model_GB.predict(X_test)\n",
    "target_names = ['Basic', 'Plus', 'Premium']\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Please also follow my comments and markdowns on every step.)\n",
    "\n",
    "Data was initially unclean; it had some incorrect or irregular values.\n",
    "I then, cleaned and processed the data for further analysis.\n",
    "\n",
    "To predict 'product tier', it is a Classification problem.\n",
    "\n",
    "One major disadvantage of the dataset was of how imbalaced the count of each classes were.\n",
    "To get a model to predict accurately, the spread of classes should ideally be balanced.\n",
    "\n",
    "There are several ways to develop a prediction model where the data is imbalanced.\n",
    "There are ML algoritmhs which are not very sensitive to imbalanced data.\n",
    "Then, there are ways to tackle imabalanced dataset problems (Resampling, class weights, etc.)\n",
    "\n",
    "I then, trained a Neural Network Model using Keras (Tensorflow backend) with different combinations:\n",
    "1. Original Dataset\n",
    "2. Cost sensitive training\n",
    "3. Undersampling\n",
    "4. Over-sampling\n",
    "5. Using Feature Selection on the Original Dataset\n",
    "6. Using Feature Selection with defining Class Weights\n",
    "7. Using Feature Selection on a 'Oversampled' Dataset\n",
    "\n",
    "For evaluation on such problems, a Classification Report is the best way to decide whether a predictive model is good or not.\n",
    "A precision score for each class is very helpful, plus macro_avg is a very good metric if we euqally value the minority classes as well.\n",
    "\n",
    "I found that Oversampling gives a pretty accurate prediction to our problem here.\n",
    "Even though, the accuracy achieved is not very high, with the information available, \n",
    "I believe a 72% accuracy (Model 4) is the best I could achieve.\n",
    "Of course, with more time and resources (data, computational power, etc), a better model can also be trained by getting the most optimal training set, finding the best hypertuning parameters, better spread of the dataset, etc.\n",
    "\n",
    "After training more models and reading papers, I came accross an understanding that Oversampling only on the training data is more logical. Because over-sampling on the whole dataset could create duplicate copies in both training and testing dataset, which could be misleading. Copies of the same point may end up in both the training and test sets. This allows the classifier to cheat, because when trying to make predictions on the test set the classifier will already have seen identical points in the train set.\n",
    "\n",
    "To answer the question, yes, it is remotely possible to predict 'product_tier' from the information available.\n",
    "Although, the model can be unreliable at times, it can still give a pretty good prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
